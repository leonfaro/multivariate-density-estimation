### Begin 00_globals.R ###
library(dplyr)
library(parallel)
library(tram)
library(trtf)
if (!exists("NC")) NC <- detectCores()
options(mc.cores = NC)
softplus <- function(x) log1p(exp(x))
### End 00_globals.R ###

### Begin 01_data_generation.R ###
Generate_iid_from_config <- function(N, cfg, return_params = FALSE) {
stopifnot(is.numeric(N), N > 0, is.list(cfg))
K <- length(cfg)
X <- matrix(NA_real_, nrow = N, ncol = K)
if (return_params) {
param_hist <- vector("list", K)
for (kk in seq_len(K))
param_hist[[kk]] <- vector("list", N)
}
for (i in seq_len(N)) {
for (k in seq_len(K)) {
c_k <- cfg[[k]]
if (is.null(c_k$parm)) {
args <- list()
} else {
if (k == 1) {
prev <- data.frame()
} else {
prev <- as.data.frame(as.list(X[i, seq_len(k - 1)]))
names(prev) <- paste0("X", seq_len(k - 1))
}
args <- c_k$parm(prev)
}
fun <- get(paste0("r", c_k$distr), mode = "function")
if (c_k$distr == "gamma" &&
all(c("shape1", "shape2") %in% names(args))) {
args <- list(shape = args$shape1, scale = args$shape2)
}
args <- lapply(args, function(p) {
if (!is.finite(p) || p <= 0) 1e-3 else p
})
if (return_params) param_hist[[k]][[i]] <- args
X[i, k] <- do.call(fun, c(list(n = 1L), args))
}
}
colnames(X) <- paste0("X", seq_len(K))
if (return_params) {
param_df <- lapply(param_hist, function(lst) {
vals <- lapply(lst, function(x) if (length(x) == 0) NULL else as.data.frame(x))
vals <- Filter(Negate(is.null), vals)
if (length(vals) == 0) return(NULL)
df <- do.call(rbind, vals)
rownames(df) <- NULL
df
})
list(X = X, params = param_df)
} else {
X
}
}
gen_samples <- function(G, return_params = FALSE) {
Generate_iid_from_config(G$n, G$config, return_params = return_params)
}
### End 01_data_generation.R ###

### Begin 02_split.R ###
SplitStruct <- function(X_tr, X_val, X_te) {
list(X_tr = X_tr, X_val = X_val, X_te = X_te)
}
split_data <- function(X, seed) {
stopifnot(is.matrix(X))
N <- nrow(X)
set.seed(seed)
idx <- sample.int(N)
n_tr  <- floor(0.8 * N)
n_val <- floor(0.1 * N)
idx_tr  <- idx[seq_len(n_tr)]
idx_val <- idx[seq_len(n_val) + n_tr]
idx_te  <- idx[(n_tr + n_val + 1):N]
SplitStruct(
X[idx_tr , , drop = FALSE],
X[idx_val, , drop = FALSE],
X[idx_te , , drop = FALSE]
)
}
### End 02_split.R ###

### Begin scripts/halfmoon_data.R ###
generate_two_moons <- function(n, noise, seed) {
stopifnot(is.numeric(n), n > 1, is.numeric(noise), is.numeric(seed))
set.seed(seed)
n1 <- floor(n / 2)
n2 <- n - n1
theta1 <- runif(n1, 0, pi)
theta2 <- runif(n2, 0, pi)
X1 <- cbind(cos(theta1), sin(theta1))
X2 <- cbind(1 - cos(theta2), -sin(theta2) + 0.5)
X <- rbind(X1, X2) + matrix(rnorm(2 * n, sd = noise), ncol = 2)
idx <- sample.int(n)
X <- X[idx, , drop = FALSE]
colnames(X) <- c("x1", "x2")
X
}
make_halfmoon_splits <- function(n_train, n_test, noise, seed, val_frac = 0.2) {
Xtr <- generate_two_moons(n_train, noise, seed)
Xte <- generate_two_moons(n_test, noise, seed + 1)
n_val <- max(10L, round(val_frac * n_train))
set.seed(seed + 2)
idx <- sample.int(n_train, n_val)
Xval <- Xtr[idx, , drop = FALSE]
Xtr <- Xtr[-idx, , drop = FALSE]
S <- list(
X_tr = Xtr,
X_val = Xval,
X_te = Xte,
K = 2L,
meta = list(
seed = seed,
noise = noise,
n_train = n_train,
n_test = n_test,
n_val = n_val,
val_frac = val_frac
)
)
check_halfmoon_splits(S)
}
check_halfmoon_splits <- function(S) {
stopifnot(is.list(S), all(c("X_tr", "X_val", "X_te", "K", "meta") %in% names(S)))
mats <- c("X_tr", "X_val", "X_te")
for (m in mats) {
X <- S[[m]]
if (!is.matrix(X) || ncol(X) != 2) stop(m, " must be a numeric matrix with two columns")
if (!is.numeric(X)) stop(m, " must be numeric")
if (any(is.na(X)) || any(is.infinite(X))) stop(m, " contains NA or Inf")
if (is.null(colnames(X)) || any(colnames(X) != c("x1", "x2"))) stop(m, " has wrong column names")
}
if (S$K != 2) stop("K must be 2")
n_train <- S$meta$n_train
n_test <- S$meta$n_test
n_val <- S$meta$n_val
if (nrow(S$X_tr) + nrow(S$X_val) != n_train) stop("Training and validation sizes inconsistent")
if (nrow(S$X_te) != n_test) stop("Test size inconsistent")
S
}
### End scripts/halfmoon_data.R ###

### Begin models/true_model.R ###
neg_loglik_uni <- function(par, x, distr) {
if (distr == "norm") {
mu <- par[1]; sd <- par[2]
if (sd <= 0) return(Inf)
-sum(dnorm(x, mean = mu, sd = sd, log = TRUE))
} else if (distr == "exp") {
rate <- par[1]
if (rate <= 0) return(Inf)
x <- pmax(x, 1e-6)
-sum(dexp(x, rate = rate, log = TRUE))
} else if (distr == "beta") {
a <- par[1]; b <- par[2]
if (a <= 0 || b <= 0) return(Inf)
x <- pmin(pmax(x, 1e-6), 1 - 1e-6)
-sum(dbeta(x, shape1 = a, shape2 = b, log = TRUE))
} else if (distr == "gamma") {
shape <- par[1]; scale <- par[2]
if (shape <= 0 || scale <= 0) return(Inf)
x <- pmax(x, 1e-6)
-sum(dgamma(x, shape = shape, scale = scale, log = TRUE))
} else {
stop("Unsupported distribution")
}
}
.log_density_vec <- function(x, distr, par) {
if (distr == "norm") {
dnorm(x, mean = par[1], sd = par[2], log = TRUE)
} else if (distr == "exp") {
x <- pmax(x, 1e-6)
dexp(x, rate = par[1], log = TRUE)
} else if (distr == "beta") {
x <- pmin(pmax(x, 1e-6), 1 - 1e-6)
dbeta(x, shape1 = par[1], shape2 = par[2], log = TRUE)
} else if (distr == "gamma") {
x <- pmax(x, 1e-6)
dgamma(x, shape = par[1], scale = par[2], log = TRUE)
} else {
stop("Unsupported distribution")
}
}
.start_par <- function(x, distr) {
if (distr == "norm") {
c(mean(x), sd(x))
} else if (distr == "exp") {
c(1 / mean(x))
} else if (distr == "beta") {
m <- mean(x); v <- var(x)
common <- m * (1 - m) / v - 1
a <- m * common; b <- (1 - m) * common
if (!is.finite(a) || a <= 0) a <- 1
if (!is.finite(b) || b <= 0) b <- 1
c(a, b)
} else if (distr == "gamma") {
m <- mean(x); v <- var(x)
shape <- m^2 / v; scale <- v / m
if (!is.finite(shape) || shape <= 0) shape <- 1
if (!is.finite(scale) || scale <= 0) scale <- 1
c(shape, scale)
} else {
stop("Unsupported distribution")
}
}
fit_TRUE <- function(S, config, cores = NC) {
stopifnot(is.list(S))
X_tr  <- S$X_tr
X_val <- S$X_val
X_te  <- S$X_te
stopifnot(is.matrix(X_tr), is.matrix(X_te))
K <- length(config)
theta_list <- parallel::mclapply(seq_len(K), function(k) {
distr_k <- config[[k]]$distr
x_k <- X_tr[, k]
init <- .start_par(x_k, distr_k)
opt <- optim(
par = init,
fn = neg_loglik_uni,
x = x_k,
distr = distr_k,
method = "L-BFGS-B",
lower = rep(1e-6, length(init))
)
opt$par
}, mc.cores = cores)
model <- list(theta = theta_list, config = config)
logL_te <- logL_TRUE(model, X_te)
model$logL_te <- logL_te
model
}
logL_TRUE <- function(M_TRUE, X, cores = NC) {
stopifnot(is.matrix(X))
theta_list <- M_TRUE$theta
config <- M_TRUE$config
K <- length(theta_list)
ll_list <- parallel::mclapply(seq_len(K), function(k) {
distr_k <- config[[k]]$distr
.log_density_vec(X[, k], distr_k, theta_list[[k]])
}, mc.cores = cores)
ll <- do.call(cbind, ll_list)
val <- -mean(rowSums(ll))
if (!is.finite(val)) stop("log-likelihood not finite")
val
}
logL_TRUE_dim <- function(M_TRUE, X, cores = NC) {
stopifnot(is.matrix(X))
theta_list <- M_TRUE$theta
config <- M_TRUE$config
K <- length(theta_list)
res <- parallel::mclapply(seq_len(K), function(k) {
distr_k <- config[[k]]$distr
ll_k <- .log_density_vec(X[, k], distr_k, theta_list[[k]])
val <- -mean(ll_k)
if (!is.finite(val)) stop("log-likelihood not finite")
val
}, mc.cores = cores)
unlist(res)
}
### End models/true_model.R ###

### Begin models/trtf_model.R ###
p <- list(
minsplit = 40,
minbucket = 5,
maxdepth = 2,
seed = 42
)
mytrtf <- function(data, ntree, minsplit, minbucket, maxdepth, seed, cores = NC) {
stopifnot(is.matrix(data))
set.seed(seed)
K <- ncol(data)
df <- as.data.frame(data)
names(df) <- paste0("X", seq_len(K))
ymod <- lapply(names(df), function(y) {
BoxCox(as.formula(paste(y, "~ 1")), data = df)
})
forests <- vector("list", K - 1L)
ctrl <- partykit::ctree_control(minsplit = minsplit,
minbucket = minbucket,
maxdepth = maxdepth)
for (k in 2:K) {
rhs <- paste(names(df)[1:(k - 1)], collapse = "+")
fm <- as.formula(paste(names(df)[k], "~", rhs))
current_mtry <- max(1, floor((k - 1) / 2))
forests[[k - 1L]] <- traforest(ymod[[k]], formula = fm, data = df,
trace = TRUE, ntree = ntree,
mltargs = list(), mtry = current_mtry,
cores = cores, control = ctrl)
}
res <- list(ymod = ymod, forests = forests, seed = seed,
varimp = lapply(forests, varimp))
class(res) <- "mytrtf"
res
}
predict.mytrtf <- function(object, newdata,
type = c("logdensity", "logdensity_by_dim"),
cores = NC, trace = TRUE) {
type <- match.arg(type)
stopifnot(inherits(object, "mytrtf"), is.matrix(newdata))
K <- length(object$ymod)
df_new <- as.data.frame(newdata)
names(df_new) <- paste0("X", seq_len(K))
N <- nrow(df_new)
ld1 <- predict(object$ymod[[1]], newdata = df_new, type = "logdensity")
stopifnot(is.numeric(ld1), length(ld1) == N)
ld_rest <- lapply(seq_along(object$forests), function(j) {
fr <- object$forests[[j]]
resp <- paste0("X", j + 1L)
q <- df_new[[resp]]
pr <- predict(fr, newdata = df_new, type = "logdensity", q = q,
cores = cores, trace = trace)
if (is.numeric(pr) && length(pr) == N) {
ld_j <- pr
} else {
M <- if (is.list(pr)) do.call(cbind, pr) else as.matrix(pr)
if (ncol(M) > N) M <- M[, seq_len(N), drop = FALSE]
stopifnot(nrow(M) == N, ncol(M) == N)
ld_j <- diag(M)
}
ld_j
})
ld_rest <- do.call(cbind, ld_rest)
ll <- cbind(ld1, ld_rest)
if (type == "logdensity_by_dim") return(ll)
rowSums(ll)
}
logL_TRTF <- function(model, X, cores = NC) {
val <- -mean(predict(model, X, type = "logdensity",
cores = cores, trace = TRUE))
if (!is.finite(val)) stop("log-likelihood not finite")
val
}
logL_TRTF_dim <- function(model, X, cores = NC) {
ll <- predict(model, X, type = "logdensity_by_dim",
cores = cores, trace = TRUE)
res <- -colMeans(ll)
if (!all(is.finite(res))) stop("log-likelihood not finite")
res
}
fit_TRTF <- function(S, config, seed = NULL, cores = NC) {
stopifnot(is.list(S))
X_tr <- S$X_tr
X_te <- S$X_te
stopifnot(is.matrix(X_tr), is.matrix(X_te))
if (!is.null(seed)) set.seed(seed)
mod <- mytrtf(data = X_tr,
ntree = nrow(X_tr),
minsplit = p$minsplit,
minbucket = p$minbucket,
maxdepth = p$maxdepth,
seed = seed,
cores = cores)
mod$config  <- config
logL_te_dim <- logL_TRTF_dim(mod, S$X_te, cores = cores)
mod$logL_te_dim <- logL_te_dim
mod$logL_te <- sum(logL_te_dim)
mod
}
### End models/trtf_model.R ###

### Begin models/ttm_marginal.R ###
.standardizeData <- function(X) {
mu <- colMeans(X)
sigma <- apply(X, 2, sd) + .Machine$double.eps
X_tilde <- sweep(X, 2, mu, "-")
X_tilde <- sweep(X_tilde, 2, sigma, "/")
list(X = X_tilde, mu = mu, sigma = sigma)
}
.forward_matrix <- function(S, X) {
Xs <- .standardize(S, X)
b <- exp(S$coeffA)
Z <- sweep(Xs, 2, b, "*")
sweep(Z, 2, S$coeffB, "+")
}
.logjac_const <- function(S) {
b <- exp(S$coeffA)
log(b) - log(S$sigma)
}
.standardize <- function(S, X) {
X <- sweep(X, 2, S$mu, "-")
sweep(X, 2, S$sigma, "/")
}
trainMarginalMap <- function(X_or_path, seed = 42) {
set.seed(seed)
S_in <- if (is.character(X_or_path)) readRDS(X_or_path) else X_or_path
stopifnot(is.list(S_in))
X_tr <- S_in$X_tr
X_val <- S_in$X_val
X_te  <- S_in$X_te
time_train <- system.time({
std <- .standardizeData(X_tr)
X_tr_std <- std$X
mu <- std$mu
sigma <- std$sigma
K <- ncol(X_tr_std)
coeffA <- numeric(K)
coeffB <- numeric(K)
for (k in seq_len(K)) {
xk <- X_tr_std[, k]
N <- length(xk)
u <- rank(xk, ties.method = "average") / (N + 1)
lower <- 1 / (N + 1)
upper <- N / (N + 1)
u <- pmin(pmax(u, lower), upper)
z_star <- qnorm(u)
covxz <- mean((xk - mean(xk)) * (z_star - mean(z_star)))
varx <- var(xk) + 1e-12
b_k <- max(0, covxz / varx)
a_k <- mean(z_star) - b_k * mean(xk)
coeffA[k] <- log(b_k + 1e-12)
coeffB[k] <- a_k
}
coeffC <- rep(0, K)
S_map <- list(
mu = mu,
sigma = sigma,
coeffA = coeffA,
coeffB = coeffB,
coeffC = coeffC,
order = seq_len(K)
)
class(S_map) <- "ttm_marginal"
})[["elapsed"]]
time_pred <- system.time({
predict(S_map, X_te, "logdensity_by_dim")
})[["elapsed"]]
list(
S = S_map,
NLL_train = NLL_set(S_map, X_tr),
NLL_val = NLL_set(S_map, X_val),
NLL_test = NLL_set(S_map, X_te),
stderr_test = SE_set(S_map, X_te),
time_train = time_train,
time_pred = time_pred
)
}
predict.ttm_marginal <- function(object, newdata,
type = c("logdensity_by_dim", "logdensity")) {
type <- tryCatch(match.arg(type), error = function(e) stop("unknown type"))
Z <- .forward_matrix(object, newdata)
LJ <- .logjac_const(object)
C <- -0.5 * log(2 * pi)
LD <- (-0.5) * (Z^2) + C +
matrix(LJ, nrow = nrow(Z), ncol = length(LJ), byrow = TRUE)
if (type == "logdensity_by_dim") {
LD
} else {
rowSums(LD)
}
}
NLL_set <- function(S, X) {
mean(-rowSums(predict(S, X, "logdensity_by_dim")))
}
SE_set <- function(S, X) {
v <- rowSums(-predict(S, X, "logdensity_by_dim"))
stats::sd(v) / sqrt(length(v))
}
forwardPass <- function(S, x) {
x_std <- .standardize(S, matrix(x, nrow = 1))
b <- exp(S$coeffA)
a <- S$coeffB
as.numeric(a + b * x_std)
}
logJacDiag <- function(S, x) {
LJ <- .logjac_const(S)
rep(LJ, length.out = length(x))
}
forwardKLLoss <- function(S, X) {
Z <- .forward_matrix(S, X)
LJ <- .logjac_const(S)
mean(0.5 * rowSums(Z^2) - sum(LJ))
}
inversePass <- function(S, z) {
b <- exp(S$coeffA)
a <- S$coeffB
x_std <- (z - a) / b
x <- sweep(x_std, 2, S$sigma, "*")
x <- sweep(x, 2, S$mu, "+")
as.numeric(x)
}
negativeLogLikelihood <- function(S, X) {
Z <- .forward_matrix(S, X)
LJ <- .logjac_const(S)
sum(0.5 * rowSums(Z^2) - sum(LJ))
}
natsPerDim <- function(NLL, N, K) {
NLL / (N * K)
}
stderr <- function(v) {
stats::sd(v) / sqrt(length(v))
}
### End models/ttm_marginal.R ###

### Begin models/ttm_separable.R ###
if (!exists(".standardizeData")) {
.standardizeData <- function(X) {
mu <- colMeans(X)
sigma <- apply(X, 2, sd) + .Machine$double.eps
X_tilde <- sweep(X, 2, mu, "-")
X_tilde <- sweep(X_tilde, 2, sigma, "/")
list(X = X_tilde, mu = mu, sigma = sigma)
}
}
if (!exists(".standardize")) {
.standardize <- function(S, X) {
X <- sweep(X, 2, S$mu, "-")
sweep(X, 2, S$sigma, "/")
}
}
erf <- function(x) 2 * pnorm(x * sqrt(2)) - 1
basis_f <- function(x) cbind(x, erf(x))
dbasis_f <- function(x) {
cbind(rep(1, length(x)), 2 / sqrt(pi) * exp(-x^2))
}
basis_g <- function(X, deg) {
if (ncol(X) == 0L) {
return(matrix(0, nrow = nrow(X), ncol = 0))
}
N <- nrow(X)
out <- matrix(1, N, 1)
for (j in seq_len(ncol(X))) {
xj <- X[, j]
for (d in seq_len(deg)) {
out <- cbind(out, xj^d)
}
}
out
}
trainSeparableMap <- function(X_or_path, degree_g = 2, lambda = 1e-3, eps = 1e-6, seed = 42) {
set.seed(seed)
S_in <- if (is.character(X_or_path)) readRDS(X_or_path) else X_or_path
stopifnot(is.list(S_in))
X_tr <- S_in$X_tr
X_val <- S_in$X_val
X_te  <- S_in$X_te
time_train <- system.time({
std <- .standardizeData(X_tr)
X_tr_std <- std$X
mu <- std$mu
sigma <- std$sigma
K <- ncol(X_tr_std)
coeffs <- vector("list", K)
N <- nrow(X_tr_std)
for (k in seq_len(K)) {
x_prev <- if (k > 1) X_tr_std[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
xk <- X_tr_std[, k]
P_non <- if (k > 1) basis_g(x_prev, degree_g) else matrix(0, N, 0)
P_mon <- basis_f(xk)
B <- dbasis_f(xk)
stopifnot(nrow(P_mon) == N, nrow(P_non) == N, nrow(B) == N)
m_non <- ncol(P_non)
m_mon <- ncol(P_mon)
if (m_non > 0) {
M <- solve(crossprod(P_non) + lambda * diag(m_non), t(P_non))
A <- (diag(N) - P_non %*% M) %*% P_mon
D <- M %*% P_mon
} else {
M <- matrix(0, 0, N)
A <- P_mon
D <- matrix(0, 0, m_mon)
}
fn <- function(c) {
r <- A %*% c
Bc <- B %*% c
if (any(Bc <= 0)) return(Inf)
q <- D %*% c
0.5 * sum(r^2) - sum(log(Bc)) + (lambda / 2) * (sum(q^2) + sum(c^2))
}
gr <- function(c) {
r <- A %*% c
Bc <- B %*% c
q <- D %*% c
as.numeric(t(A) %*% r - t(B) %*% (1 / Bc) + lambda * (t(D) %*% q + c))
}
c0 <- rep(1, m_mon)
opt <- optim(c0, fn, gr, method = "L-BFGS-B", lower = rep(eps, m_mon))
c_mon <- opt$par
c_non <- if (m_non > 0) -M %*% (P_mon %*% c_mon) else numeric(0)
coeffs[[k]] <- list(c_non = c_non, c_mon = c_mon)
}
S_map <- list(
mu = mu,
sigma = sigma,
coeffs = coeffs,
degree_g = degree_g,
order = seq_len(K)
)
class(S_map) <- "ttm_separable"
})[["elapsed"]]
time_pred <- system.time({
predict(S_map, X_te, "logdensity_by_dim")
})[["elapsed"]]
list(
S = S_map,
NLL_train = NLL_set(S_map, X_tr),
NLL_val = NLL_set(S_map, X_val),
NLL_test = NLL_set(S_map, X_te),
stderr_test = SE_set(S_map, X_te),
time_train = time_train,
time_pred = time_pred
)
}
predict.ttm_separable <- function(object, newdata,
type = c("logdensity_by_dim", "logdensity")) {
type <- tryCatch(match.arg(type), error = function(e) stop("unknown type"))
Xs <- .standardize(object, newdata)
N <- nrow(Xs)
K <- ncol(Xs)
Z <- matrix(0, N, K)
LJ <- matrix(0, N, K)
for (k in seq_len(K)) {
x_prev <- if (k > 1) Xs[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
xk <- Xs[, k]
P_non <- if (k > 1) basis_g(x_prev, object$degree_g) else matrix(0, N, 0)
P_mon <- basis_f(xk)
B <- dbasis_f(xk)
c_non <- object$coeffs[[k]]$c_non
c_mon <- object$coeffs[[k]]$c_mon
gk <- if (ncol(P_non) > 0) as.numeric(P_non %*% c_non) else rep(0, N)
fk <- as.numeric(P_mon %*% c_mon)
Z[, k] <- gk + fk
deriv <- (B %*% c_mon) / object$sigma[k]
LJ[, k] <- log(as.numeric(deriv))
}
C <- -0.5 * log(2 * pi)
LD <- (-0.5) * (Z^2) + C + LJ
if (type == "logdensity_by_dim") {
LD
} else {
rowSums(LD)
}
}
NLL_set <- function(S, X) {
mean(-rowSums(predict(S, X, "logdensity_by_dim")))
}
SE_set <- function(S, X) {
v <- rowSums(-predict(S, X, "logdensity_by_dim"))
stats::sd(v) / sqrt(length(v))
}
### End models/ttm_separable.R ###

### Begin models/ttm_cross_term.R ###
if (!exists(".standardizeData")) {
.standardizeData <- function(X) {
mu <- colMeans(X)
sigma <- apply(X, 2, sd) + .Machine$double.eps
X_tilde <- sweep(X, 2, mu, "-")
X_tilde <- sweep(X_tilde, 2, sigma, "/")
list(X = X_tilde, mu = mu, sigma = sigma)
}
}
if (!exists(".standardize")) {
.standardize <- function(S, X) {
X <- sweep(X, 2, S$mu, "-")
sweep(X, 2, S$sigma, "/")
}
}
.basis_g_ct <- function(X, deg) {
if (ncol(X) == 0L) {
return(matrix(0, nrow = nrow(X), ncol = 0))
}
N <- nrow(X)
out <- matrix(1, N, 1)
for (j in seq_len(ncol(X))) {
xj <- X[, j]
for (d in seq_len(deg)) {
out <- cbind(out, xj^d)
}
}
out
}
.psi_basis_ct <- function(t, xprev, deg_t, deg_x, cross = TRUE,
deg_t_cross = 1, deg_x_cross = 1) {
out <- numeric(0)
if (deg_t > 0) {
for (d in seq_len(deg_t)) {
out <- c(out, t^d)
}
}
if (cross && length(xprev) > 0) {
for (j in seq_along(xprev)) {
for (r in seq_len(deg_t_cross)) {
for (s in seq_len(deg_x_cross)) {
out <- c(out, t^r * xprev[j]^s)
}
}
}
}
out
}
.dpsi_dt_ct <- function(t, xprev, deg_t, deg_x, cross = TRUE,
deg_t_cross = 1, deg_x_cross = 1) {
out <- numeric(0)
if (deg_t > 0) {
for (d in seq_len(deg_t)) {
out <- c(out, d * t^(max(d - 1, 0)))
}
}
if (cross && length(xprev) > 0) {
for (j in seq_along(xprev)) {
for (r in seq_len(deg_t_cross)) {
for (s in seq_len(deg_x_cross)) {
out <- c(out, r * t^(max(r - 1, 0)) * xprev[j]^s)
}
}
}
}
out
}
.build_Psi_q_ct <- function(xval, xp, nodes, nodes_pow, deg_t, deg_x,
deg_t_cross = 1, deg_x_cross = 1) {
Q <- length(nodes)
m_beta <- deg_t + length(xp) * deg_t_cross * deg_x_cross
Psi_q <- matrix(0, Q, m_beta)
if (deg_t > 0) {
x_pow <- xval^(seq_len(deg_t))
Psi_q[, seq_len(deg_t)] <- sweep(nodes_pow[, seq_len(deg_t), drop = FALSE], 2, x_pow, "*")
}
if (length(xp) > 0) {
col <- deg_t
x_pow_cross <- xval^(seq_len(deg_t_cross))
xp_pows <- lapply(xp, function(xj) xj^(seq_len(deg_x_cross)))
for (j in seq_along(xp)) {
for (r in seq_len(deg_t_cross)) {
for (s in seq_len(deg_x_cross)) {
col <- col + 1
Psi_q[, col] <- nodes_pow[, r] * x_pow_cross[r] * xp_pows[[j]][s]
}
}
}
}
Psi_q
}
.gauss_legendre_01_ct <- function(n) {
if (n <= 0 || n != as.integer(n)) {
stop("n must be positive integer")
}
if (n == 1) {
return(list(nodes = 0.5, weights = 1))
}
i <- seq_len(n - 1)
b <- i / sqrt(4 * i^2 - 1)
J <- matrix(0, n, n)
for (k in i) {
J[k, k + 1] <- b[k]
J[k + 1, k] <- b[k]
}
e <- eigen(J, symmetric = TRUE)
x <- (e$values + 1) / 2
w <- (2 * (e$vectors[1, ]^2)) / 2
list(nodes = x, weights = w)
}
.safe_mclapply_ct <- function(X, FUN, mc.cores, ...) {
parallel::mclapply(X, function(ix) {
tryCatch(FUN(ix), error = function(e) e)
}, mc.cores = mc.cores, mc.set.seed = FALSE, mc.preschedule = TRUE, ...)
}
.is_coeffs_ok <- function(x) is.list(x) && is.numeric(x$alpha) && is.numeric(x$beta)
.is_predchunk_ok <- function(x) is.list(x) && is.numeric(x$Z_col) && is.numeric(x$LJ_col)
.zero_coeffs_ct <- function(k, X_tr_std, degree_g, degree_t,
degree_t_cross, degree_x_cross) {
N <- nrow(X_tr_std)
Xprev <- if (k > 1) X_tr_std[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
m_alpha <- ncol(.basis_g_ct(Xprev, degree_g))
xprev_first <- if (k > 1) Xprev[1, , drop = TRUE] else numeric(0)
m_beta <- length(.psi_basis_ct(0, xprev_first, degree_t, degree_g, TRUE, degree_t_cross, degree_x_cross))
list(alpha = if (m_alpha > 0) rep(0, m_alpha) else numeric(0),
beta  = rep(0, m_beta),
convergence = NA_real_)
}
.zero_predchunk_ct <- function(N, sigma_k) {
list(Z_col = rep(0, N), LJ_col = rep(-log(sigma_k), N))
}
.NLL_set_ct <- function(S, X) {
mean(-rowSums(predict(S, X, "logdensity_by_dim")))
}
.SE_set_ct <- function(S, X) {
v <- rowSums(-predict(S, X, "logdensity_by_dim"))
stats::sd(v) / sqrt(length(v))
}
.logJacDiag_ct <- function(S, x) {
Xs <- .standardize(S, matrix(x, nrow = 1))
K <- length(x)
out <- numeric(K)
for (k in seq_len(K)) {
xprev <- if (k > 1) Xs[1, 1:(k - 1)] else numeric(0)
psi <- .psi_basis_ct(Xs[1, k], xprev, S$degree_t, S$degree_g, TRUE, S$degree_t_cross, S$degree_x_cross)
beta <- S$coeffs[[k]]$beta
out[k] <- sum(beta * psi) - log(S$sigma[k])
}
out
}
.forwardKLLoss_ct <- function(S, X) {
X <- as.matrix(X)
K <- ncol(X)
LD <- predict(S, X, "logdensity_by_dim")
mean(-rowSums(LD) - 0.5 * K * log(2 * pi))
}
trainCrossTermMap <- function(X_or_path, degree_g = 2, degree_t = 2, degree_t_cross = 1, degree_x_cross = 1,
lambda = 1e-3, batch_n = NULL, Q = NULL,
eps = 1e-6, clip = Inf,
alpha_init_list = NULL, warmstart_from_separable = FALSE,
sep_degree_g = NULL, sep_lambda = 1e-3, seed = 42) {
set.seed(seed)
S_in <- if (is.character(X_or_path)) readRDS(X_or_path) else X_or_path
stopifnot(is.list(S_in))
X_tr <- S_in$X_tr
X_val <- S_in$X_val
X_te  <- S_in$X_te
if (is.null(alpha_init_list) && warmstart_from_separable) {
if (!exists("trainSeparableMap")) {
stop("trainSeparableMap not found for warm start")
}
sep_deg <- if (is.null(sep_degree_g)) degree_g else sep_degree_g
fit_sep <- trainSeparableMap(S_in, degree_g = sep_deg, lambda = sep_lambda, seed = seed)
alpha_init_list <- lapply(fit_sep$S$coeffs, `[[`, "c_non")
}
time_train <- system.time({
std <- .standardizeData(X_tr)
X_tr_std <- std$X
mu <- std$mu
sigma <- std$sigma
N <- nrow(X_tr_std)
K <- ncol(X_tr_std)
if (!is.null(alpha_init_list)) {
stopifnot(length(alpha_init_list) == K)
}
degree_t_max <- max(degree_t, degree_t_cross)
Q_use <- if (is.null(Q)) min(12, 4 + 2 * degree_t_max) else Q
batch_use <- if (is.null(batch_n)) min(N, max(256L, floor(65536 / max(1L, Q_use)))) else min(N, batch_n)
quad <- .gauss_legendre_01_ct(Q_use)
nodes <- quad$nodes
weights <- quad$weights
nodes_pow <- outer(nodes, seq_len(degree_t_max), `^`)
fit_k <- function(k) {
Xprev <- if (k > 1) X_tr_std[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
xk <- X_tr_std[, k]
Phi <- .basis_g_ct(Xprev, degree_g)
m_alpha <- ncol(Phi)
xprev_first <- if (k > 1) Xprev[1, , drop = TRUE] else numeric(0)
m_beta <- length(.psi_basis_ct(0, xprev_first, degree_t, degree_g, TRUE, degree_t_cross, degree_x_cross))
alpha_start <- if (m_alpha > 0) {
if (is.null(alpha_init_list)) {
rep(0, m_alpha)
} else {
ai <- alpha_init_list[[k]]
if (length(ai) != m_alpha) rep(0, m_alpha) else ai
}
} else {
numeric(0)
}
loss_grad <- function(alpha, beta) {
S_sq_sum <- 0
term_sum <- 0
grad_alpha <- if (m_alpha > 0) rep(0, m_alpha) else numeric(0)
grad_beta <- rep(0, m_beta)
for (i0 in seq(1, N, by = batch_use)) {
idx <- i0:min(i0 + batch_use - 1, N)
Phi_blk <- if (m_alpha > 0) Phi[idx, , drop = FALSE] else NULL
Xprev_blk <- if (k > 1) Xprev[idx, , drop = FALSE] else matrix(0, length(idx), 0)
xk_blk <- xk[idx]
for (b in seq_along(idx)) {
xp <- if (k > 1) Xprev_blk[b, ] else numeric(0)
xval <- xk_blk[b]
Psi_q <- .build_Psi_q_ct(xval, xp, nodes, nodes_pow, degree_t, degree_g, degree_t_cross, degree_x_cross)
V <- as.vector(Psi_q %*% beta)
b_vec <- log(weights) + V
b_max <- max(b_vec)
r <- exp(b_vec - b_max)
s <- exp(b_max) * sum(r)
I_i <- xval * s
soft <- r / sum(r)
dI_i <- I_i * as.vector(t(Psi_q) %*% soft)
psi_x <- .psi_basis_ct(xval, xp, degree_t, degree_g, TRUE, degree_t_cross, degree_x_cross)
S_i <- if (m_alpha > 0) sum(Phi_blk[b, ] * alpha) + I_i else I_i
S_sq_sum <- S_sq_sum + S_i^2
if (m_alpha > 0) grad_alpha <- grad_alpha + S_i * Phi_blk[b, ]
grad_beta <- grad_beta + S_i * dI_i - psi_x
term_sum <- term_sum + sum(psi_x * beta)
}
}
loss <- 0.5 * S_sq_sum / N - term_sum / N +
0.5 * lambda * (sum(alpha^2) + sum(beta^2))
grad_alpha_out <- if (m_alpha > 0) grad_alpha / N + lambda * alpha else numeric(0)
grad_beta_out <- grad_beta / N + lambda * beta
list(loss = loss, grad = c(grad_alpha_out, grad_beta_out))
}
cache <- new.env(parent = emptyenv())
fn <- function(theta) {
alpha <- if (m_alpha > 0) theta[seq_len(m_alpha)] else numeric(0)
beta <- theta[(m_alpha + 1):length(theta)]
res <- loss_grad(alpha, beta)
cache$grad <- res$grad
res$loss
}
gr <- function(theta) {
if (!is.null(cache$grad)) {
g <- cache$grad
cache$grad <- NULL
return(g)
}
alpha <- if (m_alpha > 0) theta[seq_len(m_alpha)] else numeric(0)
beta <- theta[(m_alpha + 1):length(theta)]
loss_grad(alpha, beta)$grad
}
theta0 <- c(alpha_start, rep(0, m_beta))
opt <- optim(theta0, fn, gr, method = "L-BFGS-B", lower = -Inf, upper = Inf)
alpha_hat <- if (m_alpha > 0) opt$par[seq_len(m_alpha)] else numeric(0)
beta_hat <- opt$par[(m_alpha + 1):length(opt$par)]
list(alpha = alpha_hat, beta = beta_hat, convergence = opt$convergence)
}
res <- .safe_mclapply_ct(seq_len(K), fit_k,
mc.cores = min(getOption("mc.cores", 10L), K))
for (k in seq_len(K)) {
if (!.is_coeffs_ok(res[[k]])) {
r2 <- tryCatch(fit_k(k), error = function(e) e)
if (!.is_coeffs_ok(r2)) {
r2 <- .zero_coeffs_ct(k, X_tr_std, degree_g, degree_t, degree_t_cross, degree_x_cross)
}
res[[k]] <- r2
}
}
coeffs <- res
stopifnot(length(coeffs) == K,
all(vapply(coeffs, .is_coeffs_ok, logical(1))) )
S_map <- list(
mu = mu,
sigma = sigma,
degree_g = degree_g,
degree_t = degree_t,
degree_t_cross = degree_t_cross,
degree_x_cross = degree_x_cross,
coeffs = coeffs,
Q = Q_use,
nodes = nodes,
weights = weights,
nodes_pow = nodes_pow,
quad_nodes_ct = nodes,
quad_weights_ct = weights,
quad_nodes_pow_ct = nodes_pow,
clip = clip,
order = seq_len(K)
)
class(S_map) <- "ttm_cross_term"
})[["elapsed"]]
time_pred <- system.time({
predict(S_map, X_te, "logdensity_by_dim")
})[["elapsed"]]
list(
S = S_map,
NLL_train = .NLL_set_ct(S_map, X_tr),
NLL_val = .NLL_set_ct(S_map, X_val),
NLL_test = .NLL_set_ct(S_map, X_te),
stderr_test = .SE_set_ct(S_map, X_te),
time_train = time_train,
time_pred = time_pred
)
}
predict.ttm_cross_term <- function(object, newdata,
type = c("logdensity_by_dim", "logdensity"),
batch_n = NULL) {
type <- tryCatch(match.arg(type), error = function(e) stop("unknown type"))
Xs <- .standardize(object, newdata)
N <- nrow(Xs)
K <- ncol(Xs)
batch_use <- if (is.null(batch_n)) min(N, max(256L, floor(65536 / max(1L, object$Q)))) else min(N, batch_n)
nodes <- object$quad_nodes_ct
weights <- object$quad_weights_ct
nodes_pow <- object$quad_nodes_pow_ct
C <- -0.5 * log(2 * pi)
chunk_fun <- function(k) {
Xprev <- if (k > 1) Xs[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
xk <- Xs[, k]
Phi <- .basis_g_ct(Xprev, object$degree_g)
m_alpha <- ncol(Phi)
alpha <- object$coeffs[[k]]$alpha
beta <- object$coeffs[[k]]$beta
xprev_first <- if (k > 1) Xprev[1, , drop = TRUE] else numeric(0)
psi_len <- length(.psi_basis_ct(Xs[1, k], xprev_first,
object$degree_t, object$degree_g, TRUE, object$degree_t_cross, object$degree_x_cross))
stopifnot(length(beta) == psi_len)
Z_col <- numeric(N)
LJ_col <- numeric(N)
for (i0 in seq(1, N, by = batch_use)) {
idx <- i0:min(i0 + batch_use - 1, N)
Phi_blk <- if (m_alpha > 0) Phi[idx, , drop = FALSE] else NULL
Xprev_blk <- if (k > 1) Xprev[idx, , drop = FALSE] else matrix(0, length(idx), 0)
xk_blk <- xk[idx]
for (b in seq_along(idx)) {
xp <- if (k > 1) Xprev_blk[b, ] else numeric(0)
xval <- xk_blk[b]
Psi_q <- .build_Psi_q_ct(xval, xp, nodes, nodes_pow, object$degree_t, object$degree_g, object$degree_t_cross, object$degree_x_cross)
V <- as.vector(Psi_q %*% beta)
b_vec <- log(weights) + V
b_max <- max(b_vec)
r <- exp(b_vec - b_max)
s <- exp(b_max) * sum(r)
I_i <- xval * s
psi_x <- .psi_basis_ct(xval, xp, object$degree_t, object$degree_g, TRUE, object$degree_t_cross, object$degree_x_cross)
Z_col[idx[b]] <- if (m_alpha > 0) sum(Phi_blk[b, ] * alpha) + I_i else I_i
LJ_col[idx[b]] <- sum(beta * psi_x) - log(object$sigma[k])
}
}
list(Z_col = Z_col, LJ_col = LJ_col)
}
res <- .safe_mclapply_ct(seq_len(K), chunk_fun,
mc.cores = min(getOption("mc.cores", 10L), K))
for (k in seq_len(K)) {
if (!.is_predchunk_ok(res[[k]])) {
r2 <- tryCatch(chunk_fun(k), error = function(e) e)
if (!.is_predchunk_ok(r2)) {
r2 <- .zero_predchunk_ct(N, object$sigma[k])
r2$Z_col <- Xs[, k]
}
res[[k]] <- r2
}
}
Z <- do.call(cbind, lapply(res, `[[`, "Z_col"))
LJ <- do.call(cbind, lapply(res, `[[`, "LJ_col"))
LD <- (-0.5) * (Z^2) + C + LJ
if (type == "logdensity_by_dim") {
LD
} else {
rowSums(LD)
}
}
### End models/ttm_cross_term.R ###

### Begin models/true_joint_model.R ###
.sanitize_args <- function(args, distr) {
if (distr == "gamma" && all(c("shape1", "shape2") %in% names(args))) {
args$shape <- args$shape1
args$scale <- args$shape2
args$shape1 <- NULL
args$shape2 <- NULL
}
pos_params <- switch(distr,
norm  = "sd",
exp   = "rate",
beta  = c("shape1", "shape2"),
gamma = c("shape", "scale"),
character(0)
)
defaults <- list(
norm = list(sd = 1),
exp = list(rate = 1),
beta = list(shape1 = 1, shape2 = 1),
gamma = list(shape = 1, scale = 1)
)
for (nm in pos_params) {
val <- args[[nm]]
if (is.null(val) || !is.finite(val) || val <= 0) {
val <- defaults[[distr]][[nm]]
}
args[[nm]] <- max(val, 1e-6)
}
args
}
.log_density_conditional_row <- function(x_row, config) {
K <- length(config)
out <- numeric(K)
prev_names <- paste0("X", seq_len(K))
for (k in seq_len(K)) {
prev <- if (k == 1) data.frame() else {
df <- as.data.frame(as.list(x_row[seq_len(k - 1)]))
names(df) <- prev_names[seq_len(k - 1)]
df
}
distr_k <- config[[k]]$distr
if (is.null(config[[k]]$parm)) {
args <- list()
if (distr_k == "beta") {
args$shape1 <- 1
args$shape2 <- 1
} else if (distr_k == "gamma") {
args$shape <- 1
args$scale <- 1
}
} else {
args <- config[[k]]$parm(prev)
}
args <- .sanitize_args(args, distr_k)
xk <- x_row[k]
if (distr_k %in% c("exp", "gamma")) {
xk <- max(xk, 1e-6)
} else if (distr_k == "beta") {
xk <- min(max(xk, 1e-6), 1 - 1e-6)
}
out[k] <- switch(distr_k,
norm  = dnorm(xk, mean = args$mean %||% 0, sd = args$sd %||% 1, log = TRUE),
exp   = dexp(xk, rate = args$rate %||% 1, log = TRUE),
beta  = dbeta(xk, shape1 = args$shape1, shape2 = args$shape2, log = TRUE),
gamma = dgamma(xk, shape = args$shape, scale = args$scale, log = TRUE),
stop("Unsupported distribution")
)
}
out
}
true_joint_logdensity_by_dim <- function(config, X, cores = NC) {
stopifnot(is.matrix(X))
res <- parallel::mclapply(seq_len(nrow(X)), function(i) {
.log_density_conditional_row(X[i, ], config)
}, mc.cores = cores)
ll <- do.call(rbind, res)
if (!all(is.finite(ll))) stop("log-density not finite")
ll
}
logL_TRUE_JOINT_dim <- function(config, X, cores = NC) {
ll <- true_joint_logdensity_by_dim(config, X, cores)
-colMeans(ll)
}
logL_TRUE_JOINT <- function(config, X, cores = NC) {
ll <- true_joint_logdensity_by_dim(config, X, cores)
-mean(rowSums(ll))
}
fit_TRUE_JOINT <- function(S, config, cores = NC) {
stopifnot(is.list(S))
te_dim <- logL_TRUE_JOINT_dim(config, S$X_te, cores)
res <- list(
config = config,
logL_te_dim = te_dim,
logL_te = sum(te_dim)
)
class(res) <- "true_joint"
res
}
`%||%` <- function(a, b) if (is.null(a)) b else a
### End models/true_joint_model.R ###

### Begin 04_evaluation.R ###
root_path <- getwd()
if (basename(root_path) == "testthat") {
root_path <- dirname(dirname(root_path))
}
source(file.path(root_path, "models/ttm_marginal.R"))
source(file.path(root_path, "models/ttm_separable.R"))
source(file.path(root_path, "models/ttm_cross_term.R"))
source(file.path(root_path, "models/true_joint_model.R"))
add_sum_row <- function(tab, label = "k") {
stopifnot(is.data.frame(tab))
sum_row <- setNames(vector("list", ncol(tab)), names(tab))
for (nm in names(tab)) {
if (nm == "dim") {
sum_row[[nm]] <- label
} else if (is.numeric(tab[[nm]])) {
sum_row[[nm]] <- sum(tab[[nm]], na.rm = TRUE)
} else {
sum_row[[nm]] <- NA
}
}
rbind(tab, as.data.frame(sum_row, stringsAsFactors = FALSE))
}
prepare_data <- function(n, config, seed = 42) {
X <- Generate_iid_from_config(n, config)
S <- split_data(X, seed)
list(X = X, S = S)
}
fit_models <- function(S, config) {
M_TRUE <- fit_TRUE(S, config)
t_true <- system.time({
ll_true <- logL_TRUE_dim(M_TRUE, S$X_te)
})[["elapsed"]]
M_TRTF <- fit_TRTF(S, config)
t_trtf <- system.time({
ll_trtf <- logL_TRTF_dim(M_TRTF, S$X_te)
})[["elapsed"]]
M_TTM_cross <- trainCrossTermMap(S)
t_ttm_cross <- system.time({
ll_ttm_cross <- -predict(M_TTM_cross$S, S$X_te, type = "logdensity_by_dim")
})[["elapsed"]]
list(models = list(true = M_TRUE, trtf = M_TRTF,
ttm_cross = M_TTM_cross),
ll = list(true = ll_true, trtf = ll_trtf,
ttm_cross = ll_ttm_cross),
times = c(true = t_true, trtf = t_trtf,
ttm_cross = t_ttm_cross))
}
calc_loglik_tables <- function(models, config, X_te) {
K <- length(config)
ll_true <- matrix(NA_real_, nrow = nrow(X_te), ncol = K)
for (k in seq_len(K)) {
ll_vec <- .log_density_vec(X_te[, k], config[[k]]$distr,
models$true$theta[[k]])
ll_true[, k] <- -ll_vec
}
ll_trtf <- -predict(models$trtf, X_te, type = "logdensity_by_dim")
ll_true_joint <- - true_joint_logdensity_by_dim(config, X_te)
if (!is.null(models$ttm)) {
ll_ttm <- -predict(models$ttm$S, X_te, type = "logdensity_by_dim")
mean_ttm <- colMeans(ll_ttm)
se_ttm   <- apply(ll_ttm, 2, stderr)
total_nll_ttm <- rowSums(ll_ttm)
se_sum_ttm <- stats::sd(total_nll_ttm) / sqrt(length(total_nll_ttm))
} else {
mean_ttm <- rep(NA_real_, K)
se_ttm   <- rep(NA_real_, K)
se_sum_ttm <- NA_real_
}
if (!is.null(models$ttm_sep)) {
ll_ttm_sep <- -predict(models$ttm_sep$S, X_te, type = "logdensity_by_dim")
mean_sep <- colMeans(ll_ttm_sep)
se_sep   <- apply(ll_ttm_sep, 2, stderr)
total_nll_sep <- rowSums(ll_ttm_sep)
se_sum_sep <- stats::sd(total_nll_sep) / sqrt(length(total_nll_sep))
} else {
mean_sep <- rep(NA_real_, K)
se_sep   <- rep(NA_real_, K)
se_sum_sep <- NA_real_
}
if (!is.null(models$ttm_cross)) {
ll_ttm_cross <- -predict(models$ttm_cross$S, X_te,
type = "logdensity_by_dim")
mean_cross <- colMeans(ll_ttm_cross)
se_cross   <- apply(ll_ttm_cross, 2, stderr)
total_nll_cross <- rowSums(ll_ttm_cross)
se_sum_cross <- stats::sd(total_nll_cross) / sqrt(length(total_nll_cross))
} else {
mean_cross <- rep(NA_real_, K)
se_cross   <- rep(NA_real_, K)
se_sum_cross <- NA_real_
}
mean_true <- colMeans(ll_true)
se_true   <- apply(ll_true, 2, stderr)
total_nll_true <- rowSums(ll_true)
se_sum_true <- stats::sd(total_nll_true) / sqrt(length(total_nll_true))
mean_true_joint <- colMeans(ll_true_joint)
se_true_joint   <- apply(ll_true_joint, 2, stderr)
total_nll_true_joint <- rowSums(ll_true_joint)
se_sum_true_joint <- stats::sd(total_nll_true_joint) /
sqrt(length(total_nll_true_joint))
mean_trtf <- colMeans(ll_trtf)
se_trtf   <- apply(ll_trtf, 2, stderr)
total_nll_trtf <- rowSums(ll_trtf)
se_sum_trtf <- stats::sd(total_nll_trtf) / sqrt(length(total_nll_trtf))
fmt <- function(m, se) sprintf("%.2f Â± %.2f", round(m, 2), round(2 * se, 2))
tab <- data.frame(
dim = as.character(seq_len(K)),
distribution = sapply(config, `[[`, "distr"),
true = fmt(mean_true, se_true),
true_joint = fmt(mean_true_joint, se_true_joint),
trtf = fmt(mean_trtf, se_trtf),
ttm  = fmt(mean_ttm, se_ttm),
ttm_sep = fmt(mean_sep, se_sep),
ttm_cross = fmt(mean_cross, se_cross),
stringsAsFactors = FALSE
)
sum_row <- data.frame(
dim = "k",
distribution = "SUM",
true = fmt(sum(mean_true), se_sum_true),
true_joint = fmt(sum(mean_true_joint), se_sum_true_joint),
trtf = fmt(sum(mean_trtf), se_sum_trtf),
ttm  = fmt(sum(mean_ttm),  se_sum_ttm),
ttm_sep = fmt(sum(mean_sep),  se_sum_sep),
ttm_cross = fmt(sum(mean_cross), se_sum_cross),
stringsAsFactors = FALSE
)
tab <- rbind(tab, sum_row)
nm <- names(tab)
nm[nm == "true"] <- "True (marginal)"
nm[nm == "true_joint"] <- "True (Joint)"
nm[nm == "trtf"] <- "Random Forest"
nm[nm == "ttm"]  <- "Marginal Map"
nm[nm == "ttm_sep"] <- "Separable Map"
nm[nm == "ttm_cross"] <- "Cross-term Map"
names(tab) <- nm
message("Ergebnis (NLL in nats; lower is better)")
tab
}
eval_halfmoon <- function(mods, S, out_csv_path = NULL) {
dir.create("results", showWarnings = FALSE)
N <- nrow(S$X_te)
K <- ncol(S$X_te)
need <- c("true", "trtf", "ttm", "ttm_sep", "ttm_cross")
config_moon <- list(list(distr = "norm"), list(distr = "norm"))
if (missing(mods) || length(mods) == 0 || !all(need %in% names(mods))) {
seed <- if (!is.null(S$meta$seed)) as.integer(S$meta$seed) else 42L
set.seed(seed)
mods <- list(
true = fit_TRUE(S, config_moon),
trtf = fit_TRTF(S, config_moon, seed = seed),
ttm = trainMarginalMap(S, seed = seed)$S,
ttm_sep = trainSeparableMap(S, seed = seed)$S,
ttm_cross = trainCrossTermMap(S, seed = seed)$S
)
}
rows <- list()
for (m in need) {
mod <- mods[[m]]
if (m == "true") {
cfg <- mod$config
LD <- do.call(cbind, lapply(seq_len(K), function(k)
.log_density_vec(S$X_te[, k], cfg[[k]]$distr, mod$theta[[k]])))
} else {
LD <- predict(mod, S$X_te, "logdensity_by_dim")
}
stopifnot(is.matrix(LD), all(dim(LD) == c(N, K)), all(is.finite(LD)))
if (m == "true") {
LDj <- rowSums(LD)
} else {
LDj_try <- try(predict(mod, S$X_te, "logdensity"), silent = TRUE)
LDj <- if (inherits(LDj_try, "try-error")) rowSums(LD) else as.numeric(LDj_try)
}
stopifnot(length(LDj) == N, all(is.finite(LDj)),
max(abs(rowSums(LD) - LDj)) < 1e-10)
nllj <- -LDj
per <- -colMeans(LD)
se <- stats::sd(nllj) / sqrt(N)
rows[[length(rows) + 1]] <- c(
list(model = m, mean_joint_nll = mean(nllj), se_joint = se),
setNames(as.list(per), paste0("per_dim_nll_", 1:K))
)
}
df <- do.call(rbind, lapply(rows, as.data.frame, stringsAsFactors = FALSE))
path <- if (is.null(out_csv_path))
sprintf("results/nll_halfmoon_seed%03d.csv", as.integer(S$meta$seed))
else out_csv_path
write.csv(df, path, row.names = FALSE)
print(df)
results_table <<- df
df
}
### End 04_evaluation.R ###

### Begin main.R ###
source("00_globals.R")
if (!exists("%||%")) "%||%" <- function(a, b) if (is.null(a)) b else a
source("01_data_generation.R")
source("02_split.R")
source("scripts/halfmoon_data.R")
source("models/true_model.R")
source("models/trtf_model.R")
source("models/ttm_marginal.R")
source("models/ttm_separable.R")
source("models/ttm_cross_term.R")
source("models/true_joint_model.R")
source("04_evaluation.R")
source("replicate_code.R")
perm <- c(1, 2, 3, 4)
n <- 50
config <- list(
list(distr = "norm", parm = NULL),
list(distr = "exp",  parm = function(d) list(rate = softplus(d$X1))),
list(distr = "beta",
parm = function(d) list(shape1 = softplus(d$X2),
shape2 = softplus(d$X1))),
list(distr = "gamma",
parm = function(d) list(shape = softplus(d$X3),
scale = softplus(d$X2)))
)
main <- function() {
dataset <- Sys.getenv("DATASET", "config4d")
seed <- as.integer(Sys.getenv("SEED", 42))
set.seed(seed)
if (dataset == "halfmoon2d") {
ntr <- pmin(as.integer(Sys.getenv("N_TRAIN", 250)), 250)
nte <- pmin(as.integer(Sys.getenv("N_TEST", 250)), 250)
noise <- as.numeric(Sys.getenv("NOISE", 0.15))
S <- make_halfmoon_splits(ntr, nte, noise, seed)
S$meta$dataset <- dataset
dir.create("results", showWarnings = FALSE)
saveRDS(S, sprintf("results/splits_%s_seed%03d.rds", dataset, seed))
cat(sprintf("[DATASET %s] K=%d | n_tr=%d (val=%d) | n_te=%d | noise=%.3f | seed=%d\n",
dataset, ncol(S$X_tr), nrow(S$X_tr), nrow(S$X_val),
nrow(S$X_te), noise, seed))
df <- eval_halfmoon(S = S)
assign("results_table", df, envir = .GlobalEnv)
return(df)
}
prep <- prepare_data(n, config, seed = seed)
S0 <- prep$S
S <- list(
X_tr  = S0$X_tr[, perm, drop = FALSE],
X_val = S0$X_val[, perm, drop = FALSE],
X_te  = S0$X_te[, perm, drop = FALSE]
)
cfg <- config[perm]
t_true_tr  <- system.time(mod_true      <- fit_TRUE(S, cfg))[['elapsed']]
t_joint_tr <- 0
mod_true_joint <- fit_TRUE_JOINT(S, cfg)
t_trtf_tr  <- system.time(mod_trtf      <- fit_TRTF(S, cfg, seed = seed))[['elapsed']]
mod_ttm     <- trainMarginalMap(S, seed = seed);  t_ttm_tr <- mod_ttm$time_train
mod_ttm_sep <- trainSeparableMap(S, seed = seed); t_sep_tr <- mod_ttm_sep$time_train
mod_ttm_cross <- trainCrossTermMap(S, seed = seed); t_ct_tr <- mod_ttm_cross$time_train
t_true_te  <- system.time(logL_TRUE(mod_true, S$X_te))[['elapsed']]
t_joint_te <- system.time(true_joint_logdensity_by_dim(cfg, S$X_te))[['elapsed']]
t_trtf_te  <- system.time(predict(mod_trtf, S$X_te, type = "logdensity_by_dim"))[['elapsed']]
t_ttm_te   <- mod_ttm$time_pred
t_sep_te   <- mod_ttm_sep$time_pred
t_ct_te    <- mod_ttm_cross$time_pred
mods <- list(
true = mod_true,
true_joint = mod_true_joint,
trtf = mod_trtf,
ttm  = mod_ttm,
ttm_sep = mod_ttm_sep,
ttm_cross = mod_ttm_cross
)
tab <- calc_loglik_tables(mods, cfg, S$X_te)
cat(sprintf("n=%d\n", n))
print(tab)
cat(sprintf("Permutation order %s\n", paste(perm, collapse = ",")))
time_tab <- data.frame(
model = c("True (marginal)", "True (Joint)", "Random Forest",
"Marginal Map", "Separable Map", "Cross-term Map"),
train_sec = c(t_true_tr, t_joint_tr, t_trtf_tr,
t_ttm_tr, t_sep_tr, t_ct_tr),
test_sec = c(t_true_te, t_joint_te, t_trtf_te,
t_ttm_te, t_sep_te, t_ct_te),
stringsAsFactors = FALSE
)
time_tab$total_sec <- with(time_tab, train_sec + test_sec)
stopifnot(all.equal(time_tab$total_sec,
time_tab$train_sec + time_tab$test_sec))
print(time_tab)
timing_table <<- time_tab
results_table <<- tab
stopifnot(identical(results_table, tab))
return(tab)
}
if (sys.nframe() == 0L) {
main()
replicate_code_scripts("main.R", "replicated_code.txt", env = globalenv())
}
### End main.R ###

### Final results table ###
      model mean_joint_nll   se_joint per_dim_nll_1 per_dim_nll_2
1      true       2.015435 0.03952443      1.315586     0.6998488
2      trtf       1.773099 0.04477884      1.261374     0.5117247
3       ttm       2.024118 0.03678561      1.313244     0.7108738
4   ttm_sep       1.978473 0.04581926      1.315586     0.6628871
5 ttm_cross       1.923089 0.04957322      1.307709     0.6153796

Permutation order 1,2,3,4

