### Begin 00_globals.R ###
library(dplyr)
library(parallel)
library(tram)
library(trtf)
if (!exists("NC")) NC <- detectCores()
options(mc.cores = NC)
softplus <- function(x) log1p(exp(x))
### End 00_globals.R ###

### Begin 01_data_generation.R ###
Generate_iid_from_config <- function(N, cfg, return_params = FALSE) {
stopifnot(is.numeric(N), N > 0, is.list(cfg))
K <- length(cfg)
X <- matrix(NA_real_, nrow = N, ncol = K)
if (return_params) {
param_hist <- vector("list", K)
for (kk in seq_len(K))
param_hist[[kk]] <- vector("list", N)
}
for (i in seq_len(N)) {
for (k in seq_len(K)) {
c_k <- cfg[[k]]
if (is.null(c_k$parm)) {
args <- list()
} else {
if (k == 1) {
prev <- data.frame()
} else {
prev <- as.data.frame(as.list(X[i, seq_len(k - 1)]))
names(prev) <- paste0("X", seq_len(k - 1))
}
args <- c_k$parm(prev)
}
fun <- get(paste0("r", c_k$distr), mode = "function")
if (c_k$distr == "gamma" &&
all(c("shape1", "shape2") %in% names(args))) {
args <- list(shape = args$shape1, scale = args$shape2)
}
args <- lapply(args, function(p) {
if (!is.finite(p) || p <= 0) 1e-3 else p
})
if (return_params) param_hist[[k]][[i]] <- args
X[i, k] <- do.call(fun, c(list(n = 1L), args))
}
}
colnames(X) <- paste0("X", seq_len(K))
if (return_params) {
param_df <- lapply(param_hist, function(lst) {
vals <- lapply(lst, function(x) if (length(x) == 0) NULL else as.data.frame(x))
vals <- Filter(Negate(is.null), vals)
if (length(vals) == 0) return(NULL)
df <- do.call(rbind, vals)
rownames(df) <- NULL
df
})
list(X = X, params = param_df)
} else {
X
}
}
gen_samples <- function(G, return_params = FALSE) {
Generate_iid_from_config(G$n, G$config, return_params = return_params)
}
### End 01_data_generation.R ###

### Begin 02_split.R ###
SplitStruct <- function(X_tr, X_val, X_te) {
list(X_tr = X_tr, X_val = X_val, X_te = X_te)
}
split_data <- function(X, seed) {
stopifnot(is.matrix(X))
N <- nrow(X)
set.seed(seed)
idx <- sample.int(N)
n_tr  <- floor(0.8 * N)
n_val <- floor(0.1 * N)
idx_tr  <- idx[seq_len(n_tr)]
idx_val <- idx[seq_len(n_val) + n_tr]
idx_te  <- idx[(n_tr + n_val + 1):N]
SplitStruct(
X[idx_tr , , drop = FALSE],
X[idx_val, , drop = FALSE],
X[idx_te , , drop = FALSE]
)
}
### End 02_split.R ###

### Begin models/true_model.R ###
neg_loglik_uni <- function(par, x, distr) {
if (distr == "norm") {
mu <- par[1]; sd <- par[2]
if (sd <= 0) return(Inf)
-sum(dnorm(x, mean = mu, sd = sd, log = TRUE))
} else if (distr == "exp") {
rate <- par[1]
if (rate <= 0) return(Inf)
x <- pmax(x, 1e-6)
-sum(dexp(x, rate = rate, log = TRUE))
} else if (distr == "beta") {
a <- par[1]; b <- par[2]
if (a <= 0 || b <= 0) return(Inf)
x <- pmin(pmax(x, 1e-6), 1 - 1e-6)
-sum(dbeta(x, shape1 = a, shape2 = b, log = TRUE))
} else if (distr == "gamma") {
shape <- par[1]; scale <- par[2]
if (shape <= 0 || scale <= 0) return(Inf)
x <- pmax(x, 1e-6)
-sum(dgamma(x, shape = shape, scale = scale, log = TRUE))
} else {
stop("Unsupported distribution")
}
}
.log_density_vec <- function(x, distr, par) {
if (distr == "norm") {
dnorm(x, mean = par[1], sd = par[2], log = TRUE)
} else if (distr == "exp") {
x <- pmax(x, 1e-6)
dexp(x, rate = par[1], log = TRUE)
} else if (distr == "beta") {
x <- pmin(pmax(x, 1e-6), 1 - 1e-6)
dbeta(x, shape1 = par[1], shape2 = par[2], log = TRUE)
} else if (distr == "gamma") {
x <- pmax(x, 1e-6)
dgamma(x, shape = par[1], scale = par[2], log = TRUE)
} else {
stop("Unsupported distribution")
}
}
.start_par <- function(x, distr) {
if (distr == "norm") {
c(mean(x), sd(x))
} else if (distr == "exp") {
c(1 / mean(x))
} else if (distr == "beta") {
m <- mean(x); v <- var(x)
common <- m * (1 - m) / v - 1
a <- m * common; b <- (1 - m) * common
if (!is.finite(a) || a <= 0) a <- 1
if (!is.finite(b) || b <= 0) b <- 1
c(a, b)
} else if (distr == "gamma") {
m <- mean(x); v <- var(x)
shape <- m^2 / v; scale <- v / m
if (!is.finite(shape) || shape <= 0) shape <- 1
if (!is.finite(scale) || scale <= 0) scale <- 1
c(shape, scale)
} else {
stop("Unsupported distribution")
}
}
fit_TRUE <- function(S, config, cores = NC) {
stopifnot(is.list(S))
X_tr  <- S$X_tr
X_val <- S$X_val
X_te  <- S$X_te
stopifnot(is.matrix(X_tr), is.matrix(X_te))
K <- length(config)
theta_list <- parallel::mclapply(seq_len(K), function(k) {
distr_k <- config[[k]]$distr
x_k <- X_tr[, k]
init <- .start_par(x_k, distr_k)
opt <- optim(
par = init,
fn = neg_loglik_uni,
x = x_k,
distr = distr_k,
method = "L-BFGS-B",
lower = rep(1e-6, length(init))
)
opt$par
}, mc.cores = cores)
model <- list(theta = theta_list, config = config)
logL_te <- logL_TRUE(model, X_te)
model$logL_te <- logL_te
model
}
logL_TRUE <- function(M_TRUE, X, cores = NC) {
stopifnot(is.matrix(X))
theta_list <- M_TRUE$theta
config <- M_TRUE$config
K <- length(theta_list)
ll_list <- parallel::mclapply(seq_len(K), function(k) {
distr_k <- config[[k]]$distr
.log_density_vec(X[, k], distr_k, theta_list[[k]])
}, mc.cores = cores)
ll <- do.call(cbind, ll_list)
val <- -mean(rowSums(ll))
if (!is.finite(val)) stop("log-likelihood not finite")
val
}
logL_TRUE_dim <- function(M_TRUE, X, cores = NC) {
stopifnot(is.matrix(X))
theta_list <- M_TRUE$theta
config <- M_TRUE$config
K <- length(theta_list)
res <- parallel::mclapply(seq_len(K), function(k) {
distr_k <- config[[k]]$distr
ll_k <- .log_density_vec(X[, k], distr_k, theta_list[[k]])
val <- -mean(ll_k)
if (!is.finite(val)) stop("log-likelihood not finite")
val
}, mc.cores = cores)
unlist(res)
}
### End models/true_model.R ###

### Begin models/trtf_model.R ###
p <- list(
minsplit = 40,
minbucket = 5,
maxdepth = 2,
seed = 42
)
mytrtf <- function(data, ntree, minsplit, minbucket, maxdepth, seed, cores = NC) {
stopifnot(is.matrix(data))
set.seed(seed)
K <- ncol(data)
df <- as.data.frame(data)
names(df) <- paste0("X", seq_len(K))
ymod <- lapply(names(df), function(y) {
BoxCox(as.formula(paste(y, "~ 1")), data = df)
})
forests <- vector("list", K - 1L)
ctrl <- partykit::ctree_control(minsplit = minsplit,
minbucket = minbucket,
maxdepth = maxdepth)
for (k in 2:K) {
rhs <- paste(names(df)[1:(k - 1)], collapse = "+")
fm <- as.formula(paste(names(df)[k], "~", rhs))
current_mtry <- max(1, floor((k - 1) / 2))
forests[[k - 1L]] <- traforest(ymod[[k]], formula = fm, data = df,
trace = TRUE, ntree = ntree,
mltargs = list(), mtry = current_mtry,
cores = cores, control = ctrl)
}
res <- list(ymod = ymod, forests = forests, seed = seed,
varimp = lapply(forests, varimp))
class(res) <- "mytrtf"
res
}
predict.mytrtf <- function(object, newdata,
type = c("logdensity", "logdensity_by_dim"),
cores = NC, trace = TRUE) {
type <- match.arg(type)
stopifnot(inherits(object, "mytrtf"), is.matrix(newdata))
K <- length(object$ymod)
df_new <- as.data.frame(newdata)
names(df_new) <- paste0("X", seq_len(K))
ld1 <- predict(object$ymod[[1]], newdata = df_new, type = "logdensity")
ld_rest <- lapply(seq_along(object$forests), function(j) {
fr <- object$forests[[j]]
q <- df_new[, variable.names(fr$model)[1]]
pr <- predict(fr, newdata = df_new, type = "logdensity", q = q,
cores = cores, trace = trace)
diag(do.call(cbind, pr))
})
ll <- cbind(ld1, do.call(cbind, ld_rest))
if (type == "logdensity_by_dim") return(ll)
rowSums(ll)
}
logL_TRTF <- function(model, X, cores = NC) {
val <- -mean(predict(model, X, type = "logdensity",
cores = cores, trace = TRUE))
if (!is.finite(val)) stop("log-likelihood not finite")
val
}
logL_TRTF_dim <- function(model, X, cores = NC) {
ll <- predict(model, X, type = "logdensity_by_dim",
cores = cores, trace = TRUE)
res <- -colMeans(ll)
if (!all(is.finite(res))) stop("log-likelihood not finite")
res
}
fit_TRTF <- function(S, config, seed = NULL, cores = NC) {
stopifnot(is.list(S))
X_tr <- S$X_tr
X_te <- S$X_te
stopifnot(is.matrix(X_tr), is.matrix(X_te))
if (!is.null(seed)) set.seed(seed)
mod <- mytrtf(data = X_tr,
ntree = nrow(X_tr),
minsplit = p$minsplit,
minbucket = p$minbucket,
maxdepth = p$maxdepth,
seed = seed,
cores = cores)
mod$config  <- config
logL_te_dim <- logL_TRTF_dim(mod, S$X_te, cores = cores)
mod$logL_te_dim <- logL_te_dim
mod$logL_te <- sum(logL_te_dim)
mod
}
### End models/trtf_model.R ###

### Begin models/ks_model.R ###
.log_sum_exp <- function(x) {
m <- max(x)
m + log(sum(exp(x - m)))
}
fit_KS <- function(S, config, seed = 42) {
stopifnot(is.list(S))
X_tr  <- S$X_tr
X_val <- S$X_val
X_te  <- S$X_te
stopifnot(is.matrix(X_tr), is.matrix(X_val), is.matrix(X_te))
set.seed(seed)
h <- apply(rbind(X_tr, X_val), 2, stats::bw.nrd0)
model <- list(X_tr = X_tr, h = h, config = config, seed = seed)
class(model) <- "ks_model"
model$logL_te <- logL_KS(model, X_te)
model
}
predict.ks_model <- function(object, newdata,
type = c("logdensity", "logdensity_by_dim"),
cores = NC) {
type <- match.arg(type)
X_tr <- object$X_tr
h <- object$h
stopifnot(is.matrix(newdata))
K <- ncol(X_tr)
n <- nrow(newdata)
ll_list <- parallel::mclapply(seq_len(n), function(i) {
x <- newdata[i, ]
logkern <- vapply(seq_len(K), function(r) {
dnorm((x[r] - X_tr[, r]) / h[r], log = TRUE) - log(h[r])
}, numeric(nrow(X_tr)))
cumsums <- t(apply(logkern, 1, cumsum))
log_g <- apply(cumsums, 2, function(v) .log_sum_exp(v) - log(nrow(X_tr)))
ll_i <- numeric(K)
ll_i[1] <- log_g[1]
if (K > 1) {
ll_i[2:K] <- diff(log_g)
}
ll_i
}, mc.cores = cores)
ll <- do.call(rbind, ll_list)
if (type == "logdensity_by_dim") return(ll)
rowSums(ll)
}
logL_KS <- function(model, X, cores = NC) {
val <- -mean(predict(model, X, type = "logdensity", cores = cores))
if (!is.finite(val)) stop("log-likelihood not finite")
val
}
logL_KS_dim <- function(model, X, cores = NC) {
ll <- predict(model, X, type = "logdensity_by_dim", cores = cores)
res <- -colMeans(ll)
if (!all(is.finite(res))) stop("log-likelihood not finite")
res
}
### End models/ks_model.R ###

### Begin models/ttm_marginal.R ###
.standardizeData <- function(X) {
mu <- colMeans(X)
sigma <- apply(X, 2, sd) + .Machine$double.eps
X_tilde <- sweep(X, 2, mu, "-")
X_tilde <- sweep(X_tilde, 2, sigma, "/")
list(X = X_tilde, mu = mu, sigma = sigma)
}
.forward_matrix <- function(S, X) {
Xs <- .standardize(S, X)
b <- exp(S$coeffA)
Z <- sweep(Xs, 2, b, "*")
sweep(Z, 2, S$coeffB, "+")
}
.logjac_const <- function(S) {
b <- exp(S$coeffA)
log(b) - log(S$sigma)
}
.standardize <- function(S, X) {
X <- sweep(X, 2, S$mu, "-")
sweep(X, 2, S$sigma, "/")
}
trainMarginalMap <- function(X_or_path) {
set.seed(42)
S_in <- if (is.character(X_or_path)) readRDS(X_or_path) else X_or_path
stopifnot(is.list(S_in))
X_tr <- S_in$X_tr
X_val <- S_in$X_val
X_te  <- S_in$X_te
time_train <- system.time({
std <- .standardizeData(X_tr)
X_tr_std <- std$X
mu <- std$mu
sigma <- std$sigma
K <- ncol(X_tr_std)
coeffA <- numeric(K)
coeffB <- numeric(K)
for (k in seq_len(K)) {
xk <- X_tr_std[, k]
N <- length(xk)
u <- rank(xk, ties.method = "average") / (N + 1)
lower <- 1 / (N + 1)
upper <- N / (N + 1)
u <- pmin(pmax(u, lower), upper)
z_star <- qnorm(u)
covxz <- mean((xk - mean(xk)) * (z_star - mean(z_star)))
varx <- var(xk) + 1e-12
b_k <- max(0, covxz / varx)
a_k <- mean(z_star) - b_k * mean(xk)
coeffA[k] <- log(b_k + 1e-12)
coeffB[k] <- a_k
}
coeffC <- rep(0, K)
S_map <- list(
mu = mu,
sigma = sigma,
coeffA = coeffA,
coeffB = coeffB,
coeffC = coeffC,
order = seq_len(K)
)
class(S_map) <- "ttm_marginal"
})[["elapsed"]]
time_pred <- system.time({
predict(S_map, X_te, "logdensity_by_dim")
})[["elapsed"]]
list(
S = S_map,
NLL_train = NLL_set(S_map, X_tr),
NLL_val = NLL_set(S_map, X_val),
NLL_test = NLL_set(S_map, X_te),
stderr_test = SE_set(S_map, X_te),
time_train = time_train,
time_pred = time_pred
)
}
predict.ttm_marginal <- function(object, newdata,
type = c("logdensity_by_dim", "logdensity")) {
type <- tryCatch(match.arg(type), error = function(e) stop("unknown type"))
Z <- .forward_matrix(object, newdata)
LJ <- .logjac_const(object)
C <- -0.5 * log(2 * pi)
LD <- (-0.5) * (Z^2) + C +
matrix(LJ, nrow = nrow(Z), ncol = length(LJ), byrow = TRUE)
if (type == "logdensity_by_dim") {
LD
} else {
rowSums(LD)
}
}
NLL_set <- function(S, X) {
mean(-rowSums(predict(S, X, "logdensity_by_dim")))
}
SE_set <- function(S, X) {
v <- rowSums(-predict(S, X, "logdensity_by_dim"))
stats::sd(v) / sqrt(length(v))
}
forwardPass <- function(S, x) {
x_std <- .standardize(S, matrix(x, nrow = 1))
b <- exp(S$coeffA)
a <- S$coeffB
as.numeric(a + b * x_std)
}
logJacDiag <- function(S, x) {
LJ <- .logjac_const(S)
rep(LJ, length.out = length(x))
}
forwardKLLoss <- function(S, X) {
Z <- .forward_matrix(S, X)
LJ <- .logjac_const(S)
mean(0.5 * rowSums(Z^2) - sum(LJ))
}
inversePass <- function(S, z) {
b <- exp(S$coeffA)
a <- S$coeffB
x_std <- (z - a) / b
x <- sweep(x_std, 2, S$sigma, "*")
x <- sweep(x, 2, S$mu, "+")
as.numeric(x)
}
negativeLogLikelihood <- function(S, X) {
Z <- .forward_matrix(S, X)
LJ <- .logjac_const(S)
sum(0.5 * rowSums(Z^2) - sum(LJ))
}
natsPerDim <- function(NLL, N, K) {
NLL / (N * K)
}
stderr <- function(v) {
stats::sd(v) / sqrt(length(v))
}
### End models/ttm_marginal.R ###

### Begin models/ttm_separable.R ###
if (!exists(".standardizeData")) {
.standardizeData <- function(X) {
mu <- colMeans(X)
sigma <- apply(X, 2, sd) + .Machine$double.eps
X_tilde <- sweep(X, 2, mu, "-")
X_tilde <- sweep(X_tilde, 2, sigma, "/")
list(X = X_tilde, mu = mu, sigma = sigma)
}
}
if (!exists(".standardize")) {
.standardize <- function(S, X) {
X <- sweep(X, 2, S$mu, "-")
sweep(X, 2, S$sigma, "/")
}
}
erf <- function(x) 2 * pnorm(x * sqrt(2)) - 1
basis_f <- function(x) cbind(x, erf(x))
dbasis_f <- function(x) {
cbind(rep(1, length(x)), 2 / sqrt(pi) * exp(-x^2))
}
basis_g <- function(X, deg) {
if (ncol(X) == 0L) {
return(matrix(0, nrow = nrow(X), ncol = 0))
}
N <- nrow(X)
out <- matrix(1, N, 1)
for (j in seq_len(ncol(X))) {
xj <- X[, j]
for (d in seq_len(deg)) {
out <- cbind(out, xj^d)
}
}
out
}
trainSeparableMap <- function(X_or_path, degree_g = 2, lambda = 1e-3, eps = 1e-6) {
set.seed(42)
S_in <- if (is.character(X_or_path)) readRDS(X_or_path) else X_or_path
stopifnot(is.list(S_in))
X_tr <- S_in$X_tr
X_val <- S_in$X_val
X_te  <- S_in$X_te
time_train <- system.time({
std <- .standardizeData(X_tr)
X_tr_std <- std$X
mu <- std$mu
sigma <- std$sigma
K <- ncol(X_tr_std)
coeffs <- vector("list", K)
N <- nrow(X_tr_std)
for (k in seq_len(K)) {
x_prev <- if (k > 1) X_tr_std[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
xk <- X_tr_std[, k]
P_non <- if (k > 1) basis_g(x_prev, degree_g) else matrix(0, N, 0)
P_mon <- basis_f(xk)
B <- dbasis_f(xk)
stopifnot(nrow(P_mon) == N, nrow(P_non) == N, nrow(B) == N)
m_non <- ncol(P_non)
m_mon <- ncol(P_mon)
if (m_non > 0) {
M <- solve(crossprod(P_non) + lambda * diag(m_non), t(P_non))
A <- (diag(N) - P_non %*% M) %*% P_mon
D <- M %*% P_mon
} else {
M <- matrix(0, 0, N)
A <- P_mon
D <- matrix(0, 0, m_mon)
}
fn <- function(c) {
r <- A %*% c
Bc <- B %*% c
if (any(Bc <= 0)) return(Inf)
q <- D %*% c
0.5 * sum(r^2) - sum(log(Bc)) + (lambda / 2) * (sum(q^2) + sum(c^2))
}
gr <- function(c) {
r <- A %*% c
Bc <- B %*% c
q <- D %*% c
as.numeric(t(A) %*% r - t(B) %*% (1 / Bc) + lambda * (t(D) %*% q + c))
}
c0 <- rep(1, m_mon)
opt <- optim(c0, fn, gr, method = "L-BFGS-B", lower = rep(eps, m_mon))
c_mon <- opt$par
c_non <- if (m_non > 0) -M %*% (P_mon %*% c_mon) else numeric(0)
coeffs[[k]] <- list(c_non = c_non, c_mon = c_mon)
}
S_map <- list(
mu = mu,
sigma = sigma,
coeffs = coeffs,
degree_g = degree_g,
order = seq_len(K)
)
class(S_map) <- "ttm_separable"
})[["elapsed"]]
time_pred <- system.time({
predict(S_map, X_te, "logdensity_by_dim")
})[["elapsed"]]
list(
S = S_map,
NLL_train = NLL_set(S_map, X_tr),
NLL_val = NLL_set(S_map, X_val),
NLL_test = NLL_set(S_map, X_te),
stderr_test = SE_set(S_map, X_te),
time_train = time_train,
time_pred = time_pred
)
}
predict.ttm_separable <- function(object, newdata,
type = c("logdensity_by_dim", "logdensity")) {
type <- tryCatch(match.arg(type), error = function(e) stop("unknown type"))
Xs <- .standardize(object, newdata)
N <- nrow(Xs)
K <- ncol(Xs)
Z <- matrix(0, N, K)
LJ <- matrix(0, N, K)
for (k in seq_len(K)) {
x_prev <- if (k > 1) Xs[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
xk <- Xs[, k]
P_non <- if (k > 1) basis_g(x_prev, object$degree_g) else matrix(0, N, 0)
P_mon <- basis_f(xk)
B <- dbasis_f(xk)
c_non <- object$coeffs[[k]]$c_non
c_mon <- object$coeffs[[k]]$c_mon
gk <- if (ncol(P_non) > 0) as.numeric(P_non %*% c_non) else rep(0, N)
fk <- as.numeric(P_mon %*% c_mon)
Z[, k] <- gk + fk
deriv <- (B %*% c_mon) / object$sigma[k]
LJ[, k] <- log(as.numeric(deriv))
}
C <- -0.5 * log(2 * pi)
LD <- (-0.5) * (Z^2) + C + LJ
if (type == "logdensity_by_dim") {
LD
} else {
rowSums(LD)
}
}
NLL_set <- function(S, X) {
mean(-rowSums(predict(S, X, "logdensity_by_dim")))
}
SE_set <- function(S, X) {
v <- rowSums(-predict(S, X, "logdensity_by_dim"))
stats::sd(v) / sqrt(length(v))
}
### End models/ttm_separable.R ###

### Begin 04_evaluation.R ###
root_path <- getwd()
if (basename(root_path) == "testthat") {
root_path <- dirname(dirname(root_path))
}
source(file.path(root_path, "models/ttm_marginal.R"))
source(file.path(root_path, "models/ttm_separable.R"))
source(file.path(root_path, "models/ks_model.R"))
source(file.path(root_path, "models/ttm_cross_term.R"))
add_sum_row <- function(tab, label = "k") {
stopifnot(is.data.frame(tab))
sum_row <- setNames(vector("list", ncol(tab)), names(tab))
for (nm in names(tab)) {
if (nm == "dim") {
sum_row[[nm]] <- label
} else if (is.numeric(tab[[nm]])) {
sum_row[[nm]] <- sum(tab[[nm]])
} else {
sum_row[[nm]] <- NA
}
}
rbind(tab, as.data.frame(sum_row, stringsAsFactors = FALSE))
}
prepare_data <- function(n, config, seed = 42) {
X <- Generate_iid_from_config(n, config)
S <- split_data(X, seed)
list(X = X, S = S)
}
fit_models <- function(S, config) {
M_TRUE <- fit_TRUE(S, config)
t_true <- system.time({
ll_true <- logL_TRUE_dim(M_TRUE, S$X_te)
})[["elapsed"]]
M_TRTF <- fit_TRTF(S, config)
t_trtf <- system.time({
ll_trtf <- logL_TRTF_dim(M_TRTF, S$X_te)
})[["elapsed"]]
M_KS <- fit_KS(S, config)
t_ks <- system.time({
ll_ks <- logL_KS_dim(M_KS, S$X_te)
})[["elapsed"]]
M_TTM_cross <- trainCrossTermMap(S)
t_ttm_cross <- system.time({
ll_ttm_cross <- -predict(M_TTM_cross$S, S$X_te, type = "logdensity_by_dim")
})[["elapsed"]]
list(models = list(true = M_TRUE, trtf = M_TRTF, ks = M_KS,
ttm_cross = M_TTM_cross),
ll = list(true = ll_true, trtf = ll_trtf, ks = ll_ks,
ttm_cross = ll_ttm_cross),
times = c(true = t_true, trtf = t_trtf, ks = t_ks,
ttm_cross = t_ttm_cross))
}
calc_loglik_tables <- function(models, config, X_te) {
K <- length(config)
ll_true <- matrix(NA_real_, nrow = nrow(X_te), ncol = K)
for (k in seq_len(K)) {
ll_vec <- .log_density_vec(X_te[, k], config[[k]]$distr,
models$true$theta[[k]])
ll_true[, k] <- -ll_vec
}
ll_trtf <- -predict(models$trtf, X_te, type = "logdensity_by_dim")
ll_ks   <- -predict(models$ks,  X_te, type = "logdensity_by_dim")
if (!is.null(models$ttm)) {
ll_ttm <- -predict(models$ttm$S, X_te, type = "logdensity_by_dim")
mean_ttm <- colMeans(ll_ttm)
se_ttm   <- apply(ll_ttm, 2, stderr)
total_nll_ttm <- rowSums(ll_ttm)
se_sum_ttm <- stats::sd(total_nll_ttm) / sqrt(length(total_nll_ttm))
} else {
mean_ttm <- rep(NA_real_, K)
se_ttm   <- rep(NA_real_, K)
se_sum_ttm <- NA_real_
}
if (!is.null(models$ttm_sep)) {
ll_ttm_sep <- -predict(models$ttm_sep$S, X_te, type = "logdensity_by_dim")
mean_sep <- colMeans(ll_ttm_sep)
se_sep   <- apply(ll_ttm_sep, 2, stderr)
total_nll_sep <- rowSums(ll_ttm_sep)
se_sum_sep <- stats::sd(total_nll_sep) / sqrt(length(total_nll_sep))
} else {
mean_sep <- rep(NA_real_, K)
se_sep   <- rep(NA_real_, K)
se_sum_sep <- NA_real_
}
if (!is.null(models$ttm_cross)) {
ll_ttm_cross <- -predict(models$ttm_cross$S, X_te,
type = "logdensity_by_dim")
mean_cross <- colMeans(ll_ttm_cross)
se_cross   <- apply(ll_ttm_cross, 2, stderr)
total_nll_cross <- rowSums(ll_ttm_cross)
se_sum_cross <- stats::sd(total_nll_cross) / sqrt(length(total_nll_cross))
} else {
mean_cross <- rep(NA_real_, K)
se_cross   <- rep(NA_real_, K)
se_sum_cross <- NA_real_
}
mean_true <- colMeans(ll_true)
se_true   <- apply(ll_true, 2, stderr)
total_nll_true <- rowSums(ll_true)
se_sum_true <- stats::sd(total_nll_true) / sqrt(length(total_nll_true))
mean_trtf <- colMeans(ll_trtf)
se_trtf   <- apply(ll_trtf, 2, stderr)
total_nll_trtf <- rowSums(ll_trtf)
se_sum_trtf <- stats::sd(total_nll_trtf) / sqrt(length(total_nll_trtf))
mean_ks   <- colMeans(ll_ks)
se_ks     <- apply(ll_ks,   2, stderr)
total_nll_ks <- rowSums(ll_ks)
se_sum_ks <- stats::sd(total_nll_ks) / sqrt(length(total_nll_ks))
fmt <- function(m, se) sprintf("%.2f ± %.2f", round(m, 2), round(2 * se, 2))
tab <- data.frame(
dim = as.character(seq_len(K)),
distribution = sapply(config, `[[`, "distr"),
true = fmt(mean_true, se_true),
trtf = fmt(mean_trtf, se_trtf),
ks   = fmt(mean_ks, se_ks),
ttm  = fmt(mean_ttm, se_ttm),
ttm_sep = fmt(mean_sep, se_sep),
ttm_cross = fmt(mean_cross, se_cross),
stringsAsFactors = FALSE
)
sum_row <- data.frame(
dim = "k",
distribution = "SUM",
true = fmt(sum(mean_true), se_sum_true),
trtf = fmt(sum(mean_trtf), se_sum_trtf),
ks   = fmt(sum(mean_ks),   se_sum_ks),
ttm  = fmt(sum(mean_ttm),  se_sum_ttm),
ttm_sep = fmt(sum(mean_sep),  se_sum_sep),
ttm_cross = fmt(sum(mean_cross), se_sum_cross),
stringsAsFactors = FALSE
)
tab <- rbind(tab, sum_row)
nm <- names(tab)
nm[nm == "trtf"] <- "Random Forest"
nm[nm == "ttm"]  <- "Marginal Map"
nm[nm == "ttm_sep"] <- "Separable Map"
nm[nm == "ttm_cross"] <- "Cross-term Map"
names(tab) <- nm
message("Ergebnis (NLL in nats; lower is better)")
tab
}
### End 04_evaluation.R ###

### Begin replicate_code.R ###
extract_sources <- function(main_file = "main.R") {
lines <- readLines(main_file, warn = FALSE)
pattern <- 'source\\("([^\\"]+)"\\)'
matches <- regmatches(lines, gregexpr(pattern, lines, perl = TRUE))
src_files <- unlist(lapply(matches, function(x) if (length(x) > 0) gsub(pattern, "\\1", x)))
unique(src_files)
}
replicate_code_scripts <- function(main_file = "main.R",
outfile = "replicated_code.txt",
env = parent.frame()) {
src_files <- extract_sources(main_file)
output_lines <- character()
for (f in src_files) {
if (file.exists(f)) {
lines <- readLines(f, warn = FALSE)
lines <- sub("
lines <- trimws(lines)
lines <- lines[nchar(lines) > 0]
output_lines <- c(output_lines,
paste0("
lines,
paste0("
"")
}
}
if (file.exists(main_file)) {
lines <- readLines(main_file, warn = FALSE)
lines <- sub("
lines <- trimws(lines)
lines <- lines[nchar(lines) > 0]
output_lines <- c(output_lines,
paste0("
lines,
paste0("
"")
}
if (exists("results_table", envir = env)) {
tab <- get("results_table", envir = env)
tab_lines <- capture.output(print(tab))
output_lines <- c(output_lines,
"
tab_lines,
"")
}
writeLines(output_lines, outfile)
}
if (sys.nframe() == 0L) {
replicate_code_scripts()
}
### End replicate_code.R ###

### Begin main.R ###
source("00_globals.R")
source("01_data_generation.R")
source("02_split.R")
source("models/true_model.R")
source("models/trtf_model.R")
source("models/ks_model.R")
source("models/ttm_marginal.R")
source("models/ttm_separable.R")
source("04_evaluation.R")
source("replicate_code.R")
n <- 50
config <- list(
list(distr = "norm", parm = NULL),
list(distr = "exp",  parm = function(d) list(rate = softplus(d$X1))),
list(distr = "beta",
parm = function(d) list(shape1 = softplus(d$X2),
shape2 = softplus(d$X1))),
list(distr = "gamma",
parm = function(d) list(shape = softplus(d$X3),
scale = softplus(d$X2)))
)
main <- function() {
set.seed(42)
prep <- prepare_data(n, config, seed = 42)
mods <- list(
true = fit_TRUE(prep$S, config),
trtf = fit_TRTF(prep$S, config, seed = 42),
ks   = fit_KS(prep$S, config),
ttm  = trainMarginalMap(prep$S),
ttm_sep = trainSeparableMap(prep$S),
ttm_cross = trainCrossTermMap(prep$S)
)
tab <- calc_loglik_tables(mods, config, prep$S$X_te)
print(tab)
results_table <<- tab
invisible(tab)
}
if (sys.nframe() == 0L) {
main()
replicate_code_scripts("main.R", "replicated_code.txt", env = globalenv())
}
### End main.R ###

### Final results table ###
  dim distribution         true Random Forest            ks Marginal Map
1   1         norm  1.55 ± 0.47   1.62 ± 0.42   1.60 ± 0.46  1.57 ± 0.38
2   2          exp  1.65 ± 0.63   2.73 ± 1.00   2.06 ± 0.62  3.30 ± 0.01
3   3         beta -0.75 ± 1.23  -0.12 ± 0.52  -0.15 ± 0.70  0.41 ± 0.22
4   4        gamma  2.93 ± 1.97   2.72 ± 1.98 10.90 ± 11.98  3.32 ± 1.45
5   k          SUM  5.38 ± 2.03   6.95 ± 3.02 14.40 ± 12.48  8.59 ± 1.77
  Separable Map Cross-term Map
1   1.55 ± 0.47    1.50 ± 0.46
2   1.91 ± 0.65    2.66 ± 1.22
3  -0.00 ± 0.63   -0.43 ± 1.28
4   3.36 ± 2.68    2.18 ± 1.59
5   6.81 ± 3.36    5.91 ± 2.26

