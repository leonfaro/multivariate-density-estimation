### Begin 00_globals.R ###
library(dplyr)
library(parallel)
library(tram)
library(trtf)
if (!exists("NC")) NC <- detectCores()
options(mc.cores = NC)
softplus <- function(x) log1p(exp(x))
### End 00_globals.R ###

### Begin 01_data_generation.R ###
Generate_iid_from_config <- function(N, cfg, return_params = FALSE) {
stopifnot(is.numeric(N), N > 0, is.list(cfg))
K <- length(cfg)
X <- matrix(NA_real_, nrow = N, ncol = K)
if (return_params) {
param_hist <- vector("list", K)
for (kk in seq_len(K))
param_hist[[kk]] <- vector("list", N)
}
for (i in seq_len(N)) {
for (k in seq_len(K)) {
c_k <- cfg[[k]]
if (is.null(c_k$parm)) {
args <- list()
} else {
if (k == 1) {
prev <- data.frame()
} else {
prev <- as.data.frame(as.list(X[i, seq_len(k - 1)]))
names(prev) <- paste0("X", seq_len(k - 1))
}
args <- c_k$parm(prev)
}
fun <- get(paste0("r", c_k$distr), mode = "function")
if (c_k$distr == "gamma" &&
all(c("shape1", "shape2") %in% names(args))) {
args <- list(shape = args$shape1, scale = args$shape2)
}
args <- lapply(args, function(p) {
if (!is.finite(p) || p <= 0) 1e-3 else p
})
if (return_params) param_hist[[k]][[i]] <- args
X[i, k] <- do.call(fun, c(list(n = 1L), args))
}
}
colnames(X) <- paste0("X", seq_len(K))
if (return_params) {
param_df <- lapply(param_hist, function(lst) {
vals <- lapply(lst, function(x) if (length(x) == 0) NULL else as.data.frame(x))
vals <- Filter(Negate(is.null), vals)
if (length(vals) == 0) return(NULL)
df <- do.call(rbind, vals)
rownames(df) <- NULL
df
})
list(X = X, params = param_df)
} else {
X
}
}
gen_samples <- function(G, return_params = FALSE) {
Generate_iid_from_config(G$n, G$config, return_params = return_params)
}
### End 01_data_generation.R ###

### Begin 02_split.R ###
SplitStruct <- function(X_tr, X_val, X_te) {
list(X_tr = X_tr, X_val = X_val, X_te = X_te)
}
split_data <- function(X, seed) {
stopifnot(is.matrix(X))
N <- nrow(X)
set.seed(seed)
idx <- sample.int(N)
n_tr  <- floor(0.8 * N)
n_val <- floor(0.1 * N)
idx_tr  <- idx[seq_len(n_tr)]
idx_val <- idx[seq_len(n_val) + n_tr]
idx_te  <- idx[(n_tr + n_val + 1):N]
SplitStruct(
X[idx_tr , , drop = FALSE],
X[idx_val, , drop = FALSE],
X[idx_te , , drop = FALSE]
)
}
### End 02_split.R ###

### Begin models/true_model.R ###
neg_loglik_uni <- function(par, x, distr) {
if (distr == "norm") {
mu <- par[1]; sd <- par[2]
if (sd <= 0) return(Inf)
-sum(dnorm(x, mean = mu, sd = sd, log = TRUE))
} else if (distr == "exp") {
rate <- par[1]
if (rate <= 0) return(Inf)
x <- pmax(x, 1e-6)
-sum(dexp(x, rate = rate, log = TRUE))
} else if (distr == "beta") {
a <- par[1]; b <- par[2]
if (a <= 0 || b <= 0) return(Inf)
x <- pmin(pmax(x, 1e-6), 1 - 1e-6)
-sum(dbeta(x, shape1 = a, shape2 = b, log = TRUE))
} else if (distr == "gamma") {
shape <- par[1]; scale <- par[2]
if (shape <= 0 || scale <= 0) return(Inf)
x <- pmax(x, 1e-6)
-sum(dgamma(x, shape = shape, scale = scale, log = TRUE))
} else {
stop("Unsupported distribution")
}
}
.log_density_vec <- function(x, distr, par) {
if (distr == "norm") {
dnorm(x, mean = par[1], sd = par[2], log = TRUE)
} else if (distr == "exp") {
x <- pmax(x, 1e-6)
dexp(x, rate = par[1], log = TRUE)
} else if (distr == "beta") {
x <- pmin(pmax(x, 1e-6), 1 - 1e-6)
dbeta(x, shape1 = par[1], shape2 = par[2], log = TRUE)
} else if (distr == "gamma") {
x <- pmax(x, 1e-6)
dgamma(x, shape = par[1], scale = par[2], log = TRUE)
} else {
stop("Unsupported distribution")
}
}
.start_par <- function(x, distr) {
if (distr == "norm") {
c(mean(x), sd(x))
} else if (distr == "exp") {
c(1 / mean(x))
} else if (distr == "beta") {
m <- mean(x); v <- var(x)
common <- m * (1 - m) / v - 1
a <- m * common; b <- (1 - m) * common
if (!is.finite(a) || a <= 0) a <- 1
if (!is.finite(b) || b <= 0) b <- 1
c(a, b)
} else if (distr == "gamma") {
m <- mean(x); v <- var(x)
shape <- m^2 / v; scale <- v / m
if (!is.finite(shape) || shape <= 0) shape <- 1
if (!is.finite(scale) || scale <= 0) scale <- 1
c(shape, scale)
} else {
stop("Unsupported distribution")
}
}
fit_TRUE <- function(S, config, cores = NC) {
stopifnot(is.list(S))
X_tr  <- S$X_tr
X_val <- S$X_val
X_te  <- S$X_te
stopifnot(is.matrix(X_tr), is.matrix(X_te))
K <- length(config)
theta_list <- parallel::mclapply(seq_len(K), function(k) {
distr_k <- config[[k]]$distr
x_k <- X_tr[, k]
init <- .start_par(x_k, distr_k)
opt <- optim(
par = init,
fn = neg_loglik_uni,
x = x_k,
distr = distr_k,
method = "L-BFGS-B",
lower = rep(1e-6, length(init))
)
opt$par
}, mc.cores = cores)
model <- list(theta = theta_list, config = config)
logL_te <- logL_TRUE(model, X_te)
model$logL_te <- logL_te
model
}
logL_TRUE <- function(M_TRUE, X, cores = NC) {
stopifnot(is.matrix(X))
theta_list <- M_TRUE$theta
config <- M_TRUE$config
K <- length(theta_list)
ll_list <- parallel::mclapply(seq_len(K), function(k) {
distr_k <- config[[k]]$distr
.log_density_vec(X[, k], distr_k, theta_list[[k]])
}, mc.cores = cores)
ll <- do.call(cbind, ll_list)
val <- -mean(rowSums(ll))
if (!is.finite(val)) stop("log-likelihood not finite")
val
}
logL_TRUE_dim <- function(M_TRUE, X, cores = NC) {
stopifnot(is.matrix(X))
theta_list <- M_TRUE$theta
config <- M_TRUE$config
K <- length(theta_list)
res <- parallel::mclapply(seq_len(K), function(k) {
distr_k <- config[[k]]$distr
ll_k <- .log_density_vec(X[, k], distr_k, theta_list[[k]])
val <- -mean(ll_k)
if (!is.finite(val)) stop("log-likelihood not finite")
val
}, mc.cores = cores)
unlist(res)
}
### End models/true_model.R ###

### Begin models/trtf_model.R ###
p <- list(
minsplit = 40,
minbucket = 5,
maxdepth = 2,
seed = 42
)
mytrtf <- function(data, ntree, minsplit, minbucket, maxdepth, seed, cores = NC) {
stopifnot(is.matrix(data))
set.seed(seed)
K <- ncol(data)
df <- as.data.frame(data)
names(df) <- paste0("X", seq_len(K))
ymod <- lapply(names(df), function(y) {
BoxCox(as.formula(paste(y, "~ 1")), data = df)
})
forests <- vector("list", K - 1L)
ctrl <- partykit::ctree_control(minsplit = minsplit,
minbucket = minbucket,
maxdepth = maxdepth)
for (k in 2:K) {
rhs <- paste(names(df)[1:(k - 1)], collapse = "+")
fm <- as.formula(paste(names(df)[k], "~", rhs))
current_mtry <- max(1, floor((k - 1) / 2))
forests[[k - 1L]] <- traforest(ymod[[k]], formula = fm, data = df,
trace = TRUE, ntree = ntree,
mltargs = list(), mtry = current_mtry,
cores = cores, control = ctrl)
}
res <- list(ymod = ymod, forests = forests, seed = seed,
varimp = lapply(forests, varimp))
class(res) <- "mytrtf"
res
}
predict.mytrtf <- function(object, newdata,
type = c("logdensity", "logdensity_by_dim"),
cores = NC, trace = TRUE) {
type <- match.arg(type)
stopifnot(inherits(object, "mytrtf"), is.matrix(newdata))
K <- length(object$ymod)
df_new <- as.data.frame(newdata)
names(df_new) <- paste0("X", seq_len(K))
ld1 <- predict(object$ymod[[1]], newdata = df_new, type = "logdensity")
ld_rest <- lapply(seq_along(object$forests), function(j) {
fr <- object$forests[[j]]
q <- df_new[, variable.names(fr$model)[1]]
pr <- predict(fr, newdata = df_new, type = "logdensity", q = q,
cores = cores, trace = trace)
diag(do.call(cbind, pr))
})
ll <- cbind(ld1, do.call(cbind, ld_rest))
if (type == "logdensity_by_dim") return(ll)
rowSums(ll)
}
logL_TRTF <- function(model, X, cores = NC) {
val <- -mean(predict(model, X, type = "logdensity",
cores = cores, trace = TRUE))
if (!is.finite(val)) stop("log-likelihood not finite")
val
}
logL_TRTF_dim <- function(model, X, cores = NC) {
ll <- predict(model, X, type = "logdensity_by_dim",
cores = cores, trace = TRUE)
res <- -colMeans(ll)
if (!all(is.finite(res))) stop("log-likelihood not finite")
res
}
fit_TRTF <- function(S, config, seed = NULL, cores = NC) {
stopifnot(is.list(S))
X_tr <- S$X_tr
X_te <- S$X_te
stopifnot(is.matrix(X_tr), is.matrix(X_te))
if (!is.null(seed)) set.seed(seed)
mod <- mytrtf(data = X_tr,
ntree = nrow(X_tr),
minsplit = p$minsplit,
minbucket = p$minbucket,
maxdepth = p$maxdepth,
seed = seed,
cores = cores)
mod$config  <- config
logL_te_dim <- logL_TRTF_dim(mod, S$X_te, cores = cores)
mod$logL_te_dim <- logL_te_dim
mod$logL_te <- sum(logL_te_dim)
mod
}
### End models/trtf_model.R ###

### Begin models/ttm_marginal.R ###
.standardizeData <- function(X) {
mu <- colMeans(X)
sigma <- apply(X, 2, sd) + .Machine$double.eps
X_tilde <- sweep(X, 2, mu, "-")
X_tilde <- sweep(X_tilde, 2, sigma, "/")
list(X = X_tilde, mu = mu, sigma = sigma)
}
.forward_matrix <- function(S, X) {
Xs <- .standardize(S, X)
b <- exp(S$coeffA)
Z <- sweep(Xs, 2, b, "*")
sweep(Z, 2, S$coeffB, "+")
}
.logjac_const <- function(S) {
b <- exp(S$coeffA)
log(b) - log(S$sigma)
}
.standardize <- function(S, X) {
X <- sweep(X, 2, S$mu, "-")
sweep(X, 2, S$sigma, "/")
}
trainMarginalMap <- function(X_or_path) {
set.seed(42)
S_in <- if (is.character(X_or_path)) readRDS(X_or_path) else X_or_path
stopifnot(is.list(S_in))
X_tr <- S_in$X_tr
X_val <- S_in$X_val
X_te  <- S_in$X_te
time_train <- system.time({
std <- .standardizeData(X_tr)
X_tr_std <- std$X
mu <- std$mu
sigma <- std$sigma
K <- ncol(X_tr_std)
coeffA <- numeric(K)
coeffB <- numeric(K)
for (k in seq_len(K)) {
xk <- X_tr_std[, k]
N <- length(xk)
u <- rank(xk, ties.method = "average") / (N + 1)
lower <- 1 / (N + 1)
upper <- N / (N + 1)
u <- pmin(pmax(u, lower), upper)
z_star <- qnorm(u)
covxz <- mean((xk - mean(xk)) * (z_star - mean(z_star)))
varx <- var(xk) + 1e-12
b_k <- max(0, covxz / varx)
a_k <- mean(z_star) - b_k * mean(xk)
coeffA[k] <- log(b_k + 1e-12)
coeffB[k] <- a_k
}
coeffC <- rep(0, K)
S_map <- list(
mu = mu,
sigma = sigma,
coeffA = coeffA,
coeffB = coeffB,
coeffC = coeffC,
order = seq_len(K)
)
class(S_map) <- "ttm_marginal"
})[["elapsed"]]
time_pred <- system.time({
predict(S_map, X_te, "logdensity_by_dim")
})[["elapsed"]]
list(
S = S_map,
NLL_train = NLL_set(S_map, X_tr),
NLL_val = NLL_set(S_map, X_val),
NLL_test = NLL_set(S_map, X_te),
stderr_test = SE_set(S_map, X_te),
time_train = time_train,
time_pred = time_pred
)
}
predict.ttm_marginal <- function(object, newdata,
type = c("logdensity_by_dim", "logdensity")) {
type <- tryCatch(match.arg(type), error = function(e) stop("unknown type"))
Z <- .forward_matrix(object, newdata)
LJ <- .logjac_const(object)
C <- -0.5 * log(2 * pi)
LD <- (-0.5) * (Z^2) + C +
matrix(LJ, nrow = nrow(Z), ncol = length(LJ), byrow = TRUE)
if (type == "logdensity_by_dim") {
LD
} else {
rowSums(LD)
}
}
NLL_set <- function(S, X) {
mean(-rowSums(predict(S, X, "logdensity_by_dim")))
}
SE_set <- function(S, X) {
v <- rowSums(-predict(S, X, "logdensity_by_dim"))
stats::sd(v) / sqrt(length(v))
}
forwardPass <- function(S, x) {
x_std <- .standardize(S, matrix(x, nrow = 1))
b <- exp(S$coeffA)
a <- S$coeffB
as.numeric(a + b * x_std)
}
logJacDiag <- function(S, x) {
LJ <- .logjac_const(S)
rep(LJ, length.out = length(x))
}
forwardKLLoss <- function(S, X) {
Z <- .forward_matrix(S, X)
LJ <- .logjac_const(S)
mean(0.5 * rowSums(Z^2) - sum(LJ))
}
inversePass <- function(S, z) {
b <- exp(S$coeffA)
a <- S$coeffB
x_std <- (z - a) / b
x <- sweep(x_std, 2, S$sigma, "*")
x <- sweep(x, 2, S$mu, "+")
as.numeric(x)
}
negativeLogLikelihood <- function(S, X) {
Z <- .forward_matrix(S, X)
LJ <- .logjac_const(S)
sum(0.5 * rowSums(Z^2) - sum(LJ))
}
natsPerDim <- function(NLL, N, K) {
NLL / (N * K)
}
stderr <- function(v) {
stats::sd(v) / sqrt(length(v))
}
### End models/ttm_marginal.R ###

### Begin models/ttm_separable.R ###
if (!exists(".standardizeData")) {
.standardizeData <- function(X) {
mu <- colMeans(X)
sigma <- apply(X, 2, sd) + .Machine$double.eps
X_tilde <- sweep(X, 2, mu, "-")
X_tilde <- sweep(X_tilde, 2, sigma, "/")
list(X = X_tilde, mu = mu, sigma = sigma)
}
}
if (!exists(".standardize")) {
.standardize <- function(S, X) {
X <- sweep(X, 2, S$mu, "-")
sweep(X, 2, S$sigma, "/")
}
}
erf <- function(x) 2 * pnorm(x * sqrt(2)) - 1
basis_f <- function(x) cbind(x, erf(x))
dbasis_f <- function(x) {
cbind(rep(1, length(x)), 2 / sqrt(pi) * exp(-x^2))
}
basis_g <- function(X, deg) {
if (ncol(X) == 0L) {
return(matrix(0, nrow = nrow(X), ncol = 0))
}
N <- nrow(X)
out <- matrix(1, N, 1)
for (j in seq_len(ncol(X))) {
xj <- X[, j]
for (d in seq_len(deg)) {
out <- cbind(out, xj^d)
}
}
out
}
trainSeparableMap <- function(X_or_path, degree_g = 2, lambda = 1e-3, eps = 1e-6) {
set.seed(42)
S_in <- if (is.character(X_or_path)) readRDS(X_or_path) else X_or_path
stopifnot(is.list(S_in))
X_tr <- S_in$X_tr
X_val <- S_in$X_val
X_te  <- S_in$X_te
time_train <- system.time({
std <- .standardizeData(X_tr)
X_tr_std <- std$X
mu <- std$mu
sigma <- std$sigma
K <- ncol(X_tr_std)
coeffs <- vector("list", K)
N <- nrow(X_tr_std)
for (k in seq_len(K)) {
x_prev <- if (k > 1) X_tr_std[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
xk <- X_tr_std[, k]
P_non <- if (k > 1) basis_g(x_prev, degree_g) else matrix(0, N, 0)
P_mon <- basis_f(xk)
B <- dbasis_f(xk)
stopifnot(nrow(P_mon) == N, nrow(P_non) == N, nrow(B) == N)
m_non <- ncol(P_non)
m_mon <- ncol(P_mon)
if (m_non > 0) {
M <- solve(crossprod(P_non) + lambda * diag(m_non), t(P_non))
A <- (diag(N) - P_non %*% M) %*% P_mon
D <- M %*% P_mon
} else {
M <- matrix(0, 0, N)
A <- P_mon
D <- matrix(0, 0, m_mon)
}
fn <- function(c) {
r <- A %*% c
Bc <- B %*% c
if (any(Bc <= 0)) return(Inf)
q <- D %*% c
0.5 * sum(r^2) - sum(log(Bc)) + (lambda / 2) * (sum(q^2) + sum(c^2))
}
gr <- function(c) {
r <- A %*% c
Bc <- B %*% c
q <- D %*% c
as.numeric(t(A) %*% r - t(B) %*% (1 / Bc) + lambda * (t(D) %*% q + c))
}
c0 <- rep(1, m_mon)
opt <- optim(c0, fn, gr, method = "L-BFGS-B", lower = rep(eps, m_mon))
c_mon <- opt$par
c_non <- if (m_non > 0) -M %*% (P_mon %*% c_mon) else numeric(0)
coeffs[[k]] <- list(c_non = c_non, c_mon = c_mon)
}
S_map <- list(
mu = mu,
sigma = sigma,
coeffs = coeffs,
degree_g = degree_g,
order = seq_len(K)
)
class(S_map) <- "ttm_separable"
})[["elapsed"]]
time_pred <- system.time({
predict(S_map, X_te, "logdensity_by_dim")
})[["elapsed"]]
list(
S = S_map,
NLL_train = NLL_set(S_map, X_tr),
NLL_val = NLL_set(S_map, X_val),
NLL_test = NLL_set(S_map, X_te),
stderr_test = SE_set(S_map, X_te),
time_train = time_train,
time_pred = time_pred
)
}
predict.ttm_separable <- function(object, newdata,
type = c("logdensity_by_dim", "logdensity")) {
type <- tryCatch(match.arg(type), error = function(e) stop("unknown type"))
Xs <- .standardize(object, newdata)
N <- nrow(Xs)
K <- ncol(Xs)
Z <- matrix(0, N, K)
LJ <- matrix(0, N, K)
for (k in seq_len(K)) {
x_prev <- if (k > 1) Xs[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
xk <- Xs[, k]
P_non <- if (k > 1) basis_g(x_prev, object$degree_g) else matrix(0, N, 0)
P_mon <- basis_f(xk)
B <- dbasis_f(xk)
c_non <- object$coeffs[[k]]$c_non
c_mon <- object$coeffs[[k]]$c_mon
gk <- if (ncol(P_non) > 0) as.numeric(P_non %*% c_non) else rep(0, N)
fk <- as.numeric(P_mon %*% c_mon)
Z[, k] <- gk + fk
deriv <- (B %*% c_mon) / object$sigma[k]
LJ[, k] <- log(as.numeric(deriv))
}
C <- -0.5 * log(2 * pi)
LD <- (-0.5) * (Z^2) + C + LJ
if (type == "logdensity_by_dim") {
LD
} else {
rowSums(LD)
}
}
NLL_set <- function(S, X) {
mean(-rowSums(predict(S, X, "logdensity_by_dim")))
}
SE_set <- function(S, X) {
v <- rowSums(-predict(S, X, "logdensity_by_dim"))
stats::sd(v) / sqrt(length(v))
}
### End models/ttm_separable.R ###

### Begin models/ttm_cross_term.R ###
if (!exists(".standardizeData")) {
.standardizeData <- function(X) {
mu <- colMeans(X)
sigma <- apply(X, 2, sd) + .Machine$double.eps
X_tilde <- sweep(X, 2, mu, "-")
X_tilde <- sweep(X_tilde, 2, sigma, "/")
list(X = X_tilde, mu = mu, sigma = sigma)
}
}
if (!exists(".standardize")) {
.standardize <- function(S, X) {
X <- sweep(X, 2, S$mu, "-")
sweep(X, 2, S$sigma, "/")
}
}
.basis_g_ct <- function(X, deg) {
if (ncol(X) == 0L) {
return(matrix(0, nrow = nrow(X), ncol = 0))
}
N <- nrow(X)
out <- matrix(1, N, 1)
for (j in seq_len(ncol(X))) {
xj <- X[, j]
for (d in seq_len(deg)) {
out <- cbind(out, xj^d)
}
}
out
}
.psi_basis_ct <- function(t, xprev, deg_t, deg_x, cross = TRUE) {
out <- numeric(0)
for (d in seq_len(deg_t)) {
out <- c(out, t^d)
}
if (cross && length(xprev) > 0) {
for (j in seq_along(xprev)) {
out <- c(out, t * xprev[j])
}
}
out
}
.dpsi_dt_ct <- function(t, xprev, deg_t, deg_x, cross = TRUE) {
out <- numeric(0)
for (d in seq_len(deg_t)) {
out <- c(out, d * t^(max(d - 1, 0)))
}
if (cross && length(xprev) > 0) {
for (j in seq_along(xprev)) {
out <- c(out, xprev[j])
}
}
out
}
.build_Psi_q_ct <- function(xval, xp, nodes, nodes_pow, deg_t, deg_x) {
Q <- length(nodes)
m_beta <- deg_t + length(xp)
Psi_q <- matrix(0, Q, m_beta)
if (deg_t > 0) {
x_pow <- xval^(seq_len(deg_t))
Psi_q[, seq_len(deg_t)] <- sweep(nodes_pow, 2, x_pow, "*")
}
if (length(xp) > 0) {
t_vec <- nodes * xval
for (j in seq_along(xp)) {
Psi_q[, deg_t + j] <- t_vec * xp[j]
}
}
Psi_q
}
.gauss_legendre_01_ct <- function(n) {
if (n <= 0 || n != as.integer(n)) {
stop("n must be positive integer")
}
if (n == 1) {
return(list(nodes = 0.5, weights = 1))
}
i <- seq_len(n - 1)
b <- i / sqrt(4 * i^2 - 1)
J <- matrix(0, n, n)
for (k in i) {
J[k, k + 1] <- b[k]
J[k + 1, k] <- b[k]
}
e <- eigen(J, symmetric = TRUE)
x <- (e$values + 1) / 2
w <- (2 * (e$vectors[1, ]^2)) / 2
list(nodes = x, weights = w)
}
.safe_mclapply_ct <- function(X, FUN, mc.cores, ...) {
parallel::mclapply(X, function(ix) {
tryCatch(FUN(ix), error = function(e) e)
}, mc.cores = mc.cores, mc.set.seed = FALSE, mc.preschedule = TRUE, ...)
}
.is_coeffs_ok <- function(x) is.list(x) && is.numeric(x$alpha) && is.numeric(x$beta)
.is_predchunk_ok <- function(x) is.list(x) && is.numeric(x$Z_col) && is.numeric(x$LJ_col)
.zero_coeffs_ct <- function(k, X_tr_std, degree_g, degree_t) {
N <- nrow(X_tr_std)
Xprev <- if (k > 1) X_tr_std[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
m_alpha <- ncol(.basis_g_ct(Xprev, degree_g))
xprev_first <- if (k > 1) Xprev[1, , drop = TRUE] else numeric(0)
m_beta <- length(.psi_basis_ct(0, xprev_first, degree_t, degree_g, TRUE))
list(alpha = if (m_alpha > 0) rep(0, m_alpha) else numeric(0),
beta  = rep(0, m_beta))
}
.zero_predchunk_ct <- function(N, sigma_k) {
list(Z_col = rep(0, N), LJ_col = rep(-log(sigma_k), N))
}
.NLL_set_ct <- function(S, X) {
mean(-rowSums(predict(S, X, "logdensity_by_dim")))
}
.SE_set_ct <- function(S, X) {
v <- rowSums(-predict(S, X, "logdensity_by_dim"))
stats::sd(v) / sqrt(length(v))
}
.logJacDiag_ct <- function(S, x) {
Xs <- .standardize(S, matrix(x, nrow = 1))
K <- length(x)
out <- numeric(K)
for (k in seq_len(K)) {
xprev <- if (k > 1) Xs[1, 1:(k - 1)] else numeric(0)
psi <- .psi_basis_ct(Xs[1, k], xprev, S$degree_t, S$degree_g, TRUE)
beta <- S$coeffs[[k]]$beta
out[k] <- sum(beta * psi) - log(S$sigma[k])
}
out
}
.forwardKLLoss_ct <- function(S, X) {
X <- as.matrix(X)
K <- ncol(X)
LD <- predict(S, X, "logdensity_by_dim")
mean(-rowSums(LD) - 0.5 * K * log(2 * pi))
}
trainCrossTermMap <- function(X_or_path, degree_g = 2, degree_t = 2,
lambda = 1e-3, batch_n = NULL, Q = NULL,
eps = 1e-6, clip = 20) {
set.seed(42)
S_in <- if (is.character(X_or_path)) readRDS(X_or_path) else X_or_path
stopifnot(is.list(S_in))
X_tr <- S_in$X_tr
X_val <- S_in$X_val
X_te  <- S_in$X_te
time_train <- system.time({
std <- .standardizeData(X_tr)
X_tr_std <- std$X
mu <- std$mu
sigma <- std$sigma
N <- nrow(X_tr_std)
K <- ncol(X_tr_std)
Q_use <- if (is.null(Q)) min(12, 4 + 2 * degree_t) else Q
batch_use <- if (is.null(batch_n)) min(N, max(256L, floor(65536 / max(1L, Q_use)))) else min(N, batch_n)
quad <- .gauss_legendre_01_ct(Q_use)
nodes <- quad$nodes
weights <- quad$weights
nodes_pow <- outer(nodes, seq_len(degree_t), `^`)
fit_k <- function(k) {
Xprev <- if (k > 1) X_tr_std[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
xk <- X_tr_std[, k]
Phi <- .basis_g_ct(Xprev, degree_g)
m_alpha <- ncol(Phi)
xprev_first <- if (k > 1) Xprev[1, , drop = TRUE] else numeric(0)
m_beta <- length(.psi_basis_ct(0, xprev_first, degree_t, degree_g, TRUE))
loss_grad <- function(alpha, beta) {
S_sq_sum <- 0
term_sum <- 0
grad_alpha <- if (m_alpha > 0) rep(0, m_alpha) else numeric(0)
grad_beta <- rep(0, m_beta)
for (i0 in seq(1, N, by = batch_use)) {
idx <- i0:min(i0 + batch_use - 1, N)
Phi_blk <- if (m_alpha > 0) Phi[idx, , drop = FALSE] else NULL
Xprev_blk <- if (k > 1) Xprev[idx, , drop = FALSE] else matrix(0, length(idx), 0)
xk_blk <- xk[idx]
for (b in seq_along(idx)) {
xp <- if (k > 1) Xprev_blk[b, ] else numeric(0)
xval <- xk_blk[b]
Psi_q <- .build_Psi_q_ct(xval, xp, nodes, nodes_pow, degree_t, degree_g)
V <- Psi_q %*% beta
m <- max(V)
v_shift <- V - m
ev <- exp(pmax(v_shift, -clip))
s  <- sum(weights * ev)
I_i  <- xval * exp(m) * s
dI_i <- xval * exp(m) * as.vector(t(Psi_q) %*% (weights * ev))
psi_x <- .psi_basis_ct(xval, xp, degree_t, degree_g, TRUE)
S_i <- if (m_alpha > 0) sum(Phi_blk[b, ] * alpha) + I_i else I_i
S_sq_sum <- S_sq_sum + S_i^2
if (m_alpha > 0) grad_alpha <- grad_alpha + S_i * Phi_blk[b, ]
grad_beta <- grad_beta + S_i * dI_i - psi_x
term_sum <- term_sum + sum(psi_x * beta)
}
}
loss <- 0.5 * S_sq_sum / N - term_sum / N +
0.5 * lambda * (sum(alpha^2) + sum(beta^2))
grad_alpha_out <- if (m_alpha > 0) grad_alpha / N + lambda * alpha else numeric(0)
grad_beta_out <- grad_beta / N + lambda * beta
list(loss = loss, grad = c(grad_alpha_out, grad_beta_out))
}
cache <- new.env(parent = emptyenv())
fn <- function(theta) {
alpha <- if (m_alpha > 0) theta[seq_len(m_alpha)] else numeric(0)
beta <- theta[(m_alpha + 1):length(theta)]
res <- loss_grad(alpha, beta)
cache$grad <- res$grad
res$loss
}
gr <- function(theta) {
if (!is.null(cache$grad)) {
g <- cache$grad
cache$grad <- NULL
return(g)
}
alpha <- if (m_alpha > 0) theta[seq_len(m_alpha)] else numeric(0)
beta <- theta[(m_alpha + 1):length(theta)]
loss_grad(alpha, beta)$grad
}
theta0 <- rep(0, m_alpha + m_beta)
opt <- optim(theta0, fn, gr, method = "L-BFGS-B", lower = -Inf, upper = Inf)
alpha_hat <- if (m_alpha > 0) opt$par[seq_len(m_alpha)] else numeric(0)
beta_hat <- opt$par[(m_alpha + 1):length(opt$par)]
list(alpha = alpha_hat, beta = beta_hat)
}
res <- .safe_mclapply_ct(seq_len(K), fit_k,
mc.cores = min(getOption("mc.cores", 10L), K))
for (k in seq_len(K)) {
if (!.is_coeffs_ok(res[[k]])) {
r2 <- tryCatch(fit_k(k), error = function(e) e)
if (!.is_coeffs_ok(r2)) {
r2 <- .zero_coeffs_ct(k, X_tr_std, degree_g, degree_t)
}
res[[k]] <- r2
}
}
coeffs <- res
stopifnot(length(coeffs) == K,
all(vapply(coeffs, .is_coeffs_ok, logical(1))) )
S_map <- list(
mu = mu,
sigma = sigma,
degree_g = degree_g,
degree_t = degree_t,
coeffs = coeffs,
Q = Q_use,
nodes = nodes,
weights = weights,
nodes_pow = nodes_pow,
quad_nodes_ct = nodes,
quad_weights_ct = weights,
quad_nodes_pow_ct = nodes_pow,
clip = clip,
order = seq_len(K)
)
class(S_map) <- "ttm_cross_term"
})[["elapsed"]]
time_pred <- system.time({
predict(S_map, X_te, "logdensity_by_dim")
})[["elapsed"]]
list(
S = S_map,
NLL_train = .NLL_set_ct(S_map, X_tr),
NLL_val = .NLL_set_ct(S_map, X_val),
NLL_test = .NLL_set_ct(S_map, X_te),
stderr_test = .SE_set_ct(S_map, X_te),
time_train = time_train,
time_pred = time_pred
)
}
predict.ttm_cross_term <- function(object, newdata,
type = c("logdensity_by_dim", "logdensity"),
batch_n = NULL) {
type <- tryCatch(match.arg(type), error = function(e) stop("unknown type"))
Xs <- .standardize(object, newdata)
N <- nrow(Xs)
K <- ncol(Xs)
batch_use <- if (is.null(batch_n)) min(N, max(256L, floor(65536 / max(1L, object$Q)))) else min(N, batch_n)
nodes <- object$quad_nodes_ct
weights <- object$quad_weights_ct
nodes_pow <- object$quad_nodes_pow_ct
C <- -0.5 * log(2 * pi)
chunk_fun <- function(k) {
Xprev <- if (k > 1) Xs[, 1:(k - 1), drop = FALSE] else matrix(0, N, 0)
xk <- Xs[, k]
Phi <- .basis_g_ct(Xprev, object$degree_g)
m_alpha <- ncol(Phi)
alpha <- object$coeffs[[k]]$alpha
beta <- object$coeffs[[k]]$beta
xprev_first <- if (k > 1) Xprev[1, , drop = TRUE] else numeric(0)
psi_len <- length(.psi_basis_ct(Xs[1, k], xprev_first,
object$degree_t, object$degree_g, TRUE))
stopifnot(length(beta) == psi_len)
Z_col <- numeric(N)
LJ_col <- numeric(N)
for (i0 in seq(1, N, by = batch_use)) {
idx <- i0:min(i0 + batch_use - 1, N)
Phi_blk <- if (m_alpha > 0) Phi[idx, , drop = FALSE] else NULL
Xprev_blk <- if (k > 1) Xprev[idx, , drop = FALSE] else matrix(0, length(idx), 0)
xk_blk <- xk[idx]
for (b in seq_along(idx)) {
xp <- if (k > 1) Xprev_blk[b, ] else numeric(0)
xval <- xk_blk[b]
Psi_q <- .build_Psi_q_ct(xval, xp, nodes, nodes_pow, object$degree_t, object$degree_g)
V <- Psi_q %*% beta
m <- max(V)
v_shift <- V - m
ev <- exp(pmax(v_shift, -object$clip))
s <- sum(weights * ev)
I_i <- xval * exp(m) * s
psi_x <- .psi_basis_ct(xval, xp, object$degree_t, object$degree_g, TRUE)
Z_col[idx[b]] <- if (m_alpha > 0) sum(Phi_blk[b, ] * alpha) + I_i else I_i
LJ_col[idx[b]] <- sum(beta * psi_x) - log(object$sigma[k])
}
}
list(Z_col = Z_col, LJ_col = LJ_col)
}
res <- .safe_mclapply_ct(seq_len(K), chunk_fun,
mc.cores = min(getOption("mc.cores", 10L), K))
for (k in seq_len(K)) {
if (!.is_predchunk_ok(res[[k]])) {
r2 <- tryCatch(chunk_fun(k), error = function(e) e)
if (!.is_predchunk_ok(r2)) {
r2 <- .zero_predchunk_ct(N, object$sigma[k])
r2$Z_col <- Xs[, k]
}
res[[k]] <- r2
}
}
Z <- do.call(cbind, lapply(res, `[[`, "Z_col"))
LJ <- do.call(cbind, lapply(res, `[[`, "LJ_col"))
LD <- (-0.5) * (Z^2) + C + LJ
if (type == "logdensity_by_dim") {
LD
} else {
rowSums(LD)
}
}
### End models/ttm_cross_term.R ###

### Begin models/true_joint_model.R ###
.sanitize_args <- function(args, distr) {
if (distr == "gamma" && all(c("shape1", "shape2") %in% names(args))) {
args$shape <- args$shape1
args$scale <- args$shape2
args$shape1 <- NULL
args$shape2 <- NULL
}
pos_params <- switch(distr,
norm  = "sd",
exp   = "rate",
beta  = c("shape1", "shape2"),
gamma = c("shape", "scale"),
character(0)
)
defaults <- list(
norm = list(sd = 1),
exp = list(rate = 1),
beta = list(shape1 = 1, shape2 = 1),
gamma = list(shape = 1, scale = 1)
)
for (nm in pos_params) {
val <- args[[nm]]
if (is.null(val) || !is.finite(val) || val <= 0) {
val <- defaults[[distr]][[nm]]
}
args[[nm]] <- max(val, 1e-6)
}
args
}
.log_density_conditional_row <- function(x_row, config) {
K <- length(config)
out <- numeric(K)
prev_names <- paste0("X", seq_len(K))
for (k in seq_len(K)) {
prev <- if (k == 1) data.frame() else {
df <- as.data.frame(as.list(x_row[seq_len(k - 1)]))
names(df) <- prev_names[seq_len(k - 1)]
df
}
distr_k <- config[[k]]$distr
if (is.null(config[[k]]$parm)) {
args <- list()
if (distr_k == "beta") {
args$shape1 <- 1
args$shape2 <- 1
} else if (distr_k == "gamma") {
args$shape <- 1
args$scale <- 1
}
} else {
args <- config[[k]]$parm(prev)
}
args <- .sanitize_args(args, distr_k)
xk <- x_row[k]
if (distr_k %in% c("exp", "gamma")) {
xk <- max(xk, 1e-6)
} else if (distr_k == "beta") {
xk <- min(max(xk, 1e-6), 1 - 1e-6)
}
out[k] <- switch(distr_k,
norm  = dnorm(xk, mean = args$mean %||% 0, sd = args$sd %||% 1, log = TRUE),
exp   = dexp(xk, rate = args$rate %||% 1, log = TRUE),
beta  = dbeta(xk, shape1 = args$shape1, shape2 = args$shape2, log = TRUE),
gamma = dgamma(xk, shape = args$shape, scale = args$scale, log = TRUE),
stop("Unsupported distribution")
)
}
out
}
true_joint_logdensity_by_dim <- function(config, X, cores = NC) {
stopifnot(is.matrix(X))
res <- parallel::mclapply(seq_len(nrow(X)), function(i) {
.log_density_conditional_row(X[i, ], config)
}, mc.cores = cores)
ll <- do.call(rbind, res)
if (!all(is.finite(ll))) stop("log-density not finite")
ll
}
logL_TRUE_JOINT_dim <- function(config, X, cores = NC) {
ll <- true_joint_logdensity_by_dim(config, X, cores)
-colMeans(ll)
}
logL_TRUE_JOINT <- function(config, X, cores = NC) {
ll <- true_joint_logdensity_by_dim(config, X, cores)
-mean(rowSums(ll))
}
fit_TRUE_JOINT <- function(S, config, cores = NC) {
stopifnot(is.list(S))
te_dim <- logL_TRUE_JOINT_dim(config, S$X_te, cores)
res <- list(
config = config,
logL_te_dim = te_dim,
logL_te = sum(te_dim)
)
class(res) <- "true_joint"
res
}
`%||%` <- function(a, b) if (is.null(a)) b else a
### End models/true_joint_model.R ###

### Begin 04_evaluation.R ###
root_path <- getwd()
if (basename(root_path) == "testthat") {
root_path <- dirname(dirname(root_path))
}
source(file.path(root_path, "models/ttm_marginal.R"))
source(file.path(root_path, "models/ttm_separable.R"))
source(file.path(root_path, "models/ttm_cross_term.R"))
source(file.path(root_path, "models/true_joint_model.R"))
add_sum_row <- function(tab, label = "k") {
stopifnot(is.data.frame(tab))
sum_row <- setNames(vector("list", ncol(tab)), names(tab))
for (nm in names(tab)) {
if (nm == "dim") {
sum_row[[nm]] <- label
} else if (is.numeric(tab[[nm]])) {
sum_row[[nm]] <- sum(tab[[nm]], na.rm = TRUE)
} else {
sum_row[[nm]] <- NA
}
}
rbind(tab, as.data.frame(sum_row, stringsAsFactors = FALSE))
}
prepare_data <- function(n, config, seed = 42) {
X <- Generate_iid_from_config(n, config)
S <- split_data(X, seed)
list(X = X, S = S)
}
fit_models <- function(S, config) {
M_TRUE <- fit_TRUE(S, config)
t_true <- system.time({
ll_true <- logL_TRUE_dim(M_TRUE, S$X_te)
})[["elapsed"]]
M_TRTF <- fit_TRTF(S, config)
t_trtf <- system.time({
ll_trtf <- logL_TRTF_dim(M_TRTF, S$X_te)
})[["elapsed"]]
M_TTM_cross <- trainCrossTermMap(S)
t_ttm_cross <- system.time({
ll_ttm_cross <- -predict(M_TTM_cross$S, S$X_te, type = "logdensity_by_dim")
})[["elapsed"]]
list(models = list(true = M_TRUE, trtf = M_TRTF,
ttm_cross = M_TTM_cross),
ll = list(true = ll_true, trtf = ll_trtf,
ttm_cross = ll_ttm_cross),
times = c(true = t_true, trtf = t_trtf,
ttm_cross = t_ttm_cross))
}
calc_loglik_tables <- function(models, config, X_te) {
K <- length(config)
ll_true <- matrix(NA_real_, nrow = nrow(X_te), ncol = K)
for (k in seq_len(K)) {
ll_vec <- .log_density_vec(X_te[, k], config[[k]]$distr,
models$true$theta[[k]])
ll_true[, k] <- -ll_vec
}
ll_trtf <- -predict(models$trtf, X_te, type = "logdensity_by_dim")
ll_true_joint <- - true_joint_logdensity_by_dim(config, X_te)
if (!is.null(models$ttm)) {
ll_ttm <- -predict(models$ttm$S, X_te, type = "logdensity_by_dim")
mean_ttm <- colMeans(ll_ttm)
se_ttm   <- apply(ll_ttm, 2, stderr)
total_nll_ttm <- rowSums(ll_ttm)
se_sum_ttm <- stats::sd(total_nll_ttm) / sqrt(length(total_nll_ttm))
} else {
mean_ttm <- rep(NA_real_, K)
se_ttm   <- rep(NA_real_, K)
se_sum_ttm <- NA_real_
}
if (!is.null(models$ttm_sep)) {
ll_ttm_sep <- -predict(models$ttm_sep$S, X_te, type = "logdensity_by_dim")
mean_sep <- colMeans(ll_ttm_sep)
se_sep   <- apply(ll_ttm_sep, 2, stderr)
total_nll_sep <- rowSums(ll_ttm_sep)
se_sum_sep <- stats::sd(total_nll_sep) / sqrt(length(total_nll_sep))
} else {
mean_sep <- rep(NA_real_, K)
se_sep   <- rep(NA_real_, K)
se_sum_sep <- NA_real_
}
if (!is.null(models$ttm_cross)) {
ll_ttm_cross <- -predict(models$ttm_cross$S, X_te,
type = "logdensity_by_dim")
mean_cross <- colMeans(ll_ttm_cross)
se_cross   <- apply(ll_ttm_cross, 2, stderr)
total_nll_cross <- rowSums(ll_ttm_cross)
se_sum_cross <- stats::sd(total_nll_cross) / sqrt(length(total_nll_cross))
} else {
mean_cross <- rep(NA_real_, K)
se_cross   <- rep(NA_real_, K)
se_sum_cross <- NA_real_
}
mean_true <- colMeans(ll_true)
se_true   <- apply(ll_true, 2, stderr)
total_nll_true <- rowSums(ll_true)
se_sum_true <- stats::sd(total_nll_true) / sqrt(length(total_nll_true))
mean_true_joint <- colMeans(ll_true_joint)
se_true_joint   <- apply(ll_true_joint, 2, stderr)
total_nll_true_joint <- rowSums(ll_true_joint)
se_sum_true_joint <- stats::sd(total_nll_true_joint) /
sqrt(length(total_nll_true_joint))
mean_trtf <- colMeans(ll_trtf)
se_trtf   <- apply(ll_trtf, 2, stderr)
total_nll_trtf <- rowSums(ll_trtf)
se_sum_trtf <- stats::sd(total_nll_trtf) / sqrt(length(total_nll_trtf))
fmt <- function(m, se) sprintf("%.2f ± %.2f", round(m, 2), round(2 * se, 2))
tab <- data.frame(
dim = as.character(seq_len(K)),
distribution = sapply(config, `[[`, "distr"),
true = fmt(mean_true, se_true),
true_joint = fmt(mean_true_joint, se_true_joint),
trtf = fmt(mean_trtf, se_trtf),
ttm  = fmt(mean_ttm, se_ttm),
ttm_sep = fmt(mean_sep, se_sep),
ttm_cross = fmt(mean_cross, se_cross),
stringsAsFactors = FALSE
)
sum_row <- data.frame(
dim = "k",
distribution = "SUM",
true = fmt(sum(mean_true), se_sum_true),
true_joint = fmt(sum(mean_true_joint), se_sum_true_joint),
trtf = fmt(sum(mean_trtf), se_sum_trtf),
ttm  = fmt(sum(mean_ttm),  se_sum_ttm),
ttm_sep = fmt(sum(mean_sep),  se_sum_sep),
ttm_cross = fmt(sum(mean_cross), se_sum_cross),
stringsAsFactors = FALSE
)
tab <- rbind(tab, sum_row)
nm <- names(tab)
nm[nm == "true"] <- "True (marginal)"
nm[nm == "true_joint"] <- "True (Joint)"
nm[nm == "trtf"] <- "Random Forest"
nm[nm == "ttm"]  <- "Marginal Map"
nm[nm == "ttm_sep"] <- "Separable Map"
nm[nm == "ttm_cross"] <- "Cross-term Map"
names(tab) <- nm
message("Ergebnis (NLL in nats; lower is better)")
tab
}
### End 04_evaluation.R ###

### Begin main.R ###
source("00_globals.R")
if (!exists("%||%")) "%||%" <- function(a, b) if (is.null(a)) b else a
source("01_data_generation.R")
source("02_split.R")
source("models/true_model.R")
source("models/trtf_model.R")
source("models/ttm_marginal.R")
source("models/ttm_separable.R")
source("models/ttm_cross_term.R")
source("models/true_joint_model.R")
source("04_evaluation.R")
source("replicate_code.R")
n <- 50
config <- list(
list(distr = "norm", parm = NULL),
list(distr = "exp",  parm = function(d) list(rate = softplus(d$X1))),
list(distr = "beta",
parm = function(d) list(shape1 = softplus(d$X2),
shape2 = softplus(d$X1))),
list(distr = "gamma",
parm = function(d) list(shape = softplus(d$X3),
scale = softplus(d$X2)))
)
main <- function() {
set.seed(42)
prep <- prepare_data(n, config, seed = 42)
mods <- list(
true = fit_TRUE(prep$S, config),
true_joint = fit_TRUE_JOINT(prep$S, config),
trtf = fit_TRTF(prep$S, config, seed = 42),
ttm  = trainMarginalMap(prep$S),
ttm_sep = trainSeparableMap(prep$S),
ttm_cross = trainCrossTermMap(prep$S)
)
tab <- calc_loglik_tables(mods, config, prep$S$X_te)
print(tab)
results_table <<- tab
invisible(tab)
}
if (sys.nframe() == 0L) {
main()
replicate_code_scripts("main.R", "replicated_code.txt", env = globalenv())
}
### End main.R ###

### Final results table ###
  dim distribution True (marginal) True (Joint) Random Forest Marginal Map
1   1         norm     1.55 ± 0.47  1.54 ± 0.48   1.62 ± 0.42  1.57 ± 0.38
2   2          exp     1.65 ± 0.63  1.65 ± 0.87   2.73 ± 1.00  3.30 ± 0.01
3   3         beta    -0.75 ± 1.23 -1.23 ± 1.69  -0.12 ± 0.52  0.41 ± 0.22
4   4        gamma     2.93 ± 1.97  2.25 ± 1.47   2.72 ± 1.98  3.32 ± 1.45
5   k          SUM     5.38 ± 2.03  4.21 ± 2.17   6.95 ± 3.02  8.59 ± 1.77
  Separable Map Cross-term Map
1   1.55 ± 0.47    1.50 ± 0.46
2   1.91 ± 0.65    2.92 ± 1.21
3  -0.00 ± 0.63   -0.75 ± 1.20
4   3.36 ± 2.68    1.72 ± 1.03
5   6.81 ± 3.36    5.38 ± 1.54

