Nachfolgend eine **modulare Skript-Gliederung** (Dateien `.R`), wobei innerhalb jeder Datei nur **algorithmischer Pseudocode** steht.
Jeder Block beschreibt

* Zweck der Datei
* Wichtigste Funktionen (Prozeduren)
* Mathematisch pr√§zise Schritte, gegliedert in Unterpunkte

Dadurch kann man die `config`-Liste oder die Zahl der Dimensionen $K$ √§ndern, ohne irgendeine andere Datei anfassen zu m√ºssen, und jederzeit neue Modelle nachr√ºsten.

---

### **Script 1: 00\_globals.R**

```


FUNCTION setup_global():
    INPUT  : ‚Äî
    OUTPUT : list G = (N, config, seed, split_ratio, H_grid, model_ids, P_max)

    1  N           ‚Üê 500                                 # Stichprobenumfang
    2  config      ‚Üê USER-EINGABE                        # Liste mit K Elementen
    3  seed        ‚Üê 42                                  # Reproduzierbarkeit
    4  split_ratio ‚Üê 0.70                                # Train-Anteil
    5  P_max       ‚Üê 6                                   # h√∂chster Polynomgrad
    6  H_grid      ‚Üê {h ‚àà ‚Ñï | 1 ‚â§ h ‚â§ P_max}             # Gradbeschr√§nkung
    7  model_ids   ‚Üê {"TRUE"}                             # erweiterbar
    8  RETURN G
```

---

### **Script 2: 01\_data\_generation.R**

```
FUNCTION gen_samples(G):
    INPUT : G = (N, config, seed, ‚Ä¶)
    OUTPUT: Matrix X ‚àà ‚Ñù^{N√óK}         # gleiche Reihenfolge wie config

    1  SET rng ‚Üê seed
    2  K ‚Üê |config|
    3  INIT X ‚Üê matrix(NA, N, K)
    4  FOR i = 1,‚Ä¶,N:
    5      FOR k = 1,‚Ä¶,K:                        # sequentiell ‚áí bedingt
    6          c_k      ‚Üê config[k]
    7          params_k ‚Üê
                 IF is.null(c_k.parm)
                 THEN {}
                 ELSE c_k.parm( X[i, 1:(k‚àí1)] )
    8          IF c_k.distr = "gamma" ‚àß {shape1, shape2} ‚äÇ names(params_k):
                 params_k ‚Üê {shape = params_k.shape1,
                              scale = params_k.shape2}
    9          FOR p ‚àà params_k:
                 IF ¬¨finite(p) ‚à® p ‚â§ 0: p ‚Üê 1e‚àí3
   10          fun ‚Üê get("r" ++ c_k.distr)
   11          X[i,k]  ‚Üê fun(1, params_k)
   12  SET colnames(X) ‚Üê {"X1",‚Ä¶,"XK"}
   13  RETURN X
```

Die Generierung nutzt die jeweiligen Basisfunktionen `r<distr>` aus R und
ersetzt ung√ºltige Parameter (‚â§0 oder nicht endlich) durch `1e‚àí3`.

---

### **Script 3: 02\_split.R**

```
FUNCTION train_test_split(X, split_ratio, seed):
    INPUT : Datenmatrix X, split-Ratio r, seed
    OUTPUT: list S = (X_tr, X_te)

    1  SET rng ‚Üê seed + 1              # anderer Stream
    2  idx   ‚Üê random_permutation(1,‚Ä¶,N)
    3  N_tr  ‚Üê ‚åär¬∑N‚åã
    4  X_tr  ‚Üê X[ idx[1:N_tr],  ]
    5  X_te  ‚Üê X[ idx[N_tr+1:N], ]
    6  RETURN S
```

---


### **Script 4 (neu): models/**`triangular_transport_map.R`

> **Ziel**‚ÄÉTriangul√§re **Transport Map**
>
> $$
> S_\theta(x)=\bigl(S_1(x_1),\,S_2(x_{1:2}),\dots,S_K(x_{1:K})\bigr)^\top,\qquad  
> S_k = g_k(x_{1:k-1};\beta_k) \;+\; f_k(x_k;\alpha_k)
> $$
>
> *Alle* numerisch kritischen Schritte laufen **im Log-Raum**.

---

#### 4.1 Hilfsfunktionen (Log-Raum)

```
FUNCTION log_phi_K(z):
    # log-Dichte der K-dimensionalen Standardnormalen
    RETURN ‚àí0.5 * (K * log(2œÄ) + ||z||¬≤)

FUNCTION logsumexp(v):
    m ‚Üê max(v)
    RETURN m + log( Œ£ exp(v ‚àí m) )

FUNCTION poly_deg(h)(t ; Œ≥):
    # schlichtes Polynom   Œ£_{j=0}^h Œ≥_j t^j
    RETURN Œ£_{j=0}^h Œ≥_j * t^j

FUNCTION f_k (x_k ; Œ±_k, h):
    # monotone 1-D Komponente ‚ÄÉ‚ÄÉf_k = ‚à´‚ÇÄ^{x_k} exp( poly_deg(h)(t;Œ±_k) ) dt
    # (=> immer streng steigend, kein Overflow dank Log-Raum)
    logI ‚Üê log_integrate_exp( Œª t: poly_deg(h)(t;Œ±_k), 0, x_k )
    RETURN exp( logI )

FUNCTION log_fprime_k (x_k ; Œ±_k, h):
    # log f'_k(x_k) = poly_deg(h)( x_k ; Œ±_k )
    RETURN poly_deg(h)( x_k ; Œ±_k )
```

*(`log_integrate_exp` wie im alten Skript; wird nur f√ºr $f_k$ gebraucht.)*

---

#### 4.2 Map $S_\theta$, Jacobian-Logdet und Log-Likelihood

```
FUNCTION S(x ; Œ∏=(Œ≤,Œ±), h):
    INPUT  : x ‚àà ‚Ñù^K
    OUTPUT : z ‚àà ‚Ñù^K

    FOR k = 1,‚Ä¶,K:
        g_k ‚Üê poly_deg(h)( x[1:(k‚àí1)] ; Œ≤_k )        # nur fr√ºhere Coordinates
        f_k_val ‚Üê f_k( x_k ; Œ±_k , h )                # 1-D, streng steigend
        z_k ‚Üê g_k + f_k_val
    RETURN z
```

```
FUNCTION logJ(x ; Œ∏, h):
    # log |det ‚àáS| = Œ£_k log f'_k(x_k)
    logdet ‚Üê 0
    FOR k = 1,‚Ä¶,K:
        logdet ‚Üê logdet + log_fprime_k( x_k ; Œ±_k , h )
    RETURN logdet
```

```
FUNCTION ‚Ñì(Œ∏ | x, h):
    z      ‚Üê S(x ; Œ∏ , h)
    RETURN log_phi_K(z) + logJ(x ; Œ∏ , h)      # sample-LogLikelihood
```

---

#### 4.3 Training (empirische KL / ‚Äìlog L)

```
FUNCTION ùîè_train(Œ∏ | h, X_tr):
    RETURN ‚àí (1/|X_tr|) * Œ£_{x ‚àà X_tr} ‚Ñì(Œ∏ | x , h)
```

```
FUNCTION fit_SEPAR(X_tr, X_te, H_grid):
    INPUT  : Trainings-/Testdaten, Polynomgrade
    OUTPUT : M_SEP = (Œ∏*, h*, logL_te*)

    FOR h ‚àà H_grid:
        Œ∏‚Å∞      ‚Üê 0
        Œ∏ÃÇ(h)   ‚Üê argmin_Œ∏  ùîè_train(Œ∏ | h, X_tr)     # L-BFGS-B
                  stop wenn ||‚àáùîè_train||_‚àû < 1e‚àí6
        logL_te(h) ‚Üê ‚àí (1/|X_te|) Œ£_{x ‚àà X_te} ‚Ñì( Œ∏ÃÇ(h) | x , h )
        MESSAGE "h={h}, logL_te={logL_te(h)}"

    h*  ‚Üê argmin_h logL_te(h)
    Œ∏*  ‚Üê Œ∏ÃÇ(h*)
    RETURN (Œ∏*, h*, logL_te(h*))
```

```
FUNCTION logL_SEPAR(M_SEP, X):
    (Œ∏*, h*) ‚Üê M_SEP
    RETURN ‚àí (1/|X|) Œ£_{x ‚àà X} ‚Ñì( Œ∏*, x , h* )
```

---

#### 4.4 Sampling und Dichtesch√§tzung

```
FUNCTION sample_SEPAR(M_SEP, Z):
    INPUT  : Z ~ N(0,I_K)
    OUTPUT : X  via sequentielle Inversion

    (Œ∏*, h*) ‚Üê M_SEP
    FOR k = 1,‚Ä¶,K:
        g_k ‚Üê poly_deg(h*)( X[1:(k‚àí1)] ; Œ≤*_k )
        # l√∂se   f_k(x_k) = Z_k ‚àí g_k   nach x_k  (1-D root-finding, z.B. Newton)
        x_k ‚Üê invert_f_k( Z_k ‚àí g_k ; Œ±*_k , h* )
        X_k ‚Üê x_k
    RETURN X
```

```
FUNCTION density_SEPAR(M_SEP, x):
    z      ‚Üê S(x ; Œ∏*, h*)
    logdet ‚Üê logJ(x ; Œ∏*, h*)
    RETURN exp( log_phi_K(z) + logdet )        # œÄÃÇ(x)
```

`invert_f_k` benutzt z.B. Newton‚ÄìRaphson mit Startwert $x_k^{(0)} = Z_k$; nur $f_k$ und $f'_k$ n√∂tig.



---

### **Script 5: models/true\_model.R**  (‚Äûwahrer‚Äú Baseline-MLE)

```
FUNCTION fit_TRUE(X_tr, X_te, config):
    INPUT : X_tr, X_te, config
    OUTPUT: M_TRUE = (ŒòÃÇ, logL_te)

    FOR k = 1,‚Ä¶,K:
        distr_k ‚Üê config[k].distr
        ŒòÃÇ_k    ‚Üê argmax_Œ∏_k Œ£_{x‚ààX_tr[,k]} log f_{distr_k}(x | Œ∏_k)   # wie bisher
                 # in der Implementierung ist log f() ohnehin im Log-Raum
    logL_te ‚Üê ‚àí |X_te|^{-1} Œ£_i Œ£_k log f_{distr_k}( X_te[i,k] | ŒòÃÇ_k )
    RETURN (ŒòÃÇ, logL_te)

FUNCTION logL_TRUE(M_TRUE, X):
    RETURN ‚àí |X|^{-1} Œ£_i Œ£_k log f_{distr_k}( X[i,k] | ŒòÃÇ_k )


```

*Anmerkung:* Jede Dimension wird unabh√§ngig behandelt, denn ‚Äûwahrer‚Äú Mechanismus kennt die bedingten Dichten.

---

### **Script 6: 04\_evaluation.R**

```
FUNCTION evaluate_all(X_te, model_list):
    INPUT : Testdaten X_te, Liste model_list = {M_TRUE, ‚Ä¶}
    OUTPUT: Tabelle P = (model_id, ‚àílogL_te)

    1  INIT empty table P
    2  FOR i = 1,‚Ä¶,|model_list|:
    3      id   ‚Üê names(model_list)[i]
    4      M    ‚Üê model_list[[i]]
    5      loss ‚Üê logL_<id>(M, X_te)            # dynamischer Funktionsaufruf
    6      append_row(P, (id, loss))
    7  sort_by loss ascending
    8  RETURN P
```

`model_specific_logL` ruft intern `logL_TRUE` oder eine Analogie f√ºr k√ºnftige Modelle.

---

### **Script 7: 05\_main.R**  (Orchestrator)

```
config <- list(
  list(distr = "norm", parm = NULL),
  list(distr = "exp",  parm = function(d) list(rate = d$X1)),
  list(distr = "beta", parm = function(d) list(shape1 = softplus(d$X2), shape2 = 1)),
  list(distr = "gamma", parm = function(d) list(shape = softplus(d$X3), scale = 1))
)

FUNCTION main():
    1  G        ‚Üê setup_global()                    # Script 1
    2  X        ‚Üê gen_samples(G)                    # Script 2
    3  S        ‚Üê train_test_split(X, G.split_ratio, G.seed)   # Script 3
    4  M_TRUE   ‚Üê fit_TRUE(S.X_tr, S.X_te, G.config) # Script 5
    5  results  ‚Üê evaluate_all(S.X_te, {M_TRUE})      # Script 6
    7  print(results)
    8  # einfache M√∂glichkeit, weitere Modelle:
       # Quellcode in models/<neues>.R mit
       #   fit_<NAME>()  und  logL_<NAME>()
       # anschlie√üend hier einfach laden & anh√§ngen.
```

---
