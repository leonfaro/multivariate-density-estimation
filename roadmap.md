Nachfolgend eine **modulare Skript-Gliederung** (Dateien `.R`), wobei innerhalb jeder Datei nur **algorithmischer Pseudocode** steht.
Jeder Block beschreibt

* Zweck der Datei
* Wichtigste Funktionen (Prozeduren)
* Mathematisch pr√§zise Schritte, gegliedert in Unterpunkte

Dadurch kann man die `config`-Liste oder die Zahl der Dimensionen $K$ √§ndern, ohne irgendeine andere Datei anfassen zu m√ºssen, und jederzeit neue Modelle nachr√ºsten.

---

### **Script 1: 00\_globals.R**

```
FUNCTION setup_global():
    INPUT: ‚Äî
    OUTPUT: list G = (N, config, seed, split_ratio, H_grid, model_ids)

    1  N            ‚Üê 500                                # Stichprobenumfang
    2  config       ‚Üê USER-EINGABE                       # Liste mit K Elementen
    3  seed         ‚Üê 42                                 # Reproduzierbarkeit
    4  split_ratio  ‚Üê 0.70                               # Train-Anteil
    5  H_grid       ‚Üê {p ‚àà ‚Ñï | 1 ‚â§ p ‚â§ P_max}            # Hyperparameter f√ºr TTM
    6  model_ids    ‚Üê {"TTM", "TRUE"}                    # erweiterbar
    7  RETURN G
```

---

### **Script 2: 01\_data\_generation.R**

```
FUNCTION gen_samples(G):
    INPUT : G = (N, config, seed, ‚Ä¶)
    OUTPUT: Matrix X ‚àà ‚Ñù^{N√óK}         # gleiche Reihenfolge wie config

    1  SET rng ‚Üê seed
    2  FOR i = 1,‚Ä¶,N:
    3      FOR k = 1,‚Ä¶,K:                        # sequentiell ‚áí bedingt
    4          c_k      ‚Üê config[k]
    5          params_k ‚Üê
                 IF is.null(c_k.parm)
                 THEN {}
                 ELSE c_k.parm( X[i, 1:(k‚àí1)] )  # greift auf fr√ºhere Spalten
    6          X[i,k]  ‚Üê draw_from( c_k.distr , params_k )
    7  RETURN X
```

*`draw_from`* ist eine generische Hilfsroutine (z. B. Norm, Gamma usw.).

---

### **Script 3: 02\_split.R**

```
FUNCTION train_test_split(X, split_ratio, seed):
    INPUT : Datenmatrix X, split-Ratio r, seed
    OUTPUT: list S = (X_tr, X_te)

    1  SET rng ‚Üê seed + 1              # anderer Stream
    2  idx   ‚Üê random_permutation(1,‚Ä¶,N)
    3  N_tr  ‚Üê ‚åär¬∑N‚åã
    4  X_tr  ‚Üê X[ idx[1:N_tr],  ]
    5  X_te  ‚Üê X[ idx[N_tr+1:N], ]
    6  RETURN S
```

---

### **Script 4: models/ttm\_model.R**  (Referenz-Modell aus dem Paper)

```
FUNCTION fit_TTM(X_tr, H_grid):
    INPUT : Trainingsdaten X_tr, Hyperparameter-Grid H_grid
    OUTPUT: model M_TTM = (Œ∏*, h*, logL_te)

    1  FOR each h ‚àà H_grid:                          # z. B. Polynomiellgrad
    2      Œ∏ÃÇ(h) ‚Üê argmin_Œ∏  ùîè_train(Œ∏ | h)           # s. Block 4 oben
                       subject to Œ∏_{k,j}^f ‚â• 0
    3      logL_te(h) ‚Üê ‚àí  |X_te|^{-1}   Œ£_{x ‚àà X_te}  ‚Ñì_{Œ∏ÃÇ(h)}(x)
    4  h*    ‚Üê argmin_h  logL_te(h)
    5  Œ∏*    ‚Üê Œ∏ÃÇ(h*)
    6  RETURN (Œ∏*, h*, logL_te(h*))

FUNCTION logL_TTM(M_TTM, X):
    INPUT : Modell (Œ∏*, ‚Ä¶), Datenmatrix X
    OUTPUT: ‚àílog-Likelihood pro Beobachtung
```

*Subschritte*:

* $‚Ñì_{Œ∏}(x)$ und $ùîè_\text{train}$ exakt wie im vorherigen Post.
* Optimierung via LBFGS-B (weil lineare Ungleichungen).

---

### **Script 5: models/true\_model.R**  (‚Äûwahrer‚Äú Baseline-MLE)

```
FUNCTION fit_TRUE(X_tr, config):
    INPUT : Trainingsdaten X_tr, vollst√§ndige Verteilungskonfiguration
    OUTPUT: model M_TRUE = (ŒòÃÇ, logL_te)

    1  FOR k = 1,‚Ä¶,K:
    2      distr_k ‚Üê config[k].distr
    3      # univariate MLE f√ºr jeden k getrennt
    4      ŒòÃÇ_k   ‚Üê argmax_Œ∏_k   Œ£_{x‚ààX_tr[,k]}  log f_{distr_k}(x | Œ∏_k)
                       via optim()
    5  logL_te ‚Üê ‚àí |X_te|^{-1} Œ£_{i} Œ£_{k} log f_{distr_k}(X_te[i,k] | ŒòÃÇ_k)
    6  RETURN (ŒòÃÇ, logL_te)

FUNCTION logL_TRUE(M_TRUE, X):
    INPUT : (ŒòÃÇ,‚Ä¶), Datenmatrix X
    OUTPUT: ‚àílog-Likelihood pro Beobachtung
```

*Anmerkung:* Jede Dimension wird unabh√§ngig behandelt, denn ‚Äûwahrer‚Äú Mechanismus kennt die bedingten Dichten.

---

### **Script 6: 04\_evaluation.R**

```
FUNCTION evaluate_all(X_te, model_list):
    INPUT : Testdaten X_te, Liste model_list = {M_TTM, M_TRUE, ‚Ä¶}
    OUTPUT: Tabelle P = (model_id, ‚àílogL_te)

    1  INIT empty table P
    2  FOR each M in model_list:
    3      id ‚Üê model_name(M)
    4      loss ‚Üê model_specific_logL(M, X_te)
    5      append_row(P, (id, loss))
    6  sort_by loss ascending
    7  RETURN P
```

`model_specific_logL` ruft intern `logL_TTM`, `logL_TRUE`, oder eine Analogie f√ºr k√ºnftige Modelle.

---

### **Script 7: 05\_main.R**  (Orchestrator)

```
FUNCTION main():
    1  G        ‚Üê setup_global()                    # Script 1
    2  X        ‚Üê gen_samples(G)                    # Script 2
    3  S        ‚Üê train_test_split(X, G.split_ratio, G.seed)   # Script 3
    4  M_TTM    ‚Üê fit_TTM (S.X_tr, G.H_grid)        # Script 4
    5  M_TRUE   ‚Üê fit_TRUE(S.X_tr, G.config)        # Script 5
    6  results  ‚Üê evaluate_all(S.X_te, {M_TTM, M_TRUE})   # Script 6
    7  print(results)
    8  # einfache M√∂glichkeit, weitere Modelle:
       # Quellcode in models/<neues>.R mit
       #   fit_<NAME>()  und  logL_<NAME>()
       # anschlie√üend hier einfach laden & anh√§ngen.
```

---

## **Wie man die Flexibilit√§t nutzt**

1. **Dimensionalit√§t √§ndern**
   *Passe nur* `config` in `00_globals.R` an.
   Das Sampling in `01_data_generation.R` sowie alle Schleifen √ºber $k=1,\dots,K$ adaptieren automatisch.

2. **Andere Bedingungsstrukturen**
   Ersetze in `config[[k]]$parm` die Funktion, die aus den bereits generierten Spalten Parameter ableitet.
   Kein weiterer Code muss ge√§ndert werden.

3. **Neues Modell hinzuf√ºgen**

   * Datei `models/<neues_modell>.R` anlegen
   * Zwei Funktionen implementieren: `fit_<NAME>()`, `logL_<NAME>()`
   * In `00_globals.R` den Namen ins Set `model_ids` und in `05_main.R` nach dem Fitting in `evaluate_all` √ºbergeben.

4. **Hyperparameter-Sweep ver√§ndern**
   Ausschlie√ülich `H_grid` in `00_globals.R` anpassen.

Damit bleibt das Gesamtsystem **skript-modular** und **konfigurationsgetrieben**: s√§mtliche Pipeline-√Ñnderungen erfolgen, ohne andere Dateien ‚Äûanzufassen‚Äú oder internen Code umschreiben zu m√ºssen.

