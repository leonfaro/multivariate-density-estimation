Nachfolgend eine **modulare Skript-Gliederung** (Dateien `.R`), wobei innerhalb jeder Datei nur **algorithmischer Pseudocode** steht.
Jeder Block beschreibt

* Zweck der Datei
* Wichtigste Funktionen (Prozeduren)
* Mathematisch prÃ¤zise Schritte, gegliedert in Unterpunkte

Dadurch kann man die `config`-Liste oder die Zahl der Dimensionen $K$ Ã¤ndern, ohne irgendeine andere Datei anfassen zu mÃ¼ssen, und jederzeit neue Modelle nachrÃ¼sten.

---

### **Script 1: 00\_globals.R**

```
FUNCTION setup_global():
    INPUT  : â€”
    OUTPUT : list G = (N, config, seed, split_ratio, H_grid, model_ids, P_max)

    1  N           â† 500                                 # Stichprobenumfang
    2  config      â† USER-EINGABE                        # Liste mit K Elementen
    3  seed        â† 42                                  # Reproduzierbarkeit
    4  split_ratio â† 0.70                                # Train-Anteil
    5  P_max       â† 6                                   # hÃ¶chster Polynomgrad
    6  H_grid      â† {h âˆˆ â„• | 1 â‰¤ h â‰¤ P_max}             # Hyperparameter fÃ¼r TTM
    7  model_ids   â† {"TTM", "TRUE"}                     # erweiterbar
    8  RETURN G
```

---






### **Script 2: 01\_data\_generation.R**

```
FUNCTION gen_samples(G):
    INPUT : G = (N, config, seed, â€¦)
    OUTPUT: Matrix X âˆˆ â„^{NÃ—K}         # gleiche Reihenfolge wie config

    1  SET rng â† seed
    2  FOR i = 1,â€¦,N:
    3      FOR k = 1,â€¦,K:                        # sequentiell â‡’ bedingt
    4          c_k      â† config[k]
    5          params_k â†
                 IF is.null(c_k.parm)
                 THEN {}
                 ELSE c_k.parm( X[i, 1:(kâˆ’1)] )  # greift auf frÃ¼here Spalten
    6          X[i,k]  â† draw_from( c_k.distr , params_k )
    7  RETURN X
```

*`draw_from`* ist eine generische Hilfsroutine (z. B. Norm, Gamma usw.).

---

### **Script 3: 02\_split.R**

```
FUNCTION train_test_split(X, split_ratio, seed):
    INPUT : Datenmatrix X, split-Ratio r, seed
    OUTPUT: list S = (X_tr, X_te)

    1  SET rng â† seed + 1              # anderer Stream
    2  idx   â† random_permutation(1,â€¦,N)
    3  N_tr  â† âŒŠrÂ·NâŒ‹
    4  X_tr  â† X[ idx[1:N_tr],  ]
    5  X_te  â† X[ idx[N_tr+1:N], ]
    6  RETURN S
```

---

### **Script 4: models/ttm\_model.R**  (Referenz-Modell aus dem Paper)

```
FUNCTION fit_TTM(X_tr, X_te, H_grid):
    INPUT  : TrainingsÂ­daten X_tr, TestÂ­daten X_te, Hyperparameter-Menge H_grid
    OUTPUT : model M_TTM = (Î¸*, h*, logL_te)

    # -------- Hilfsdefinitionen --------
    DEFINE  S(x ; Î¸, h)         # Triangular Transport-Map
            logJ(x ; Î¸, h)      # Log-Jacobi-Determinante
            â„“(Î¸ | x, h)         = log Ï†_K ( S(x; Î¸,h) ) + logJ(x; Î¸,h)
            ğ”_train(Î¸ | h)      = âˆ’ |X_tr|^{-1} Î£_{xâˆˆX_tr} â„“(Î¸ | x, h)

    FOR each h âˆˆ H_grid:
        1  INIT Î¸^(0) â† 0                      # alle Koeffizienten = 0
        2  Î¸Ì‚(h) â† argmin_Î¸  ğ”_train(Î¸ | h)    # L-BFGS-B  ohne Box-Constraints
                    stopping rule:  â€–âˆ‡ğ”_trainâ€–_âˆ < 10^{âˆ’6}
        3  logL_te(h) â† âˆ’ |X_te|^{-1} Î£_{xâˆˆX_te} â„“( Î¸Ì‚(h) | x , h )
        4  MESSAGE "h={h}, logL_te={logL_te(h)}"

    5  h* â† argmin_h  logL_te(h)
    6  Î¸* â† Î¸Ì‚(h*)
    7  RETURN (Î¸*, h*, logL_te(h*))

FUNCTION S(x ; Î¸, h):
    INPUT  : Beobachtung x=(xâ‚,â€¦,x_K), Parameter Î¸=(Î¸â‚,â€¦,Î¸_K), Polynomgrad h
    OUTPUT : z = (zâ‚,â€¦,z_K)

    FOR k = 1,â€¦,K:
        1  g_k â† Polynom_{Grad=h}( xâ‚,â€¦,x_{kâˆ’1} ; Î²_k )
        2  P_k(t, xâ‚:_{kâˆ’1}) â† Polynom_{Grad=h}( t, xâ‚,â€¦,x_{kâˆ’1} ; Î±_{k} )
             # P_k linear in den Koeffizienten, keine t-Konstante
        3  z_k â† g_k  +  âˆ«_{0}^{x_k}  exp( P_k( t, xâ‚:_{kâˆ’1} ) ) dt
    RETURN z

FUNCTION logJ(x ; Î¸, h):
    INPUT  : x, Î¸, h
    OUTPUT : Î£_{k=1}^{K}  P_k( x_k , xâ‚:_{kâˆ’1} )

FUNCTION logL_TTM(M_TTM, X):
    INPUT  : Modell M_TTM = (Î¸*, h*, â€¦), Datenmatrix X
    OUTPUT : âˆ’ |X|^{-1} Î£_{xâˆˆX} â„“( Î¸*, x , h* )

FUNCTION sample_TTM(M_TTM, Z):
    # optional fÃ¼r Diagnosen
    INPUT  : Modell M_TTM, Z ~ N(0, I_K)
    OUTPUT : X ~ Ï€Ì‚  via sequentielle Inversion der S_k
```


---

### **Script 5: models/true\_model.R**  (â€wahrerâ€œ Baseline-MLE)

```
FUNCTION fit_TRUE(X_tr, X_te, config):
    INPUT : Trainingsdaten X_tr, Testdaten X_te, vollstÃ¤ndige Verteilungskonfiguration
    OUTPUT: model M_TRUE = (Î˜Ì‚, logL_te)

    1  FOR k = 1,â€¦,K:
    2      distr_k â† config[k].distr
    3      # univariate MLE fÃ¼r jeden k getrennt
    4      Î˜Ì‚_k   â† argmax_Î¸_k   Î£_{xâˆˆX_tr[,k]}  log f_{distr_k}(x | Î¸_k)
                       via optim()
    5  logL_te â† âˆ’ |X_te|^{-1} Î£_{i} Î£_{k} log f_{distr_k}(X_te[i,k] | Î˜Ì‚_k)
    6  RETURN (Î˜Ì‚, logL_te)

FUNCTION logL_TRUE(M_TRUE, X):
    INPUT : (Î˜Ì‚,â€¦), Datenmatrix X
    OUTPUT: âˆ’log-Likelihood pro Beobachtung
```

*Anmerkung:* Jede Dimension wird unabhÃ¤ngig behandelt, denn â€wahrerâ€œ Mechanismus kennt die bedingten Dichten.

---

### **Script 6: 04\_evaluation.R**

```
FUNCTION evaluate_all(X_te, model_list):
    INPUT : Testdaten X_te, Liste model_list = {M_TTM, M_TRUE, â€¦}
    OUTPUT: Tabelle P = (model_id, âˆ’logL_te)

    1  INIT empty table P
    2  FOR i = 1,â€¦,|model_list|:
    3      id   â† names(model_list)[i]
    4      M    â† model_list[[i]]
    5      loss â† logL_<id>(M, X_te)            # dynamischer Funktionsaufruf
    6      append_row(P, (id, loss))
    7  sort_by loss ascending
    8  RETURN P
```

`model_specific_logL` ruft intern `logL_TTM`, `logL_TRUE`, oder eine Analogie fÃ¼r kÃ¼nftige Modelle.

---

### **Script 7: 05\_main.R**  (Orchestrator)

```
FUNCTION main():
    1  G        â† setup_global()                    # Script 1
    2  X        â† gen_samples(G)                    # Script 2
    3  S        â† train_test_split(X, G.split_ratio, G.seed)   # Script 3
    4  M_TTM    â† fit_TTM(S.X_tr, S.X_te, G.H_grid) # Script 4
    5  M_TRUE   â† fit_TRUE(S.X_tr, S.X_te, G.config) # Script 5
    6  results  â† evaluate_all(S.X_te, {M_TTM, M_TRUE})   # Script 6
    7  print(results)
    8  # einfache MÃ¶glichkeit, weitere Modelle:
       # Quellcode in models/<neues>.R mit
       #   fit_<NAME>()  und  logL_<NAME>()
       # anschlieÃŸend hier einfach laden & anhÃ¤ngen.
```

---

## **Wie man die FlexibilitÃ¤t nutzt**

1. **DimensionalitÃ¤t Ã¤ndern**
   *Passe nur* `config` in `00_globals.R` an.
   Das Sampling in `01_data_generation.R` sowie alle Schleifen Ã¼ber $k=1,\dots,K$ adaptieren automatisch.

2. **Andere Bedingungsstrukturen**
   Ersetze in `config[[k]]$parm` die Funktion, die aus den bereits generierten Spalten Parameter ableitet.
   Kein weiterer Code muss geÃ¤ndert werden.

3. **Neues Modell hinzufÃ¼gen**

   * Datei `models/<neues_modell>.R` anlegen
   * Zwei Funktionen implementieren: `fit_<NAME>()`, `logL_<NAME>()`
   * In `00_globals.R` den Namen ins Set `model_ids` und in `05_main.R` nach dem Fitting in `evaluate_all` Ã¼bergeben.

4. **Hyperparameter-Sweep verÃ¤ndern**
   AusschlieÃŸlich `H_grid` in `00_globals.R` anpassen.

Damit bleibt das Gesamtsystem **skript-modular** und **konfigurationsgetrieben**: sÃ¤mtliche Pipeline-Ã„nderungen erfolgen, ohne andere Dateien â€anzufassenâ€œ oder internen Code umschreiben zu mÃ¼ssen.

