power_file <- "/Users/leonkiafaro/Documents/multivariate-density-estimation/data/direct/power/data.npy"
x <- npyLoad(power_file)
set.seed(42);  x <- x[sample(nrow(x)), ]
train <- x[1:n_train, , drop = FALSE]
test  <- x[(n_train + 1):(n_train + n_test), , drop = FALSE]
mu <- colMeans(train);  sd <- apply(train, 2, sd)
train <- scale(train, center = mu, scale = sd)
test  <- scale(test,  center = mu, scale = sd)
## ---------- Legacy‑Funktionen  -------------------------------------
mytrtf <- function(data,
ntree = 50,
mtry = floor(sqrt(ncol(data) - 1)),
minsplit = 25,
minbucket = 20,
maxdepth = 4,
seed = 42,
cores_inner = NC,
trace = TRUE) {
library(trtf)
df <- as.data.frame(data)
set.seed(seed)
ymod <- lapply(colnames(df), function(y) BoxCox(as.formula(paste(y, "~ 1")), data = df))
fm   <- lapply(2:ncol(df), function(j) as.formula(paste(colnames(df)[j], "~",
paste(colnames(df)[1:(j - 1)], collapse = "+"))))
forests <- with_progress({
pg <- progressor(along = seq_along(fm))
lapply(seq_along(fm), function(j) {
pg(sprintf("%d/%d", j, length(fm)))
traforest(ymod[[j + 1L]], formula = fm[[j]], data = df,
ntree = ntree, mtry = mtry,
minsplit = minsplit, minbucket = minbucket, maxdepth = maxdepth,
trace = FALSE, cores = cores_inner)
})
})
structure(list(ymod = ymod, forests = forests), class = "mytrtf")
}
predict.mytrtf <- function(object, newdata, type = "logdensity") {
df_new <- as.data.frame(newdata)
ld1 <- predict(object$ymod[[1]], newdata = df_new, type = type)
ld  <- with_progress({
pg <- progressor(along = object$forests)
lapply(object$forests, function(frst) {
pg()
q <- df_new[, variable.names(frst$model)[1]]
diag(do.call(cbind, predict(frst, newdata = df_new, type = type, q = q)))
})
})
Reduce("+", ld) + ld1
}
## ---------- Fit & Test‑Evaluation ----------------------------------
t0 <- Sys.time()
final_model <- mytrtf(train,
ntree      = p$ntree,
mtry       = p$mtry,
minsplit   = p$minsplit,
minbucket  = p$minbucket,
maxdepth   = p$maxdepth,
seed       = seed_fit,
cores_inner = NC)
neg_avg_ll <- -mean(predict.mytrtf(final_model, test, type = "logdensity"))
elapsed <- as.numeric(difftime(Sys.time(), t0, units = "secs"))
cat(sprintf(
"\nPOWER – n_train=%d  n_test=%d  variant=%s  exec=%s\n   -avgLL=%.6f  runtime=%.1f s\n",
n_train, n_test, variant, exec_mode, neg_avg_ll, elapsed
))
library(trtf)
library(RcppCNPy)
library(future.apply)
library(progressr)
## --------- SCHALTER -----------------------------------------------
exec_mode <- "sequential"          # "sequential"  |  "multisession"
variant   <- "fast"            # "full" | "balanced" | "fast"
n_train   <- 50
n_test    <- 50
seed_fit  <- 4242
if (exec_mode == "multisession") plan(multisession) else plan(sequential)
handlers("txtprogressbar")
options(future.availableCores = parallel::detectCores())
(NC <- parallel::detectCores())
## ---------- Hyperparameter‑Presets ---------------------------------
config <- list(
full     = list(ntree = 500, mtry = 3, minsplit = 2,  minbucket = 1,  maxdepth = 30),
balanced = list(ntree = 100, mtry = 2, minsplit = 10, minbucket = 5,  maxdepth = 30),
fast     = list(ntree = 50,  mtry = 2, minsplit = 20, minbucket = 10, maxdepth = 15)
)
p <- config[[variant]]
## ---------- Data ---------------------------------------------------
power_file <- "/Users/leonkiafaro/Documents/multivariate-density-estimation/data/direct/power/data.npy"
x <- npyLoad(power_file)
set.seed(42);  x <- x[sample(nrow(x)), ]
train <- x[1:n_train, , drop = FALSE]
test  <- x[(n_train + 1):(n_train + n_test), , drop = FALSE]
mu <- colMeans(train);  sd <- apply(train, 2, sd)
train <- scale(train, center = mu, scale = sd)
test  <- scale(test,  center = mu, scale = sd)
## ---------- Legacy‑Funktionen  -------------------------------------
mytrtf <- function(data,
ntree = 50,
mtry = floor(sqrt(ncol(data) - 1)),
minsplit = 25,
minbucket = 20,
maxdepth = 4,
seed = 42,
cores_inner = NC,
trace = TRUE) {
library(trtf)
df <- as.data.frame(data)
set.seed(seed)
ymod <- lapply(colnames(df), function(y) BoxCox(as.formula(paste(y, "~ 1")), data = df))
fm   <- lapply(2:ncol(df), function(j) as.formula(paste(colnames(df)[j], "~",
paste(colnames(df)[1:(j - 1)], collapse = "+"))))
forests <- with_progress({
pg <- progressor(along = seq_along(fm))
lapply(seq_along(fm), function(j) {
pg(sprintf("%d/%d", j, length(fm)))
traforest(ymod[[j + 1L]], formula = fm[[j]], data = df,
ntree = ntree, mtry = mtry,
minsplit = minsplit, minbucket = minbucket, maxdepth = maxdepth,
trace = FALSE, cores = cores_inner)
})
})
structure(list(ymod = ymod, forests = forests), class = "mytrtf")
}
predict.mytrtf <- function(object, newdata, type = "logdensity") {
df_new <- as.data.frame(newdata)
ld1 <- predict(object$ymod[[1]], newdata = df_new, type = type)
ld  <- with_progress({
pg <- progressor(along = object$forests)
lapply(object$forests, function(frst) {
pg()
q <- df_new[, variable.names(frst$model)[1]]
diag(do.call(cbind, predict(frst, newdata = df_new, type = type, q = q)))
})
})
Reduce("+", ld) + ld1
}
## ---------- Fit & Test‑Evaluation ----------------------------------
t0 <- Sys.time()
final_model <- mytrtf(train,
ntree      = p$ntree,
mtry       = p$mtry,
minsplit   = p$minsplit,
minbucket  = p$minbucket,
maxdepth   = p$maxdepth,
seed       = seed_fit,
cores_inner = NC)
neg_avg_ll <- -mean(predict.mytrtf(final_model, test, type = "logdensity"))
elapsed <- as.numeric(difftime(Sys.time(), t0, units = "secs"))
cat(sprintf(
"\nPOWER – n_train=%d  n_test=%d  variant=%s  exec=%s\n   -avgLL=%.6f  runtime=%.1f s\n",
n_train, n_test, variant, exec_mode, neg_avg_ll, elapsed
))
library(trtf)
library(RcppCNPy)
library(future.apply)
library(progressr)
## --------- SCHALTER -----------------------------------------------
exec_mode <- "sequential"          # "sequential"  |  "multisession"
variant   <- "fast"            # "full" | "balanced" | "fast"
n_train   <- 500
n_test    <- 500
seed_fit  <- 4242
if (exec_mode == "multisession") plan(multisession) else plan(sequential)
handlers("txtprogressbar")
options(future.availableCores = parallel::detectCores())
(NC <- parallel::detectCores())
## ---------- Hyperparameter‑Presets ---------------------------------
config <- list(
full     = list(ntree = 500, mtry = 3, minsplit = 2,  minbucket = 1,  maxdepth = 30),
balanced = list(ntree = 100, mtry = 2, minsplit = 10, minbucket = 5,  maxdepth = 30),
fast     = list(ntree = 50,  mtry = 2, minsplit = 20, minbucket = 10, maxdepth = 15)
)
p <- config[[variant]]
## ---------- Data ---------------------------------------------------
power_file <- "/Users/leonkiafaro/Documents/multivariate-density-estimation/data/direct/power/data.npy"
x <- npyLoad(power_file)
set.seed(42);  x <- x[sample(nrow(x)), ]
train <- x[1:n_train, , drop = FALSE]
test  <- x[(n_train + 1):(n_train + n_test), , drop = FALSE]
mu <- colMeans(train);  sd <- apply(train, 2, sd)
train <- scale(train, center = mu, scale = sd)
test  <- scale(test,  center = mu, scale = sd)
## ---------- Legacy‑Funktionen  -------------------------------------
mytrtf <- function(data,
ntree = 50,
mtry = floor(sqrt(ncol(data) - 1)),
minsplit = 25,
minbucket = 20,
maxdepth = 4,
seed = 42,
cores_inner = NC,
trace = TRUE) {
library(trtf)
df <- as.data.frame(data)
set.seed(seed)
ymod <- lapply(colnames(df), function(y) BoxCox(as.formula(paste(y, "~ 1")), data = df))
fm   <- lapply(2:ncol(df), function(j) as.formula(paste(colnames(df)[j], "~",
paste(colnames(df)[1:(j - 1)], collapse = "+"))))
forests <- with_progress({
pg <- progressor(along = seq_along(fm))
lapply(seq_along(fm), function(j) {
pg(sprintf("%d/%d", j, length(fm)))
traforest(ymod[[j + 1L]], formula = fm[[j]], data = df,
ntree = ntree, mtry = mtry,
minsplit = minsplit, minbucket = minbucket, maxdepth = maxdepth,
trace = FALSE, cores = cores_inner)
})
})
structure(list(ymod = ymod, forests = forests), class = "mytrtf")
}
predict.mytrtf <- function(object, newdata, type = "logdensity") {
df_new <- as.data.frame(newdata)
ld1 <- predict(object$ymod[[1]], newdata = df_new, type = type)
ld  <- with_progress({
pg <- progressor(along = object$forests)
lapply(object$forests, function(frst) {
pg()
q <- df_new[, variable.names(frst$model)[1]]
diag(do.call(cbind, predict(frst, newdata = df_new, type = type, q = q)))
})
})
Reduce("+", ld) + ld1
}
## ---------- Fit & Test‑Evaluation ----------------------------------
t0 <- Sys.time()
final_model <- mytrtf(train,
ntree      = p$ntree,
mtry       = p$mtry,
minsplit   = p$minsplit,
minbucket  = p$minbucket,
maxdepth   = p$maxdepth,
seed       = seed_fit,
cores_inner = NC)
neg_avg_ll <- -mean(predict.mytrtf(final_model, test, type = "logdensity"))
elapsed <- as.numeric(difftime(Sys.time(), t0, units = "secs"))
cat(sprintf(
"\nPOWER – n_train=%d  n_test=%d  variant=%s  exec=%s\n   -avgLL=%.6f  runtime=%.1f s\n",
n_train, n_test, variant, exec_mode, neg_avg_ll, elapsed
))
library(trtf)
library(RcppCNPy)
library(future.apply)
library(progressr)
## --------- SCHALTER -----------------------------------------------
exec_mode <- "sequential"          # "sequential"  |  "multisession"
variant   <- "full"            # "full" | "balanced" | "fast"
n_train   <- 500
n_test    <- 500
seed_fit  <- 4242
if (exec_mode == "multisession") plan(multisession) else plan(sequential)
handlers("txtprogressbar")
options(future.availableCores = parallel::detectCores())
(NC <- parallel::detectCores())
## ---------- Hyperparameter‑Presets ---------------------------------
config <- list(
full     = list(ntree = 500, mtry = 3, minsplit = 2,  minbucket = 1,  maxdepth = 30),
balanced = list(ntree = 100, mtry = 2, minsplit = 10, minbucket = 5,  maxdepth = 30),
fast     = list(ntree = 50,  mtry = 2, minsplit = 20, minbucket = 10, maxdepth = 15)
)
p <- config[[variant]]
## ---------- Data ---------------------------------------------------
power_file <- "/Users/leonkiafaro/Documents/multivariate-density-estimation/data/direct/power/data.npy"
x <- npyLoad(power_file)
set.seed(42);  x <- x[sample(nrow(x)), ]
train <- x[1:n_train, , drop = FALSE]
test  <- x[(n_train + 1):(n_train + n_test), , drop = FALSE]
mu <- colMeans(train);  sd <- apply(train, 2, sd)
train <- scale(train, center = mu, scale = sd)
test  <- scale(test,  center = mu, scale = sd)
## ---------- Legacy‑Funktionen  -------------------------------------
mytrtf <- function(data,
ntree = 50,
mtry = floor(sqrt(ncol(data) - 1)),
minsplit = 25,
minbucket = 20,
maxdepth = 4,
seed = 42,
cores_inner = NC,
trace = TRUE) {
library(trtf)
df <- as.data.frame(data)
set.seed(seed)
ymod <- lapply(colnames(df), function(y) BoxCox(as.formula(paste(y, "~ 1")), data = df))
fm   <- lapply(2:ncol(df), function(j) as.formula(paste(colnames(df)[j], "~",
paste(colnames(df)[1:(j - 1)], collapse = "+"))))
forests <- with_progress({
pg <- progressor(along = seq_along(fm))
lapply(seq_along(fm), function(j) {
pg(sprintf("%d/%d", j, length(fm)))
traforest(ymod[[j + 1L]], formula = fm[[j]], data = df,
ntree = ntree, mtry = mtry,
minsplit = minsplit, minbucket = minbucket, maxdepth = maxdepth,
trace = FALSE, cores = cores_inner)
})
})
structure(list(ymod = ymod, forests = forests), class = "mytrtf")
}
predict.mytrtf <- function(object, newdata, type = "logdensity") {
df_new <- as.data.frame(newdata)
ld1 <- predict(object$ymod[[1]], newdata = df_new, type = type)
ld  <- with_progress({
pg <- progressor(along = object$forests)
lapply(object$forests, function(frst) {
pg()
q <- df_new[, variable.names(frst$model)[1]]
diag(do.call(cbind, predict(frst, newdata = df_new, type = type, q = q)))
})
})
Reduce("+", ld) + ld1
}
## ---------- Fit & Test‑Evaluation ----------------------------------
t0 <- Sys.time()
final_model <- mytrtf(train,
ntree      = p$ntree,
mtry       = p$mtry,
minsplit   = p$minsplit,
minbucket  = p$minbucket,
maxdepth   = p$maxdepth,
seed       = seed_fit,
cores_inner = NC)
neg_avg_ll <- -mean(predict.mytrtf(final_model, test, type = "logdensity"))
elapsed <- as.numeric(difftime(Sys.time(), t0, units = "secs"))
cat(sprintf(
"\nPOWER – n_train=%d  n_test=%d  variant=%s  exec=%s\n   -avgLL=%.6f  runtime=%.1f s\n",
n_train, n_test, variant, exec_mode, neg_avg_ll, elapsed
))
library(trtf)
library(RcppCNPy)
library(trtf)
library(RcppCNPy)
library(future.apply)
library(progressr)
## --------- SCHALTER -----------------------------------------------
exec_mode <- "sequential"          # "sequential"  |  "multisession"
variant   <- "full"            # "full" | "balanced" | "fast"
n_train   <- 500
n_test    <- 500
seed_fit  <- 4242
if (exec_mode == "multisession") plan(multisession) else plan(sequential)
handlers("txtprogressbar")
options(future.availableCores = parallel::detectCores())
(NC <- parallel::detectCores())
## ---------- Hyperparameter‑Presets ---------------------------------
config <- list(
full     = list(ntree = 500, mtry = 3, minsplit = 5,  minbucket = 2,  maxdepth = 30),
balanced = list(ntree = 100, mtry = 2, minsplit = 10, minbucket = 5,  maxdepth = 30),
fast     = list(ntree = 50,  mtry = 2, minsplit = 20, minbucket = 10, maxdepth = 15)
)
p <- config[[variant]]
## ---------- Data ---------------------------------------------------
power_file <- "/Users/leonkiafaro/Documents/multivariate-density-estimation/data/direct/power/data.npy"
x <- npyLoad(power_file)
set.seed(42);  x <- x[sample(nrow(x)), ]
train <- x[1:n_train, , drop = FALSE]
test  <- x[(n_train + 1):(n_train + n_test), , drop = FALSE]
mu <- colMeans(train);  sd <- apply(train, 2, sd)
train <- scale(train, center = mu, scale = sd)
test  <- scale(test,  center = mu, scale = sd)
## ---------- Legacy‑Funktionen  -------------------------------------
mytrtf <- function(data,
ntree = 50,
mtry = floor(sqrt(ncol(data) - 1)),
minsplit = 25,
minbucket = 20,
maxdepth = 4,
seed = 42,
cores_inner = NC,
trace = TRUE) {
library(trtf)
df <- as.data.frame(data)
set.seed(seed)
ymod <- lapply(colnames(df), function(y) BoxCox(as.formula(paste(y, "~ 1")), data = df))
fm   <- lapply(2:ncol(df), function(j) as.formula(paste(colnames(df)[j], "~",
paste(colnames(df)[1:(j - 1)], collapse = "+"))))
forests <- with_progress({
pg <- progressor(along = seq_along(fm))
lapply(seq_along(fm), function(j) {
pg(sprintf("%d/%d", j, length(fm)))
traforest(ymod[[j + 1L]], formula = fm[[j]], data = df,
ntree = ntree, mtry = mtry,
minsplit = minsplit, minbucket = minbucket, maxdepth = maxdepth,
trace = FALSE, cores = cores_inner)
})
})
structure(list(ymod = ymod, forests = forests), class = "mytrtf")
}
predict.mytrtf <- function(object, newdata, type = "logdensity") {
df_new <- as.data.frame(newdata)
ld1 <- predict(object$ymod[[1]], newdata = df_new, type = type)
ld  <- with_progress({
pg <- progressor(along = object$forests)
lapply(object$forests, function(frst) {
pg()
q <- df_new[, variable.names(frst$model)[1]]
diag(do.call(cbind, predict(frst, newdata = df_new, type = type, q = q)))
})
})
Reduce("+", ld) + ld1
}
## ---------- Fit & Test‑Evaluation ----------------------------------
t0 <- Sys.time()
final_model <- mytrtf(train,
ntree      = p$ntree,
mtry       = p$mtry,
minsplit   = p$minsplit,
minbucket  = p$minbucket,
maxdepth   = p$maxdepth,
seed       = seed_fit,
cores_inner = NC)
library(trtf)
library(trtf)
library(RcppCNPy)
library(future.apply)
library(progressr)
## --------- SCHALTER -----------------------------------------------
exec_mode <- "sequential"          # "sequential"  |  "multisession"
variant   <- "full"            # "full" | "balanced" | "fast"
n_train   <- 500
n_test    <- 500
seed_fit  <- 4242
if (exec_mode == "multisession") plan(multisession) else plan(sequential)
handlers("txtprogressbar")
options(future.availableCores = parallel::detectCores()-2)
(NC <- parallel::detectCores())
(NC <- parallel::detectCores()-2)
library(trtf)
library(RcppCNPy)
library(future.apply)
library(progressr)
## --------- SCHALTER -----------------------------------------------
exec_mode <- "sequential"          # "sequential"  |  "multisession"
variant   <- "full"            # "full" | "balanced" | "fast"
n_train   <- 500
n_test    <- 500
seed_fit  <- 4242
if (exec_mode == "multisession") plan(multisession) else plan(sequential)
handlers("txtprogressbar")
options(future.availableCores = parallel::detectCores()-2)
(NC <- parallel::detectCores()-2)
## ---------- Hyperparameter‑Presets ---------------------------------
config <- list(
full     = list(ntree = 500, mtry = 3, minsplit = 10,  minbucket = 5,  maxdepth = 30),
balanced = list(ntree = 100, mtry = 2, minsplit = 10, minbucket = 5,  maxdepth = 30),
fast     = list(ntree = 50,  mtry = 2, minsplit = 20, minbucket = 10, maxdepth = 15)
)
p <- config[[variant]]
## ---------- Data ---------------------------------------------------
power_file <- "/Users/leonkiafaro/Documents/multivariate-density-estimation/data/direct/power/data.npy"
x <- npyLoad(power_file)
set.seed(42);  x <- x[sample(nrow(x)), ]
train <- x[1:n_train, , drop = FALSE]
test  <- x[(n_train + 1):(n_train + n_test), , drop = FALSE]
mu <- colMeans(train);  sd <- apply(train, 2, sd)
train <- scale(train, center = mu, scale = sd)
test  <- scale(test,  center = mu, scale = sd)
## ---------- Legacy‑Funktionen  -------------------------------------
mytrtf <- function(data,
ntree = 50,
mtry = floor(sqrt(ncol(data) - 1)),
minsplit = 25,
minbucket = 20,
maxdepth = 4,
seed = 42,
cores_inner = NC,
trace = TRUE) {
library(trtf)
df <- as.data.frame(data)
set.seed(seed)
ymod <- lapply(colnames(df), function(y) BoxCox(as.formula(paste(y, "~ 1")), data = df))
fm   <- lapply(2:ncol(df), function(j) as.formula(paste(colnames(df)[j], "~",
paste(colnames(df)[1:(j - 1)], collapse = "+"))))
forests <- with_progress({
pg <- progressor(along = seq_along(fm))
lapply(seq_along(fm), function(j) {
pg(sprintf("%d/%d", j, length(fm)))
traforest(ymod[[j + 1L]], formula = fm[[j]], data = df,
ntree = ntree, mtry = mtry,
minsplit = minsplit, minbucket = minbucket, maxdepth = maxdepth,
trace = FALSE, cores = cores_inner)
})
})
structure(list(ymod = ymod, forests = forests), class = "mytrtf")
}
predict.mytrtf <- function(object, newdata, type = "logdensity") {
df_new <- as.data.frame(newdata)
ld1 <- predict(object$ymod[[1]], newdata = df_new, type = type)
ld  <- with_progress({
pg <- progressor(along = object$forests)
lapply(object$forests, function(frst) {
pg()
q <- df_new[, variable.names(frst$model)[1]]
diag(do.call(cbind, predict(frst, newdata = df_new, type = type, q = q)))
})
})
Reduce("+", ld) + ld1
}
## ---------- Fit & Test‑Evaluation ----------------------------------
t0 <- Sys.time()
final_model <- mytrtf(train,
ntree      = p$ntree,
mtry       = p$mtry,
minsplit   = p$minsplit,
minbucket  = p$minbucket,
maxdepth   = p$maxdepth,
seed       = seed_fit,
cores_inner = NC)
neg_avg_ll <- -mean(predict.mytrtf(final_model, test, type = "logdensity"))
elapsed <- as.numeric(difftime(Sys.time(), t0, units = "secs"))
cat(sprintf(
"\nPOWER – n_train=%d  n_test=%d  variant=%s  exec=%s\n   -avgLL=%.6f  runtime=%.1f s\n",
n_train, n_test, variant, exec_mode, neg_avg_ll, elapsed
))
