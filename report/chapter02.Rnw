% LaTeX file for Chapter 02
<<'preamble02',include=FALSE>>=
library(knitr)
opts_chunk$set(
    fig.path = 'figure/ch02_fig',
    self.contained = FALSE,
    cache = TRUE
)
@

\chapter{Methodological Background}\label{ch:background}

\section{Transport Frame and Notation}\label{sec:transport-frame}

This section fixes the standardized coordinate system, notation, and algebraic identities used throughout the thesis. The motivation and schematic in Figure~\ref{fig:transport-schematic} housed in Appendix~\ref{ch:appendix} remain valid; here we strip the exposition down to the formulas needed in later chapters. We summarize the standardized pullback likelihood, state the triangularity assumption, and record the Jacobian factorization that drives evaluation and inversion.

We work with observations on the original scale $x \in \mathbb{R}^K$. Training-split statistics define a fixed standardization map
\begin{equation}
  u \;=\; T_{\mathrm{std}}(x) \;=\; (x-\mu)\oslash\sigma,\qquad \sigma_k>0,\label{eq:transport-standardise}
\end{equation}
where $\mu$ and $\sigma$ denote the empirical mean and standard deviation estimated on the training split and $\oslash$ denotes elementwise division. In words, we shift and rescale features once, using training data only, and keep all derivatives and Jacobians in $u$-space to avoid leakage and to ensure comparability across estimators.

The standardized density $\pi_U$ is coupled to a simple reference through a monotone triangular map $S:u\mapsto z$. Throughout the thesis the reference is the $K$-variate standard normal density $\eta(z)$. The pullback identity then reads
\begin{equation}
  \pi_U(u) \;=\; \eta\!\left(S(u)\right)\,\left|\det\nabla_u S(u)\right|,\label{eq:transport-pullback}
\end{equation}
which evaluates the reference at $S(u)$ and applies the exact volume correction given by the Jacobian determinant. Reporting log densities on the original scale requires only the diagonal affine correction implied by standardization,
\begin{equation}
  \log \pi_X(x) \;=\; \log \pi_U\!\left(T_{\mathrm{std}}(x)\right) - \sum_{k=1}^{K}\log\sigma_k.\label{eq:transport-affine}
\end{equation}
We therefore differentiate with respect to $u$, and we convert to $x$-scale only at reporting time.

The transport is assumed to be lower triangular and componentwise monotone,
\begin{equation}
  S(u) \;=\; \big(S_1(u_1), S_2(u_{1:2}), \ldots, S_K(u_{1:K})\big), \qquad \partial_{u_k}S_k(u_{1:k})>0,\label{eq:transport-triangular}
\end{equation}
so the Jacobian $\nabla_u S(u)$ is lower triangular. Its determinant factorizes into a sum of one-dimensional log derivatives,
\begin{equation}
  \log \big|\det \nabla_u S(u)\big| \;=\; \sum_{k=1}^{K}\log \partial_{u_k}S_k(u_{1:k}).\label{eq:transport-det}
\end{equation}
The factorization yields $\mathcal{O}(K)$ evaluation cost per-sample, improves numerical stability, and guarantees global invertibility: strictly monotone diagonal derivatives let us recover $x$ by solving $K$ one-dimensional monotone equations in sequence, mirroring the Rosenblatt and Knothe rearrangements \citep{rosenblatt1952remarks,knothe1957contributions}.

Table~\ref{tab:transport-notation} consolidates the notation used in this transport frame. All derivatives and Jacobians act on $u$; the affine correction \eqref{eq:transport-affine} converts log densities back to $x$ for reporting. The remainder of this chapter adopts this frame. Section~\ref{sec:transport-separable} details the separable triangular parameterization used for direct transports. Section~\ref{sec:transport-trtf} shows how Transformation Random Forests induce the same triangular likelihood via the probability integral transform under the conditions stated there (strictly increasing conditional CDFs after monotone smoothing and an additive predictor). Section~\ref{sec:transport-copula} places copulas in the same reporting convention.

\begin{table}[t]
  \centering
  \caption{Notation for the transport frame used in Chapters~\ref{ch:background} and~\ref{ch:dataanalysis}. All derivatives and Jacobians are taken with respect to $u$; log densities on $x$-space apply the affine correction in Equation~\eqref{eq:transport-affine}.}
  \label{tab:transport-notation}
  \begin{tabular}{ll}
    \hline
    Symbol & Meaning \\ 
    \hline
    $x \in \mathbb{R}^K$ & Original features on the data scale \\ 
    $T_{\mathrm{std}}$ & Standardization map using training $(\mu,\sigma)$ \\ 
    $u = T_{\mathrm{std}}(x)$ & Standardized evaluation coordinates \\ 
    $z \in \mathbb{R}^K$ & Reference coordinates after transport \\ 
    $S:u\mapsto z$ & Monotone lower-triangular transport map \\ 
    $\nabla_u S(u)$ & Jacobian of $S$ with respect to $u$ \\ 
    $\eta(z)$ & $K$-variate standard normal density \\ 
    $\varphi(t)$, $\Phi(t)$ & Univariate standard normal density and CDF \\ 
    $\pi_U$, $\pi_X$ & Densities on $u$- and $x$-space, respectively \\ 
    $\mu$, $\sigma$ & Training mean vector and positive scales \\ 
    $K$ & Dimension of the feature vector \\ 
    \hline
  \end{tabular}
\end{table}

\section{Separable Triangular Maps and Transformation Random Forests as Transport}\label{sec:transport-separable}

% Checklist: enforce US spelling, ensure dynamic cross-references, keep equation labels aligned.
This section unifies separable triangular maps and Transformation Random Forests (TRTF) within the transport frame fixed in Section~\ref{sec:transport-frame}. Both estimators realize a monotone lower-triangular map $S:u\mapsto z$ that couples the standardized target to the Gaussian reference $\eta$. The use of triangular transports builds on modern measure-transport literature; see, for instance, triangular transformations and their properties in \citet{bogachev2005triangular}. Figure~\ref{fig:transport-schematic} in Appendix~\ref{ch:appendix} illustrates the shared backbone and locates \textsc{TTM-Sep} and \textsc{TRTF} on the transport branch introduced in Chapter~\ref{ch:intro}. We focus on shared likelihood identities, modeling assumptions, and limits of separability, and defer implementation details to Chapter~\ref{ch:dataanalysis} and Appendix~\ref{ch:appendix}.

The goal is to state a single likelihood for both constructions, clarify what separability permits, and identify failure modes that motivate richer parameterizations. We do not pursue non-additive TRTF predictors, cross-term triangular maps, or ordering heuristics in this section; Chapter~\ref{ch:dataanalysis} evaluates those choices empirically and Appendix~\ref{ch:appendix} documents routines and defaults.

We adopt the notation introduced in Section~\ref{sec:transport-frame}. Coordinates satisfy $u=T_{\mathrm{std}}(x)$, the reference density is $\eta(z)$, and the pullback identity \eqref{eq:transport-pullback} gives $\pi_U(u)=\eta(S(u))\,|\det\nabla_u S(u)|$. The map is lower-triangular with strictly positive diagonal partial derivatives, which yields the sum decomposition in Equation~\eqref{eq:transport-det}. These conventions keep derivatives in $u$-space and apply the affine correction \eqref{eq:transport-affine} only when reporting $\log \pi_X(x)$.

We restrict attention to separable triangular maps. Component $k$ decomposes into a context shift and a univariate monotone shape,
\begin{equation}
  S_k(u_{1:k}) \;=\; g_k(u_{1:k-1}) + h_k(u_k),\qquad \log \partial_{u_k}S_k(u_{1:k}) \;=\; \log h_k'(u_k),\label{eq:transport-separable}
\end{equation}
which fixes context effects in $g_k$ and reserves $h_k$ for the one-dimensional marginal shape. Intuitively, earlier coordinates translate the location, while the conditional shape along $u_k$ remains fixed across contexts. The Jacobian contribution depends only on $u_k$, which reduces per-sample evaluation cost and simplifies inversion.

\begin{shaded}
\textbf{Assumptions.} Unless stated otherwise, we assume:
\begin{itemize}
  \item \emph{Lower-triangularity:} $S$ has the structure in Eq.~\eqref{eq:transport-triangular}.
  \item \emph{Strict monotone coordinates:} $\partial_{u_k} S_k(u_{1:k}) > 0$ for all $k$ and all arguments.
  \item \emph{Separable component:} Eq.~\eqref{eq:transport-separable} holds, so conditional shape along $u_k$ is fixed across contexts.
\end{itemize}
\end{shaded}

Substituting the standard normal reference into \eqref{eq:transport-pullback} produces a separable objective,
\begin{equation}
  \log \pi_U(u) \;=\; \sum_{k=1}^{K}\Big[\log \varphi\!\big(S_k(u_{1:k})\big) + \log h_k'(u_k)\Big],\label{eq:transport-likelihood}
\end{equation}
where $\varphi$ denotes the univariate standard normal density. Equation~\eqref{eq:transport-likelihood} splits the log density into a reference fit and an exact volume correction. In plain language, the model evaluates how Gaussian each transformed coordinate appears, then corrects for the local stretch induced by $h_k$. The same decomposition produces linear per-sample time in $K$ and stable accumulation of log derivatives.

The negative log-likelihood per-sample takes the quadratic-plus-barrier form
\begin{equation}
  \mathcal{L}(u) \;=\; \sum_{k=1}^{K}\Big[\tfrac{1}{2}\,S_k(u_{1:k})^2 - \log h_k'(u_k)\Big],\label{eq:transport-loss}
\end{equation}
which follows because $\log \varphi(t) = -\tfrac{1}{2}t^2 - \tfrac{1}{2}\log(2\pi)$ and constants independent of the parameters drop out. Equation~\eqref{eq:transport-loss} pulls each component toward the reference while preventing degenerate derivatives through the log barrier. In practice we enforce $h_k'(u_k)>0$ by construction and control tails with mild regularization; implementation choices appear in Chapter~\ref{ch:dataanalysis} and Appendix~\ref{ch:appendix}.

Separable structure encodes clear modeling assumptions. Conditional variance, skewness, and modality do not change with the preceding coordinates once $g_k$ shifts location. Consequently, separable maps can underfit heteroskedastic or multimodal conditionals, which manifests as U-shaped or inverted-U probability integral transform (PIT) diagnostics. Variable ordering also matters for finite bases because triangular transports are anisotropic, even though a Knothe--Rosenblatt rearrangement exists for any ordering \citep{rosenblatt1952remarks,knothe1957contributions}. These caveats guide the robustness checks in Chapter~\ref{ch:dataanalysis}.

\subsection{Transformation Random Forests within the Transport Frame}\label{sec:transport-trtf}

Transformation Random Forests \citep{hothorn2017transformation,hothorn2018conditional,hothorn2021transformation} fit into the same transport frame through the probability integral transform. Let $\widehat F_k(\cdot \mid u_{1:k-1})$ denote the strictly increasing conditional CDF returned by a TRTF for coordinate $k$. (In practice, forest CDFs can be stepwise; we assume a measurable, strictly increasing version after standard monotone smoothing so that inversion and derivatives are well-defined.) The induced triangular component is
\begin{equation}
  S_k(u_{1:k}) \;=\; \Phi^{-1}\!\Big(\widehat F_k(u_k \mid u_{1:k-1})\Big),\label{eq:transport-trtf-map}
\end{equation}
which maps conditionals to standard normal margins. In plain language, TRTF predicts a conditional CDF, then the probit transform places the result on the Gaussian reference scale. Differentiating $\Phi\!\big(S_k(u_{1:k})\big)=\widehat F_k(u_k \mid u_{1:k-1})$ with respect to $u_k$ yields
\begin{equation}
  \widehat \pi_k(u_k \mid u_{1:k-1}) \;=\; \varphi\!\big(S_k(u_{1:k})\big)\,\partial_{u_k}S_k(u_{1:k}),\label{eq:transport-trtf-likelihood}
\end{equation}
which is exactly the pullback factor in Equation~\eqref{eq:transport-likelihood}. Summing over $k$ recovers Equation~\eqref{eq:transport-likelihood} in standardized coordinates.

The additive-predictor TRTF used in this thesis yields a separable transport. Under the model
\begin{equation}
  \widehat F_k(u_k \mid u_{1:k-1}) \;=\; \Phi\!\big(h_k(u_k) + g_k(u_{1:k-1})\big),\label{eq:transport-trtf-additive}
\end{equation}
we obtain
\begin{equation}
  S_k(u_{1:k}) \;=\; h_k(u_k) + g_k(u_{1:k-1}),\qquad \partial_{u_k}S_k(u_{1:k}) \;=\; h_k'(u_k),\label{eq:transport-trtf-separable}
\end{equation}
so TRTF implements the same separable triangular likelihood as the direct parameterization in Equation~\eqref{eq:transport-separable}. The map is monotone in $u_k$ by construction, the Jacobian depends only on $u_k$, and inversion proceeds by back-substitution identical to the separable map. This equivalence underpins the empirical comparisons in Chapter~\ref{ch:dataanalysis}.

The equivalence also clarifies limits. Additive TRTF predictors shift location but cannot alter conditional shape with context, which mirrors the separable constraint. Axis-aligned partitions stabilize estimation, yet they do not remove residual multimodality when the conditional shape varies with $u_{1:k-1}$. These limits are visible in PIT diagnostics and conditional negative log-likelihood decompositions on synthetic studies.

We emphasize operational scope and supporting references. All derivatives and Jacobians are computed in standardized coordinates, evaluation uses the triangular pullback, and reported log densities on the original scale include the affine correction \eqref{eq:transport-affine}. Implementation details on basis choices for $h_k$, feature construction for $g_k$, regularization, derivative clipping, timing, and memory footprints appear in Chapter~\ref{ch:dataanalysis} and Appendix~\ref{ch:appendix}, which also provides pseudo-code for both estimators. Figure~\ref{fig:transport-schematic} in Appendix~\ref{ch:appendix} visualizes how the \textsc{TTM-Sep} and \textsc{TRTF} branches share the same computational path from standardized data to reported likelihoods.

In summary, separable triangular maps and additive-predictor TRTF realize the same lower-triangular likelihood once the data are standardized and the conditional CDFs are strictly increasing after monotone smoothing. The shared structure yields exact likelihoods, exact inversion, transparent conditionals, and linear per-sample complexity, but it restricts context-dependent shape. Section~\ref{sec:transport-copula} positions copulas within the same reporting convention to decouple marginals from dependence.

\section{Copula Baselines}\label{sec:transport-copula}

% Checklist: align references with transport frame, cite Sklar, enforce US spelling.
This section positions copulas within the unified transport frame and links their reported likelihoods to the evaluation conventions used for triangular maps and Transformation Random Forests. Copulas decouple marginal modeling from dependence modeling by pairing univariate marginals with a separate dependence density on the unit hypercube \citep{nelsen2006introduction,joe2014dependence}. Figure~\ref{fig:transport-schematic} in Appendix~\ref{ch:appendix} displays the copula branch beside the triangular branch and highlights how both yield comparable reported log densities under the shared evaluation pipeline.

We begin with pseudo-observations built from training-split marginals. Let $\widehat F_k$ denote the strictly increasing empirical or smoothed CDF of $X_k$ estimated on the training split. Define the pseudo-observations and their probit transform as
\begin{equation}
  v_k \;=\; \widehat F_k(x_k),\qquad z_k \;=\; \Phi^{-1}(v_k),\label{eq:copula-probit}
\end{equation}
which map each coordinate to $(0,1)$ and then to $\mathbb{R}$ through the probit function. In plain language, the marginals become uniform scores, and $z$ records those scores on a Gaussian scale. Mid-ranks and clamping near $(0,1)$ stabilize the transformation in finite samples.

The copula representation combines marginal densities with a dependence factor. The joint log density on the original scale satisfies
\begin{equation}
  \log \widehat \pi_X(x) \;=\; \sum_{k=1}^{K} \log \widehat f_k(x_k) + \log c\!\left(v_1,\ldots,v_K\right),\label{eq:copula-logdensity}
\end{equation}
where $c$ denotes the copula density on $(0,1)^K$. Equation~\eqref{eq:copula-logdensity} separates the task into two parts: fit interpretable marginals and correct for dependence through $\log c$. The reported quantity already lives on the original scale, so the affine correction in Equation~\eqref{eq:transport-affine} is unnecessary. Figure~\ref{fig:transport-schematic} in Appendix~\ref{ch:appendix} uses the equivalent shorthand $\log c(z)$ because dependence is evaluated through $z=\Phi^{-1}(v)$.

The independence baseline fixes a lower bound for dependence modeling. Setting $c \equiv 1$ yields
\begin{equation}
  \log \widehat \pi_X^{\mathrm{ind}}(x) \;=\; \sum_{k=1}^{K} \log \widehat f_k(x_k),\label{eq:copula-independence}
\end{equation}
which treats coordinates as independent after marginal fitting. Chapter~\ref{ch:dataanalysis} uses this baseline as a reference point in evaluation tables and figures.

The Gaussian copula specifies elliptical dependence through a correlation matrix $\Sigma$. With $z=\Phi^{-1}(v)$, the copula density admits the closed form
\begin{equation}
  c_{\Sigma}(v) \;=\; |\Sigma|^{-1/2}\,\exp\!\Big(-\tfrac{1}{2}\,z^{\top}(\Sigma^{-1} - I)z\Big),\label{eq:copula-gaussian}
\end{equation}
which reduces dependence estimation to fitting $\Sigma$ on the transformed scores. In plain language, the Gaussian copula bends the joint shape away from independence according to $\Sigma$ while preserving the learned marginals.

A low-dimensional nonparametric variant avoids elliptical assumptions at small $K$. We fit a kernel density $\widehat f_Z$ on $z=\Phi^{-1}(v)$ and recover the copula density by
\begin{equation}
  c(v) \;=\; \frac{\widehat f_Z\!\big(\Phi^{-1}(v)\big)}{\prod_{k=1}^{K} \varphi\!\big(\Phi^{-1}(v_k)\big)},\label{eq:copula-kde}
\end{equation}
which applies the change of variables from $z$ back to $v$ and yields a proper copula density. In words, the kernel density models the joint shape of the probit scores, and division by the product of standard normal densities restores the unit-cube scale. This approach is viable only for small $K$, where kernel density estimation remains accurate and stable. We implement this baseline via the \texttt{kdecopula} package \citep{nagler2017kdecopula}. Chapter~\ref{ch:dataanalysis} employs it strictly as a diagnostic baseline.

The transport frame keeps reporting interoperable across modeling branches despite distinct parameterizations. Triangular maps and TRTF evaluate the pullback likelihood in standardized coordinates and apply the fixed affine correction \eqref{eq:transport-affine} when mapping back to $x$. Copulas operate on $x$ directly through Equation~\eqref{eq:copula-logdensity}, yet Figure~\ref{fig:transport-schematic} in Appendix~\ref{ch:appendix} shows how the probit scores $z$ maintain comparability with the Gaussian reference used above. This alignment keeps objectives and diagnostics consistent across Chapters~\ref{ch:background} and~\ref{ch:dataanalysis}.

Modeling choices and limits follow from the chosen copula. The Gaussian copula imposes elliptical dependence and may misrepresent tail behavior or localized asymmetry. The nonparametric variant mitigates these issues only at small dimension and sufficient sample size. The independence baseline provides a transparent reference when dependence is weak or data are scarce. These caveats motivate treating copulas as interpretable baselines rather than definitive high-dimensional models in the empirical study of Chapter~\ref{ch:dataanalysis}. Sklarâ€™s theorem underlies all constructions above and formalizes the decoupling of marginals from dependence \citep{sklar1959fonctions}.
