% LaTeX file for Chapter 03
<<'preamble03',include=FALSE>>=
library(knitr)
opts_chunk$set(
    fig.path = 'figure/ch03_fig',
    self.contained = FALSE,
    cache = TRUE
)
@

\chapter{Data Analysis and Validation}\label{ch:dataanalysis}

% Checklist: align terminology, update abbreviations, confirm notation references.
\begin{quote}
\textbf{Motivation.} We factor the joint density into simple conditional pieces using a lower-triangular parameterization. This yields exact likelihoods, transparent conditionals we can inspect, and $\mathcal{O}(K)$ per-sample cost. The shared factorization lets us run ordering experiments without changing the model class.
\end{quote}

\textbf{Model abbreviations.} We use the short labels TTM-Sep (separable triangular transport map), TTM-X (separable map with low-rank cross-terms), TRTF (Transformation Random Forests; spelled out on first mention), RealNVP, MAF, NSF, True-Marg/True-Joint, and Copula consistently across tables and figures.

\textbf{Units and signage.} Unless stated otherwise, all log-likelihood (LL) and negative log-likelihood (NLL) values are reported in nats. Plots and tables mark $\text{LL}~(\uparrow~\text{better})$ and $\text{NLL}~(\downarrow~\text{better})$ explicitly.

\textbf{Notation recap.}
\begin{itemize}
  \item Elementwise standardization with train-split statistics:
  \[ 
    u_k = \frac{x_k - \mu_k}{\sigma_k},\quad k = 1,\ldots,K
    \qquad\text{equivalently } u = \operatorname{diag}(\sigma)^{-1}(x - \mu).
  \]
  We compute derivatives and Jacobians in $u$-coordinates and transform back to $x$ only when reporting densities on the original scale via Equation~\eqref{eq:transport-affine}.
  \item Prefix subvector shorthand: $u_{1:k} := (u_1,\ldots,u_k)$.
  \item Derivatives use $h'_k(\cdot)$ for univariate derivatives; mixed partials follow the convention from Chapter~\ref{ch:background}.
\end{itemize}

\textbf{Copula conventions.}
\begin{itemize}
  \item All copula fits estimate marginals; reported values are joint densities on the original $x$-scale.
  \item Half-Moon ($K=2$) uses class-conditional copulas for blue/red labels mixed by empirical class priors when we report the unlabeled density. No other model uses labels in this chapter; detailed results appear in Section~\ref{sec:synthetic-results}.
\end{itemize}

\section{Datasets and Preprocessing}\label{sec:datasets-preprocessing}

This section fixes data sources, synthetic generators, and preprocessing so that objectives, diagnostics, and reported log-densities are comparable across models. All estimators operate in standardized coordinates, evaluate Jacobians in that space, and report log densities on the original scale using the affine correction from Equation~\eqref{eq:transport-affine}. Throughout, logistic gates are written $\operatorname{logistic}(\cdot)$.

\subsection{Standardization and Splits}
Features are standardized with training-split statistics only $(\mu, \sigma \in \mathbb{R}^K, \sigma_k > 0)$ as in Equation~\eqref{eq:transport-standardise}. The triangular pullback, determinant factorization, and affine correction from Equations~\eqref{eq:transport-pullback}--\eqref{eq:transport-affine} stay in $u$-coordinates; we transform back to $x$ once per evaluation when reporting densities. We keep fixed train/test splits. Synthetic calibration uses an $80/20$ train/test partition. Real-data splits follow the published convention for each benchmark, and compute profiles are summarized in Appendix~\ref{app:evaluation}.

For synthetic runs we hold seeds $\{11, 13, 17, 19, 23\}$ fixed across models and report means with $\pm 2$ standard errors when averaging replicates. Ordering experiments reuse the lower-triangular factorization and vary only the coordinate order; the permutation sweeps in the four-dimensional study currently pin $\texttt{SEED}=42$ unless overridden so that every ordering shares the same draws. Unless noted otherwise, our canonical ordering remains $(1,2,3,4)$ for the four-dimensional generator; Section~\ref{sec:synthetic-results} reports the permutation studies.

\subsection{Half-Moon ($K=2$)}
Half-Moon is a curved, bimodal joint designed to surface dependence beyond linear correlation. We evaluate joint log-density contours per model and compare results to the true joint. Figure~\ref{fig:halfmoon-panels} and Table~\ref{tab:halfmoon-nll} later in this chapter instantiate the diagnostics. For the copula baseline we fit blue/red class-conditional copulas and mix them by empirical class priors when reporting the unlabeled density. No other estimator uses labels.

\subsection{Four-dimensional Autoregressive Generator ($K=4$)}
The synthetic autoregressive generator matches the lower-triangular factorization while stressing skewness, heavy tails, and context-dependent shape:
\begin{itemize}
  \item $X_1 \sim \mathcal{N}(0,1)$.
  \item $X_2 \sim \mathrm{Exponential}(\lambda_0)$ with $\lambda_0 = 1$.
  \item $X_3 \mid X_{1:2}$ is a mixture of two beta laws on $(0,1)$, e.g. $\mathrm{Beta}(2.5, 5.0)$ versus $\mathrm{Beta}(5.0, 2.5)$, with gate
  \[ 
    w_3(X_{1:2}) = \operatorname{logistic}\big(\gamma_0 + \gamma_1 X_1 + \gamma_2 (X_2 - 1)\big), \qquad \gamma = (\gamma_0, \gamma_1, \gamma_2).
  \]
  \item $X_4 \mid X_{1:3}$ is a mixture of two gamma laws on $(0, \infty)$ with distinct shape/scale pairs, gated by
  \[ 
    w_4(X_{1:3}) = \operatorname{logistic}\big(\delta_0 + \delta_1 X_1 + \delta_3 (X_3 - 0.5)\big), \qquad \delta = (\delta_0, \delta_1, \delta_3).
  \]
\end{itemize}
Mixture weights are normalized through the usual softmax over component logits so that Jacobian terms stay well behaved under shared standardization. This design keeps $X_4$ conditionally heteroskedastic with positive support and aligns with the triangular evaluation cost $\mathcal{O}(K)$.

\paragraph{Why these generators?}
They match the triangular modeling assumptions yet stress estimators with skewness, heavy tails, and context-dependent variation. The true joint density and conditionals are known, which enables direct comparisons without confounding from Monte Carlo error.

\paragraph{Reproducibility note.}
All random seeds, splits, and generator parameters are fixed in the code release. Negative NLL values appear for bounded or highly concentrated marginals (e.g., beta or gamma mass near zero); this behavior is expected and does not signal an error.

\bigskip
\noindent\emph{Next: Section~\ref{sec:models-implementation} details the estimators and training settings that make these likelihoods and diagnostics comparable across methods.}


\section{Models and Implementation}\label{sec:models-implementation}

% Checklist: align references, enforce US spelling, ensure active voice.
\begin{quote}
\textbf{Scope.} This section specifies the estimators and the implementation details that keep our likelihoods, diagnostics, and plots comparable. We reuse the preprocessing and transport notation in Table~\ref{tab:transport-notation}, draw background from Chapter~\ref{ch:background}, follow the data handling in Section~\ref{sec:datasets-preprocessing}, and lean on the auxiliary pseudo-code in Appendix~\ref{ch:appendix}.
\end{quote}

\subsection{Separable Triangular Transport Maps (TTM-Sep)}

We use lower-triangular, separable transport maps
\begin{equation}
  S_k(u_{1:k}) = g_k(u_{1:k-1}) + h_k(u_k), \qquad \partial_{u_k} S_k(u_{1:k}) = h'_k(u_k) > 0,
  \label{eq:ttm-separable-def}
\end{equation}
so the Jacobian contribution at stage $k$ depends only on $u_k$. This structure yields $\mathcal{O}(K)$ per-sample cost and exact inversion by back-substitution.

\textbf{Objective.} We minimize the Gaussian pullback induced by the shared reference (Equations~\eqref{eq:transport-pullback}--\eqref{eq:transport-det}):
\begin{equation}
  \mathcal{L}(u) = \sum_{k=1}^K \Big[ \tfrac{1}{2} S_k(u_{1:k})^2 - \log h'_k(u_k) \Big].
  \label{eq:ttm-separable-loss}
\end{equation}
We solve this objective with constrained optimization and enforce monotonicity by construction.

\textbf{Parameterization.}
\begin{itemize}
  \item $h_k$: one-dimensional monotone bases (integrated radial basis functions, splines, and linear tails) with derivative nonnegativity so that $h'_k > 0$; all coefficients are learned jointly under the positivity constraint enforced by the optimizer.
  \item $g_k$: low-degree polynomial features of $u_{1:k-1}$ with light ridge regularization to keep $\nabla_u S(u)$ stable.
\end{itemize}

\paragraph{Ordering.} Feature ordering matters for triangular models. We store the learned order and reuse it at prediction time. For permutation studies (Section~\ref{sec:synthetic-results}) we apply the same bookkeeping so that permutations are reproducible.

\subsection{Cross-term Variant (TTM-X)}

We reference a low-rank interaction variant only to delimit the class used in the synthetic analyses:
\begin{equation}
  S_k(u_{1:k}) = g_k(u_{1:k-1}) + h_k(u_k) + \sum_{j<k} \alpha_{kj} \, q_j(u_j) \, r_k(u_k),
  \label{eq:ttm-cross}
\end{equation}
where $q_j$ and $r_k$ are monotone features. Constraints ensure $\partial_{u_k} S_k > 0$ despite the cross-term. We do not promote TTM-X as a baseline; the definition clarifies the naming and scope used in the synthetic results.

\subsection{Transformation Random Forests (TRTF)}

We use Transformation Random Forests (TRTF) as an alternative route to a triangular component from conditional CDFs \citep{hothorn2017transformation,hothorn2018conditional}. Let $\widehat{F}_k(\cdot \mid u_{1:k-1})$ denote the forest CDF. We define
\begin{equation}
  S_k(u_{1:k}) = \Phi^{-1}\!\big(\widehat{F}_k(u_k \mid u_{1:k-1})\big),
  \label{eq:trtf-transport}
\end{equation}
which maps $u_k$ into the standard normal reference conditional on $u_{1:k-1}$. By the chain rule,
\[
  \varphi\big(S_k(u_{1:k})\big)\, \partial_{u_k} S_k(u_{1:k}) = \widehat{f}_k(u_k \mid u_{1:k-1}),
\]
so the TRTF-induced Jacobian matches the forestâ€™s conditional density. The triangular structure mirrors TTM-Sep; the difference is operational (forest training and aggregation) rather than conceptual.

\subsection{Copula Baseline with Estimated Marginals}

We keep copulas as dependence baselines with explicit scope. Marginals are estimated on the training split, and we report the joint density on the original $x$-scale. Concretely, we fit $\widehat{F}_k$ and $\widehat{f}_k$ for each coordinate, transform to pseudo-observations $U_k = \widehat{F}_k(X_k)$, and, for Gaussian copulas, set $Z_k = \Phi^{-1}(U_k)$ to model dependence in a latent normal space. We evaluate the copula density $c(U)$ and multiply by $\prod_{k=1}^K \widehat{f}_k(x_k)$ to obtain the reported joint density.

\paragraph{Label use (Half-Moon only).} For $K=2$ in the Half-Moon study we fit class-conditional copulas for the blue/red classes and mix them by empirical class priors when reporting the unlabeled joint. No other model uses labels. Details and diagnostics appear in Section~\ref{sec:synthetic-results}.

\subsection{Shared Inversion and Evaluation}

We adopt a single inversion and evaluation convention across estimators using Equations~\eqref{eq:transport-pullback}--\eqref{eq:transport-det}. The alignment is necessary for conditional decomposition checks in Section~\ref{sec:synthetic-results} and for the compute summaries in Section~\ref{sec:realdata}.

\paragraph{Reproducibility.} We fix random seeds, cache splits, and expose the same object layouts for transport maps, TRTF, and copulas. Appendix~\ref{ch:appendix} provides pseudo-code for TRTF fitting and prediction; we reuse the same logging, timing hooks, and file formats across models.
\section{Evaluation Metrics and Protocol}\label{sec:evaluation-protocol}

% Checklist: align references, keep active voice, reuse existing notation.
\begin{quote}
\textbf{Goal.} Define the metrics and the evaluation routine applied across all estimators. We reuse the notation and preprocessing conventions from Table~\ref{tab:transport-notation}, with background in Chapter~\ref{ch:background} and dataset preparation in Section~\ref{sec:datasets-preprocessing}. All log-likelihood (LL) and negative log-likelihood (NLL) values are reported in nats; figures and tables state $\text{LL}~(\uparrow~\text{better})$ and $\text{NLL}~(\downarrow~\text{better})$ explicitly.
\end{quote}

\subsection{Joint and Conditional Decomposition}

Triangular models evaluate densities in standardized coordinates and then report on the original scale. With $u = T_{\mathrm{std}}(x)$ determined by the training-split $(\mu, \sigma)$, any estimator with lower-triangular $S$ satisfies
\begin{equation}
  \log \hat{\pi}_U(u) = \sum_{k=1}^{K} \Big[ \log \varphi\big(S_k(u_{1:k})\big) + \log \partial_{u_k} S_k(u_{1:k}) \Big],
  \label{eq:evaluation-triangular}
\end{equation}
so the determinant factorization from Equations~\eqref{eq:transport-pullback}--\eqref{eq:transport-det} applies componentwise. We transform back to $x$ once per evaluation via the affine correction in Equation~\eqref{eq:transport-affine}.

We localize error with per-dimension conditional NLLs. For coordinate $k$,
\begin{equation}
  \mathrm{NLL}_k = -\frac{1}{N_{\mathrm{test}}} \sum_{i=1}^{N_{\mathrm{test}}} \log \hat{\pi}\big(x_{ik} \mid x_{i,1:k-1}\big),
  \label{eq:evaluation-conditional-nll}
\end{equation}
and the joint NLL satisfies $\mathrm{NLL}_{\mathrm{joint}} = \sum_{k=1}^{K} \mathrm{NLL}_k$ by the triangular factorization. Negative per-dimension NLLs can occur on bounded or highly concentrated supports (e.g., beta or gamma margins); we revisit this behaviour in Section~\ref{sec:synthetic-results}.

\subsection{Compute Metrics}

We report practical costs alongside fit:
\begin{itemize}
  \item \textbf{Train time per epoch} and total wall-clock to the chosen early-stopping criterion when applicable.
  \item \textbf{Evaluation throughput} (test points per second) together with per-sample latency.
  \item \textbf{Model size,} recorded as effective parameter counts when the backend exposes them.
\end{itemize}
Compute summaries accompany the real-data tables in Section~\ref{sec:realdata}; extended profiles appear in Appendix~\ref{ch:appendix} when needed.

\subsection{Protocol (Fixed Across Methods)}

\begin{enumerate}
  \item \textbf{Preprocessing.} Standardize features with training-split $(\mu, \sigma)$, evaluate derivatives and Jacobians in $u$, and convert to $x$ with Equation~\eqref{eq:transport-affine} once per evaluation.
  \item \textbf{Evaluation in standardized space.} Compute LL, NLL, and conditional decompositions with Equation~\eqref{eq:evaluation-triangular}; map results to the original scale for reporting.
  \item \textbf{Aggregation and uncertainty.} Average metrics across seeds and report $\pm$ two standard errors (SE $= s/\sqrt{m}$ over $m$ seeds).
  \item \textbf{Reproducibility hooks.} Cache splits and random seeds, and log objective values together with compute metrics using shared file schemas across estimators.
\end{enumerate}

These choices keep likelihood reporting in standardized coordinates, align diagnostics, and make compute measurements comparable. Appendix~\ref{ch:appendix} lists the supporting routine interfaces and object layouts used in the experiments.
\section{Synthetic Results and Diagnostics}\label{sec:synthetic-results}

% Checklist: cite dynamic refs, align units, maintain topic-bridge sentences.
This section reports synthetic results for the Half-Moon and four-dimensional generators under the protocol in Section~\ref{sec:evaluation-protocol}. We summarize mean test negative log likelihoods, per-dimension conditional NLLs, and ordering robustness, referencing the corresponding tables and figures.

The Half-Moon generator stresses conditional shape in two dimensions. Table~\ref{tab:halfmoon-nll} lists mean joint NLLs with $\pm$ two standard errors: TRTF achieved $1.71 \pm 0.09$ nats, TTM-Sep achieved $1.93 \pm 0.08$ nats, and TTM-Marg achieved $2.02 \pm 0.07$ nats. The copula baseline reached $1.54 \pm 0.09$ nats and bracketed the triangular transports. The oracle references set $0.78 \pm 0.10$ nats for the true marginal density and $0.70 \pm 0.12$ nats for the true joint. Per-dimension NLLs confirm that the first coordinate is harder: TRTF reported $(1.23, 0.47)$, while TTM-Sep reported $(1.28, 0.65)$. Figure~\ref{fig:halfmoon-panels} shows contours consistent with these rankings and with the standardized pipeline described earlier in Chapter~\ref{ch:background}.\;Clipping status: not triggered in these runs (no log-derivative terms reached the bound).

\begin{table}[htbp]
  \centering
  \textit{(mean NLL in nats).}
  \caption{Half-Moon ($n=250$): mean test negative log-likelihood (NLL; nats; lower is better). Values are means $\pm$ 2SE.}
  \label{tab:halfmoon-nll}
  \begin{tabular}{lccc}
    \hline
    Model & Mean joint NLL & Conditional NLL 1 & Conditional NLL 2 \\
    \hline
    True-Marg      & $0.78 \pm 0.10$ & $0.39$ & $0.39$ \\
    True-Joint     & $0.70 \pm 0.12$ & $0.35$ & $0.35$ \\
    TRTF             & $1.71 \pm 0.09$ & $1.23$ & $0.47$ \\
    TTM-Marg         & $2.02 \pm 0.07$ & $1.28$ & $0.74$ \\
    TTM-Sep          & $1.93 \pm 0.08$ & $1.28$ & $0.65$ \\
    Copula           & $1.54 \pm 0.09$ & $0.77$ & $0.77$ \\
    \hline
  \end{tabular}
\end{table}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{figure/halfmoon_panels_seed007_N250.png}
  \caption{Half-Moon ($n=250$) log-density contours for the true joint, TRTF, TTM variants, and the copula mixture. Each panel overlays the train/test samples; contour levels correspond to the highest density regions at $50\%$, $70\%$, and $90\%$.}
  \label{fig:halfmoon-panels}
\end{figure}

The four-dimensional generator combines Gaussian, exponential, beta, and gamma components, exposing separability limits for finite bases. Table~\ref{tab:autoregressive-nll} (p.~\pageref{tab:autoregressive-nll}) reports the canonical ordering $(1,2,3,4)$. TRTF aligned closely with the exponential coordinate, recording $1.51$ nats compared with $1.49$ for the true joint reference. TTM-Sep over-penalized that coordinate at $1.88$ nats, and TTM-Marg overfit at $2.57$ nats. The beta coordinate yielded negative NLLs for the oracles because valid densities can exceed one on $(0,1)$; values were $-0.79$ for the true joint and $-0.48$ for the true marginal. TRTF reached $-0.25$, while TTM-Sep and the copula baseline reported $0.07$ and $0.05$ nats, respectively. The gamma coordinate remained most challenging, with $1.99$ nats for TRTF and $2.41$ nats for TTM-Sep. Joint sums were $4.53$ nats for TRTF, $5.66$ nats for TTM-Sep, $6.83$ nats for TTM-Marg, and $5.45$ nats for the copula, compared with $3.80$ nats for the true joint oracle. Figure~\ref{fig:autoregressive-joint-calibration} (p.~\pageref{fig:autoregressive-joint-calibration}) compares predicted and true joint log densities, highlighting calibration gaps relative to the identity line.\;Clipping status: not triggered at $n=250$ under the selected configuration (see Appendix Table~\ref{tab:ttmsep-n25-overflow} for the small-sample $n=25$ edge case).

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{figure/logdensity_joint_N250.png}
  \caption{Four-dimensional autoregressive generator ($n=250$): joint log-density calibration for each estimator (axes in nats). Panels are ordered left-to-right, top-to-bottom as True-Joint, True-Marg, TRTF, TTM-Marg, TTM-Sep, and Copula. Gray dots mark the $20\%$ test split (50 samples). The dotted red line denotes perfect calibration and the blue line is a LOWESS smoother.}
  \label{fig:autoregressive-joint-calibration}
\end{figure}

\begin{table}[htbp]
  \centering
  \textit{(mean NLL in nats).}
  \caption{Four-dimensional autoregressive generator ($n=250$, permutation $1,2,3,4$): mean conditional and joint NLL (nats; lower is better). Values are means over test samples (no SE shown).}
  \label{tab:autoregressive-nll}
  \begin{tabular}{llrrrrrr}
    \hline
    Dim & Distribution & True-Marg & True-Joint & TRTF & TTM-Marg & TTM-Sep & Copula \\
    \hline
    1 & Normal      & $1.29$ & $1.28$ & $1.28$ & $1.29$ & $1.29$ & $1.30$ \\
    2 & Exponential & $1.75$ & $1.49$ & $1.51$ & $2.57$ & $1.88$ & $1.87$ \\
    3 & Beta        & $-0.48$ & $-0.79$ & $-0.25$ & $0.28$ & $0.07$ & $0.05$ \\
    4 & Gamma       & $2.05$ & $1.83$ & $1.99$ & $2.69$ & $2.41$ & $2.22$ \\
    $K$ & Sum (joint) & $4.61$ & $3.80$ & $4.53$ & $6.83$ & $5.66$ & $5.45$ \\
    \hline
  \end{tabular}
\end{table}

Ordering affected finite-basis triangular maps, and permutation averages quantify that sensitivity. Table~\ref{tab:autoregressive-perm} (p.~\pageref{tab:autoregressive-perm}) summarizes test NLLs over all $4! = 24$ permutations: TRTF averaged $4.65$ nats, TTM-Sep averaged $5.62$ nats, TTM-Marg averaged $6.83$ nats, and the copula baseline averaged $5.45$ nats. The joint and marginal oracles remained stable at $3.80$ and $4.61$ nats, respectively. These effects confirm anisotropy and motivate the ordering heuristics described in Section~\ref{sec:models-implementation} when bases are finite. As a simple mitigation, we consider two data-driven candidatesâ€”identity and Cholesky-pivoted with optional Gaussianizationâ€”and select the ordering with the better validation NLL. Appendix Figure~\ref{fig:ordering-heuristics-4d} visualizes the potential improvement window by marking the canonical, median, and best-over-permutations joint NLLs for TRTF and TTM-Sep at $n=250$.

\begin{table}[htbp]
  \centering
  \textit{(mean NLL in nats).}
  \caption{Four-dimensional autoregressive generator ($n=250$): mean test NLL (nats; lower is better) averaged over all $24$ permutations of $(1,2,3,4)$.}
  \label{tab:autoregressive-perm}
  \begin{tabular}{lrrrrr}
    \hline
    Model & Dim 1 & Dim 2 & Dim 3 & Dim 4 & Sum \\
    \hline
    True-Marg        & 1.22 & 1.13 & 1.15 & 1.11 & 4.61 \\
    True-Joint       & 1.03 & 0.93 & 0.94 & 0.91 & 3.80 \\
    TRTF               & 1.33 & 1.19 & 1.09 & 1.04 & 4.65 \\
    TTM-Marg           & 1.77 & 1.67 & 1.73 & 1.66 & 6.83 \\
    TTM-Sep            & 1.59 & 1.38 & 1.36 & 1.29 & 5.62 \\
    Copula             & 1.42 & 1.34 & 1.36 & 1.32 & 5.45 \\
    \hline
  \end{tabular}
\end{table}

% Permutation spread summary
\begin{table}[htbp]
  \centering
  \textit{(mean NLL in nats).}
  \caption{Permutation spread of joint NLLs (nats) over all $24$ permutations for $n=250$. Values report $\min/\mathrm{median}/\max$ across orderings (lower is better).}
  \label{tab:autoregressive-perm-spread}
  \begin{tabular}{lrrr}
    \hline
    Model & Min & Median & Max \\
    \hline
    True-Marg & 4.61 & 4.61 & 4.61 \\
    True-Joint & 3.80 & 3.80 & 3.80 \\
    TRTF & 4.46 & 4.59 & 5.23 \\
    TTM-Marg & 6.83 & 6.83 & 6.83 \\
    TTM-Sep & 5.48 & 5.60 & 5.78 \\
    Copula & 5.45 & 5.45 & 5.45 \\
    \hline
  \end{tabular}
\end{table}

Sample size influenced stability and ranking, especially in the sparse regime. Table~\ref{tab:autoregressive-perm-avg} (p.~\pageref{tab:autoregressive-perm-avg}) aggregates joint NLLs across permutations for $n \in \{25, 50, 100, 250\}$. TRTF decreased from $38.18$ to $4.64$ nats as $n$ increased, while TTM-Sep decreased from $6.35$ to $5.61$ nats across the stable regimes. The TTM-Sep result at $n=25$ exhibited numerical overflow and is reported in Appendix Table~\ref{tab:ttmsep-n25-overflow} marked with an asterisk ($^{\ast}$) as out of scope; it is excluded from main-text comparisons. The copula decreased from $9.02$ to $5.45$ nats and tracked TTM-Sep once $n \ge 100$.

\begin{table}[htbp]
  \centering
  \textit{(mean NLL in nats).}
  \caption{Four-dimensional synthetic generator: permutation-averaged mean joint test NLL (nats; lower is better) over all $24$ permutations of $(1,2,3,4)$. Columns list sample sizes $n$.}
  \label{tab:autoregressive-perm-avg}
  \begin{tabular}{lrrrr}
    \hline
    Model & $n=25$ & $n=50$ & $n=100$ & $n=250$ \\
    \hline
    True-Marg       & 10.50 & 4.75 & 4.91 & 4.61 \\
    True-Joint      & 4.35 & 4.23 & 3.55 & 3.80 \\
    TRTF              & 38.18 & 6.10 & 4.59 & 4.64 \\
    TTM-Marg          & 49.36 & 7.43 & 7.72 & 6.83 \\
    TTM-Sep           & -- & 6.35 & 6.08 & 5.61 \\
    Copula            & 9.02 & 6.66 & 6.02 & 5.45 \\
    \hline
  \end{tabular}
  \caption*{Note: The TTM-Sep entry at $n=25$ is omitted from the main table due to numerical overflow; see Appendix Table~\ref{tab:ttmsep-n25-overflow}, where it is marked with an asterisk ($^{\ast}$) as out of scope.}
\end{table}

These studies indicate that TRTF closes part of the gap to oracle likelihoods while preserving the triangular evaluation frame. Separable maps remain competitive at moderate sample sizes but exhibit ordering sensitivity and sparse-regime fragility, and copulas provide competitive baselines in low dimensions. Section~\ref{sec:realdata} turns to real-data benchmarks and compute summaries under the same protocol.

\section{Real-Data Benchmarks and Compute}\label{sec:realdata}

% Checklist: align dynamic refs, restate units, bridge to later chapters.
This section presents real-data evidence on MiniBooNE and the UCI tabular benchmarks under the transport frame introduced in Chapters~\ref{ch:intro} and~\ref{ch:background}. We keep preprocessing identical to the published flow literature where applicable, align likelihood reporting through standardized coordinates and the affine correction in Equation~\eqref{eq:transport-affine}, and pair test log likelihoods with compute summaries so that score differences reflect modeling assumptions rather than inconsistent units.

\paragraph{Preprocessing.} We treat dataset-specific preprocessing as part of each estimator to preserve comparability. MiniBooNE follows \citet{papamakarios2017masked}: we remove $11$ outliers at $-1000$, drop $7$ near-constant attributes, retain $K=43$ variables, and rely on the official train, validation, and test splits. We standardize with training statistics only, evaluate Jacobians in standardized coordinates, and apply the diagonal affine correction once at reporting time. The UCI datasets follow the same rule. POWER receives jitter on the minute-of-day encoding, removal of the calendar-date and reactive-power attributes, and a small uniform perturbation to break ties. GAS keeps the \texttt{ethylene\_CO} subset and removes strongly correlated attributes to yield an eight-dimensional representation. HEPMASS keeps the positive class from the ``1000'' split and discards five repeated-value variables to avoid density spikes. These steps match the literature conventions and keep the reported likelihoods interpretable.

\paragraph{Flow baselines.} Published normalizing flows compose invertible layers with permutations or autoregressive sublayers and report strong test log likelihoods on the UCI suite and MiniBooNE \citep{rezende2015variational,dinh2017real,kingma2018glow,durkan2019neural,papamakarios2021normalizing}. Table~\ref{tab:uci-loglik} reproduces the published average test log-likelihoods per example together with $\pm$ two standard errors reported by \citet{papamakarios2017masked} and appends our TRTF measurements trained with $N=2500$ observations. Higher values indicate better fits. We report TRTF as means $\pm$ 2SE under the same evaluation pipeline.

\begin{table}[htbp]
  \centering
  \textit{(average LL; nats per example).}
  \caption{UCI: average test log-likelihood per example (nats; higher is better). Baselines (first seven rows): means $\pm$ 2SE as reported by \citet{papamakarios2017masked}. TRTF (ours): single-seed measurements at $N=2500$ (no SE). Entries marked ``--'' indicate configurations not executed in this draft.}
  \label{tab:uci-loglik}
  \begin{tabular}{lrrrr}
    \hline
    Model & POWER & GAS & HEPMASS & MiniBooNE \\
    \hline
    Gaussian          & $-7.74 \pm 0.02$ & $-3.58 \pm 0.75$ & $-27.93 \pm 0.02$ & $-37.24 \pm 1.07$ \\
    MADE              & $-3.08 \pm 0.03$ & $ 3.56 \pm 0.04$ & $-20.98 \pm 0.02$ & $-15.59 \pm 0.50$ \\
    MADE MoG          & $ 0.40 \pm 0.01$ & $ 8.47 \pm 0.02$ & $-15.15 \pm 0.02$ & $-12.27 \pm 0.47$ \\
    Real NVP (5)      & $-0.02 \pm 0.01$ & $ 4.78 \pm 1.80$ & $-19.62 \pm 0.02$ & $-13.55 \pm 0.49$ \\
    Real NVP (10)     & $ 0.17 \pm 0.01$ & $ 8.33 \pm 0.14$ & $-18.71 \pm 0.02$ & $-13.84 \pm 0.52$ \\
    MAF (5)           & $ 0.14 \pm 0.01$ & $ 9.07 \pm 0.02$ & $-17.70 \pm 0.02$ & $-11.75 \pm 0.44$ \\
    MAF MoG (5)       & $ 0.30 \pm 0.01$ & $ 9.59 \pm 0.02$ & $-17.39 \pm 0.02$ & $-11.68 \pm 0.44$ \\
    TRTF (ours)    & $-7.17 \pm 0.39$ & $-2.41 \pm 0.37$ & $-25.47 \pm 0.37$ & $-30.01 \pm 1.26$ \\
    \hline
  \end{tabular}
\end{table}

\paragraph{MiniBooNE.} Table~\ref{tab:uci-loglik} shows that the Gaussian reference yields $-37.24 \pm 1.07$ nats, providing a weak baseline. MADE reaches $-15.59 \pm 0.50$ nats, the Real NVP variants lie near $-13.7$ nats, and MAF MoG improves to $-11.68 \pm 0.44$ nats. Our TRTF result attains $-30.01 \pm 1.26$ nats at $N=2500$, improving over the Gaussian baseline yet trailing the flow families by a wide margin. This ranking is consistent with the separable Jacobian and the forest aggregation discussed in Section~\ref{sec:models-implementation}. The high dimensionality of MiniBooNE amplifies residual misfit through the triangular determinant.\;Clipping: validation-tuned bound $H$ applied; the exact value is recorded with the experiment logs.

\paragraph{POWER.} POWER offers a milder conditional structure and lower dimensionality. Table~\ref{tab:uci-loglik} reports that TRTF records $-7.17 \pm 0.39$ nats at $N=2500$, which falls short of the flow baselines. Real NVP with ten steps reaches $0.17 \pm 0.01$ nats, while MAF MoG attains $0.30 \pm 0.01$ nats. The gap indicates that the current TRTF configuration underutilizes structure in this benchmark; additional seeds or hyperparameter tuning may recover the performance previously observed at smaller sample sizes.\;Clipping: validation-tuned bound $H$ applied; the exact value is recorded with the experiment logs.

\paragraph{GAS and HEPMASS.} The TRTF results on GAS and HEPMASS yield $-2.41 \pm 0.37$ and $-25.47 \pm 0.37$ nats, respectively. Both scores remain below the flow baselines, emphasizing that the present configuration sacrifices likelihood accuracy for interpretability. Additional seeds and tuning remain planned, yet we retain the current numbers to document the outcome of the standardized pipeline at $N=2500$.\;Clipping: validation-tuned bound $H$ applied; the exact values are recorded with the experiment logs.

\paragraph{Sample size sensitivity.} Figure~\ref{fig:n-sensitivity} plots test negative log likelihood versus sample size $N$ for the UCI benchmarks, aggregating seeds at each budget. The new $N=2500$ runs extend the trajectories: GAS continues the mild decreasing trend, HEPMASS and MiniBooNE remain sensitive to additional data, and POWER shows a deterioration relative to the mid-range budgets. The figure reports one standard error bars (zero when only a single seed is available), restates that lower curves indicate better fits because the vertical axis plots NLL, and mirrors the diagnostic procedures in Section~\ref{sec:evaluation-protocol}.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\linewidth]{figure/N_sensitivity_all.png}
  \caption{Test negative log-likelihood (NLL; nats; lower is better) versus sample size $N$ on the UCI benchmarks. Points denote averages across seeds; vertical bars show one standard error (1SE).}
  \label{fig:n-sensitivity}
\end{figure}

\paragraph{Compute metrics.} Likelihood comparisons require compute summaries because similar accuracy at very different costs leads to different recommendations. Training time is wall-clock time to fit the model on the training split with fixed seeds and deterministic preprocessing. Evaluation time is the wall-clock time per $10^5$ joint log-density evaluations on the test split, averaged over seeds. These definitions mirror the compute discussion in Section~\ref{sec:evaluation-protocol}, use the same standardized inputs across datasets, and yield the budget-specific totals collected in Table~\ref{tab:real-compute}.

\begin{table}[htbp]
  \centering
  \caption{TRTF wall-clock training plus evaluation time (seconds) as a function of the training budget $N$. Runs use the standardized inputs, seeds, and transport direction shared across datasets. Dashes denote configurations that were not executed in the current draft.}
  \label{tab:real-compute}
  \begin{tabular}{lrrrrrrr}
    \hline
    Dataset & $N=25$ & $N=50$ & $N=100$ & $N=250$ & $N=500$ & $N=1000$ & $N=2500$ \\
    \hline
    POWER     & $1$ & $1$ & $2$ & $6$ & $39$ & $115$ & $130$ \\
    GAS       & $1$ & $1$ & $2$ & $5$ & $39$ & $138$ & $600$ \\
    HEPMASS   & $1$ & $2$ & $4$ & $9$ & $12$ & $153$ & $721$ \\
    MiniBooNE & $3$ & $4$ & $8$ & $20$ & $27$ & $202$ & $2007$ \\
    \hline
  \end{tabular}
\end{table}

\paragraph{Interpretation.} The real-data evidence aligns with the synthetic diagnostics in Section~\ref{sec:synthetic-results}. MiniBooNE exposes the limits of separable structure in high dimensions, and the updated POWER value shows that the present TRTF configuration no longer matches flow baselines once the training budget increases to $N=2500$. GAS and HEPMASS also trail the published flows, illustrating that interpretability and exact inversion come at a likelihood cost under the current hyperparameters. Table~\ref{tab:real-compute} documents the corresponding compute budgets and confirms the anticipated near-linear growth in wall-clock time.

\section{Reproducibility}\label{sec:reproducibility}
We avoid AIC or BIC because effective parameter counts differ across estimators, and we do not treat small likelihood differences as practically significant when $\pm 2$ SE intervals overlap. This subsection consolidates the settings needed to reproduce the reported numbers.

- Data splits and direction
  - Synthetic: fixed train/validation/test proportions $0.60/0.20/0.20$; evaluations use the shared direction $S:u\to z$ in standardized coordinates and apply the diagonal affine correction once for reporting.
  - Real data: use official splits where provided (MiniBooNE) and the same standardized evaluation pipeline; otherwise adopt the same $0.60/0.20/0.20$ convention.

- Seeds
  - Synthetic generators and model fits: seeds $\{11,13,17,19,23\}$ across repeats; permutation studies average over all $4!=24$ orderings in the 4D case.
  - Real data (UCI + MiniBooNE): single-seed runs with seed $42$ for training/evaluation in this draft.

- Standardization and evaluation
  - Standardize features with training-split $(\mu,\sigma)$ only; compute all derivatives/Jacobians in $u$; report on $x$ via the affine correction in Eq.~\eqref{eq:transport-affine}.
  - TRTF uses forest aggregation and monotone CDF smoothing so that the induced likelihood matches the separable triangular form (Sec.~\ref{sec:transport-trtf}).

- Hyperparameters and tuning
  - TTM-Sep: monotone one-dimensional bases for $h_k$ (identity, integrated sigmoids, softplus-like edge terms, integrated RBFs); low-degree polynomial features for $g_k$; ridge regularization on all coefficients; log-derivative clipping to $[-H,H]$ (bound $H$ tuned on validation). Degree and penalty strengths are selected by validation; ordering is fixed to the natural order in headline tables and varied in robustness checks.
  - TTM-Sep: monotone one-dimensional bases for $h_k$ (identity, integrated sigmoids, softplus-like edge terms, integrated RBFs); low-degree polynomial features for $g_k$; ridge regularization on all coefficients; log-derivative clipping to $[-H,H]$ (bound $H$ tuned on validation). Degree and penalty strengths are selected by validation; ordering is fixed to the natural order in headline tables and, when heuristics are enabled, chosen as the better of identity vs. Cholesky-pivoted (with optional Gaussianization) according to validation NLL.
  - TRTF: forest aggregation with strictly increasing conditional CDFs after standard monotone smoothing; remaining fit options follow package defaults unless stated; we record the number of trees, depth and split rules in the experiment logs.
  - Copulas (diagnostics only for $K\le 3$): probit pseudo-observations and kernel density copula via \texttt{kdecopula} with default bandwidth selection; independence and Gaussian baselines are used only for reference in text where noted.
  - Exact choices (e.g., basis sizes, ridge penalties, selected $H$) are captured alongside each run in the experiment logs and summarized inline where relevant; we avoid duplicate tables in the PDF.

Final safeguard settings used for the reported results. For Half-Moon ($n=250$) and 4D ($n=250$), TTM-Sep used degree$_g=2$, ridge $\lambda=0$, and no log-derivative clipping was activated (no terms hit the bound). The $n=25$ 4D case overflowed under $\lambda=0$; reruns with $\lambda>0$ and tighter $H$ removed the failure but are omitted as out of scope. Real-data tables report TRTF only, so derivative clipping does not apply there. Exact package versions and per-run settings (including any tuned $H$) are recorded with the experiment logs.

- Software and hardware
  - R with packages: \texttt{tram}, \texttt{trtf}, \texttt{partykit}, \texttt{mlt}, \texttt{dplyr}, \texttt{parallel}, and \texttt{knitr}/LaTeX for the report. We record package versions via \texttt{sessionInfo()} in run logs.
  - Single-threaded BLAS by default; optional parallel training for TRTF via \texttt{options(trtf.train\_cores = 4)} when available.
  - CPU-only runs on a laptop-class machine; logs include hardware notes (CPU model, RAM) and wall-clock timings (Table~\ref{tab:real-compute}).

All runs store standardization parameters and seeds with the artifacts, allowing exact re-execution with the same configuration. Appendix~\ref{ch:appendix} provides routine interfaces and object layouts to support this.

\paragraph{Bridge to Chapter~\ref{ch:conclusion}.} The real-data study closes Chapter~\ref{ch:dataanalysis} by positioning separable triangular transports and TRTF within the UCI and MiniBooNE landscape. TRTF offers exact inversion, linear evaluation, and transparent conditional structure, yet trails modern flows on MiniBooNE. Chapter~\ref{ch:conclusion} interprets these trade-offs and distills guidance for practitioners choosing between separable transports, transformation forests, and copula baselines on tabular data.
